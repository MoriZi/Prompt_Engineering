{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Outline**\n",
    "\n",
    "- Generating Data and Synthetic Datasets\n",
    "- Case Study: Sentiment Analysis\n",
    "- Workshop: Tackling Generated Datasets Diversity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m venv openai-env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!source openai-env/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.11/site-packages (1.13.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.11/site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.11/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.11/site-packages (from openai) (2.6.3)\n",
      "Requirement already satisfied: sniffio in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.11/site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.11/site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: certifi in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "import getpass\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "    \n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "    api_version=\"2023-05-15\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"In the world of code, there lies a path unseen,\\nWhere functions call themselves, a recursive dream.\\nLike a mirrored hallway stretching into the night,\\nA journey of iterations, an endless flight.\\n\\nOne function's call triggers another's might,\\nA dance of repetition, a waltz of light.\\nWith each recursive step, the problem unfurls,\\nLike a flower unfolding, in endless swirls.\\n\\nInto the depths of the stack, the calls descend,\\nA labyrinth of functions, a looping trend.\\nUntil a base case, like a beacon, shines bright,\\nEnding the cycle, breaking the endless flight.\\n\\nRecursion, a concept both mystical and clear,\\nA beautiful loop, with no ending near.\\nA journey of logic, a puzzle to solve,\\nIn the world of programming, it continues to evolve.\\n\\nSo embrace the recursive, let your functions sing,\\nIn the dance of iteration, let your code take wing.\\nFor in the depths of recursion, beauty resides,\\nA poetic algorithm, where complexity hides.\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-35-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Prompt Chaining**\n",
    "\n",
    "- Prompt chaining involves decomposing complex tasks into manageable subtasks, sequentially addressing each through a series of prompts.\n",
    "- **Key Benefits**:\n",
    "  - **Improved Performance**: By focusing on smaller, specific tasks, the LLM can provide more accurate and relevant responses.\n",
    "  - **Enhanced Transparency**: The step-by-step approach allows for easier tracking of how conclusions are reached, aiding in debugging and refinement.\n",
    "  - **Increased Controllability and Reliability**: Fine-tuning responses at each stage leads to more predictable outcomes.\n",
    "- **Application Areas**:\n",
    "  - **Conversational Assistants**: Tailoring responses to user queries with greater precision and personalization.\n",
    "  - **Application Enhancement**: Improving user experience by ensuring that interactions are more natural and responses are more nuanced.\n",
    "- **Strategic Approach**: Identify the key subtasks within a complex query, craft tailored prompts for each, and iteratively refine responses to achieve the final goal. This method not only optimizes the LLM's performance but also provides insights into potential areas for further improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt:\n",
    "\n",
    "[The input document ](https://en.wikipedia.org/wiki/Prompt_engineering)\n",
    "```\n",
    "You are a helpful assistant. Your task is to help answer a question given a document. The first step is to extract quotes relevant to the question from the document, delimited by ####. Please output the list of quotes using <quotes></quotes>. Respond with \"No relevant quotes found!\" if no relevant quotes were found.\n",
    "\n",
    "\n",
    "####\n",
    "{{document}}\n",
    "####\n",
    "\n",
    "```\n",
    "\n",
    "<img src=\"./images/img5.png\" width=\"800\" align=\"center\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lets clean up the qoutes a bit more\n",
    "  - **Input Integration**: Takes the relevant quotes extracted by the first prompt.\n",
    "  - **Response Formulation**: Prepares a comprehensive and informative answer.\n",
    "  - **Context Utilization**: Uses both the original document and extracted quotes.\n",
    "  - **Objective**: To provide a well-informed response to the posed question with contextual depth.\n",
    "\n",
    "```\n",
    "Given a set of relevant quotes (delimited by <quotes></quotes>) extracted from a document and the original document (delimited by ####), please compose an answer to the question. Ensure that the answer is accurate, has a friendly tone, and sounds helpful.\n",
    "\n",
    "####\n",
    "https://en.wikipedia.org/wiki/Prompt_engineering\n",
    "####\n",
    "\n",
    "<quotes>\n",
    "- Chain-of-thought (CoT) prompting[27]\n",
    "- Generated knowledge prompting[37]\n",
    "- Least-to-most prompting[38]\n",
    "- Self-consistency decoding[39]\n",
    "- Complexity-based prompting[41]\n",
    "- Self-refine[42]\n",
    "- Tree-of-thought prompting[43]\n",
    "- Maieutic prompting[45]\n",
    "- Directional-stimulus prompting[46]\n",
    "- Textual inversion and embeddings[59]\n",
    "- Using gradient descent to search for prompts[61][62][63][64]\n",
    "- Prompt injection[65][66][67]\n",
    "</quotes>\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "The prompting techniques mentioned in the document include:\n",
    "\n",
    "1. Chain-of-thought (CoT) prompting[27]\n",
    "2. Generated knowledge prompting[37]\n",
    "3. Least-to-most prompting[38]\n",
    "4. Self-consistency decoding[39]\n",
    "5. Complexity-based prompting[41]\n",
    "6. Self-refine[42]\n",
    "7. Tree-of-thought prompting[43]\n",
    "8. Maieutic prompting[45]\n",
    "9. Directional-stimulus prompting[46]\n",
    "10. Textual inversion and embeddings[59]\n",
    "11. Using gradient descent to search for prompts[61][62][63][64]\n",
    "12. Prompt injection[65][66][67]\n",
    "\n",
    "Each of these techniques employs unique strategies to enhance or specify the interactions with large language models to produce the desired outcomes.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Simplifying and creating prompt chains is beneficial for **multi-step operations** or transformations in responses.\n",
    "- Practice exercise: Design a prompt that removes citations (e.g., \"[27]\") from responses before finalizing them for application users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Function Calling with LLMs**\n",
    "  - Enables LLMs like GPT-4 and GPT-3.5 to reliably connect with external tools and APIs.\n",
    "  - Detects the need for a function call within a chat and outputs JSON with arguments to execute the function.\n",
    "\n",
    "- **Tool Integration:**\n",
    "  - Functions act as tools within AI applications, allowing for multiple tools to be defined and called in a single request.\n",
    "\n",
    "- **Importance for AI Applications:**\n",
    "  - Essential for developing LLM-powered chatbots or agents that require context retrieval or need to interact with external tools.\n",
    "  - Transforms natural language instructions into actionable API calls, enhancing the utility and interactivity of chatbots.\n",
    "\n",
    "- **Enhancing Chatbot Capabilities:**\n",
    "  - Facilitates seamless integration of LLMs with a wide range of external services and data sources.\n",
    "  - Enables chatbots to perform complex tasks, such as data retrieval, content creation, and more, by calling specific functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Applications Enabled by Functional Calling**\n",
    "\n",
    "- **Conversational Agents with External Tool Usage:**\n",
    "  - Allows conversational agents to efficiently utilize external tools to answer user questions.\n",
    "  - Example: Querying weather information translates to function calls like `get_current_weather(location: string, unit: 'celsius' | 'fahrenheit')`.\n",
    "\n",
    "- **Data Extraction and Tagging Solutions:**\n",
    "  - Empowers LLM-powered solutions to extract and tag data from various sources.\n",
    "  - Example: Extracting people names from a Wikipedia article.\n",
    "\n",
    "- **Natural Language to API Conversion:**\n",
    "  - Facilitates the creation of applications that translate natural language into API calls or database queries.\n",
    "  - Enhances the usability and accessibility of data and services.\n",
    "\n",
    "- **Conversational Knowledge Retrieval Engines:**\n",
    "  - Enables conversational engines to interact with knowledge bases, facilitating knowledge retrieval through natural language queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Function Calling with GPT-4**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Integration of LLM with External Tool for Weather Query**\n",
    "  - **Challenge:**\n",
    "    - LLM alone cannot respond to dynamic queries like checking the weather due to dataset limitations.\n",
    "  - **Solution:**\n",
    "    - Utilize function calling capabilities of the LLM to invoke an external tool for weather information retrieval.\n",
    "\n",
    "  - **Implementation Example:**\n",
    "    - User query: \"What is the weather like in a given location?\"\n",
    "    - LLM processes the query and recognizes the need for external information.\n",
    "    - Function calling mechanism selects appropriate function and arguments (e.g., `get_current_weather(location: string, unit: 'celsius' | 'fahrenheit')`).\n",
    "    - OpenAI APIs facilitate the interaction between the LLM and the weather API.\n",
    "    - Final response generated based on the retrieved weather data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "What is the weather like in London?\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To handle this request using function calling,\n",
    "  - Define a weather function or set of functions that you will be passing as part of the OpenAI API request\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
    "                    },\n",
    "                    \"unit\": {\n",
    "                        \"type\": \"string\", \n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"]\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Function Details:\n",
    "  - Name: get_current_weather\n",
    "  - Description: Retrieves the current weather in a specified location.\n",
    "  - Parameters:\n",
    "    - location: Specifies the city and state (e.g., San Francisco, CA).\n",
    "    - unit: Specifies the temperature unit (celsius or fahrenheit).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a completion function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(client, messages, model=\"gpt-4\", temperature=0, max_tokens=300, tools=None, tool_choice=None):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        tools=tools,\n",
    "        tool_choice=tool_choice\n",
    "    )\n",
    "    return response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compose the user question:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What is the weather like in London?\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_uOGq9vU9E9dZVGRpNBsFVauq', function=Function(arguments='{\"location\":\"London\"}', name='get_current_weather'), type='function')])\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(client, messages, tools=tools)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capture the arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "args = json.loads(response.tool_calls[0].function.arguments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines a dummy function to get the current weather\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    weather = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": \"50\",\n",
    "        \"unit\": unit,\n",
    "    }\n",
    "\n",
    "    return json.dumps(weather)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"location\": \"London\", \"temperature\": \"50\", \"unit\": \"fahrenheit\"}'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_weather(**args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **An LLM-powered conversational agent**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Hello! How are you?\",\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=\"Hello! I'm just a digital assistant, so I don't have feelings, but I'm here and ready to assist you. How can I help you today?\", role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(client, messages, tools=tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Specify desired behavior for function calling to tailor the response generation process according to specific requirements.\n",
    "- By default, the model autonomously determines whether to call a function and which function to call.\n",
    "-  Utilize the tool_choice parameter to control the behavior of the system.\n",
    "- Default setting: tool_choice: \"auto\".\n",
    "\n",
    "- In \"auto\" mode, the model automatically decides whether and which function to call based on the context of the user query.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=\"Hello! I'm just a digital assistant, so I don't have feelings, but I'm here and ready to assist you. How can I help you today?\", role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(client, messages, tools=tools, tool_choice=\"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=\"Hello! I'm just a digital assistant, so I don't have feelings, but I'm here and ready to assist you. How can I help you today?\", role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(client, messages, tools=tools, tool_choice=\"none\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forces the model to not use any of the functions provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='To provide you with the current weather in London, I will use the weather tool. Please hold on for a moment while I fetch the information for you.', role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's the weather like in London?\",\n",
    "    }\n",
    "]\n",
    "get_completion(client, messages, tools=tools, tool_choice=\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Force the model to choose a function if that's the behavior you want in your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_qnG8WMyJRGK1ccUXCrSTWjiF', function=Function(arguments='{\"location\":\"London\"}', name='get_current_weather'), type='function')])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's the weather like in London?\",\n",
    "    }\n",
    "]\n",
    "get_completion(client, messages, tools=tools, tool_choice={\"type\": \"function\", \"function\": {\"name\": \"get_current_weather\"}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Develop an agent that passes back the result obtained after calling your APIs with the inputs generated from function calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"user\", \"content\": \"What's the weather like in Boston!\"})\n",
    "assistant_message = get_completion(client, messages, tools=tools, tool_choice=\"auto\")\n",
    "assistant_message = json.loads(assistant_message.model_dump_json())\n",
    "assistant_message[\"content\"] = str(assistant_message[\"tool_calls\"][0][\"function\"])\n",
    "\n",
    "#a temporary patch but this should be handled differently\n",
    "# remove \"function_call\" from assistant message\n",
    "del assistant_message[\"function_call\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(assistant_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': \"What's the weather like in Boston!\"},\n",
       " {'content': '{\\'arguments\\': \\'{\"location\":\"Boston, MA\"}\\', \\'name\\': \\'get_current_weather\\'}',\n",
       "  'role': 'assistant',\n",
       "  'tool_calls': [{'id': 'call_qnG8WMyJRGK1ccUXCrSTWjiF',\n",
       "    'function': {'arguments': '{\"location\":\"Boston, MA\"}',\n",
       "     'name': 'get_current_weather'},\n",
       "    'type': 'function'}]}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"location\": \"{\\\\\"location\\\\\":\\\\\"Boston, MA\\\\\"}\", \"temperature\": \"50\", \"unit\": \"fahrenheit\"}'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the weather information to pass back to the model\n",
    "weather = get_current_weather(messages[1][\"tool_calls\"][0][\"function\"][\"arguments\"])\n",
    "\n",
    "weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({\"role\": \"tool\",\n",
    "                 \"tool_call_id\": assistant_message[\"tool_calls\"][0][\"id\"],\n",
    "                 \"name\": assistant_message[\"tool_calls\"][0][\"function\"][\"name\"],\n",
    "                 \"content\": weather})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': \"What's the weather like in Boston!\"},\n",
       " {'content': '{\\'arguments\\': \\'{\"location\":\"Boston, MA\"}\\', \\'name\\': \\'get_current_weather\\'}',\n",
       "  'role': 'assistant',\n",
       "  'tool_calls': [{'id': 'call_qnG8WMyJRGK1ccUXCrSTWjiF',\n",
       "    'function': {'arguments': '{\"location\":\"Boston, MA\"}',\n",
       "     'name': 'get_current_weather'},\n",
       "    'type': 'function'}]},\n",
       " {'role': 'tool',\n",
       "  'tool_call_id': 'call_qnG8WMyJRGK1ccUXCrSTWjiF',\n",
       "  'name': 'get_current_weather',\n",
       "  'content': '{\"location\": \"{\\\\\"location\\\\\":\\\\\"Boston, MA\\\\\"}\", \"temperature\": \"50\", \"unit\": \"fahrenheit\"}'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_response = get_completion(client, messages, tools=tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='The current weather in Boston, MA is 50 degrees Fahrenheit.', role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Generating Data**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LLMs possess powerful text generation capabilities for creating coherent text.\n",
    "- Implementing effective prompt strategies enhances the quality, consistency, and factual accuracy of the model's outputs.\n",
    "- LLMs are invaluable for generating datasets, facilitating a wide range of experiments and evaluations.\n",
    "- They can be utilized for quick sample generation in applications, such as training a sentiment classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Produce 10 exemplars for sentiment analysis. Examples are categorized as either positive or negative. Produce 2 negative examples and 8 positive examples. Use this format for the examples:\n",
    "Q: <sentence>\n",
    "A: <sentiment>\n",
    "```\n",
    "\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Q: I just got the best news ever!\n",
    "A: Positive\n",
    "\n",
    "Q: We just got a raise at work!\n",
    "A: Positive\n",
    "\n",
    "Q: I'm so proud of what I accomplished today.\n",
    "A: Positive\n",
    "\n",
    "Q: I'm having the best day ever!\n",
    "A: Positive\n",
    "\n",
    "Q: I'm really looking forward to the weekend.\n",
    "A: Positive\n",
    "\n",
    "Q: I just got the best present ever!\n",
    "A: Positive\n",
    "\n",
    "Q: I'm so happy right now.\n",
    "A: Positive\n",
    "\n",
    "Q: I'm so blessed to have such an amazing family.\n",
    "A: Positive\n",
    "\n",
    "Q: The weather outside is so gloomy.\n",
    "A: Negative\n",
    "\n",
    "Q: I just got some terrible news.\n",
    "A: Negative\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Machine Learning projects often face challenges due to insufficient labeled data, leading to prolonged data collection and labeling phases.\n",
    "- The emergence of LLMs has transformed this paradigm, enabling the testing and development of ideas or AI-powered features with minimal delay.\n",
    "- LLMs leverage their generalization capabilities to provide immediate insights and preliminary results.\n",
    "- Successful initial testing with LLMs can justify and lead into the traditional, more time-consuming development process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/synthetic_rag_1.webp\" width=\"800\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Retrieval Augmented Generation (RAG) is a method that combines\n",
    "  -  information retrieval with LLM text generation for knowledge-intensive tasks.\n",
    "- The Retrieval model is key,\n",
    "  - Selecting relevant documents for the LLM to process, with its performance directly impacting the quality of the output.\n",
    "- RAG's effectiveness can vary across languages and specific domains, \n",
    "  - Sometimes struggling with tasks like creating a chatbot for Czech legal advice or a tax assistant for the Indian market.\n",
    "- A solution to enhance RAG's performance \n",
    "  - Using LLMs to synthesize training data for new models, a method that can improve accuracy in underrepresented languages or specialized areas.\n",
    "- This approach, while computationally demanding, aims at distilling LLMs into more efficient models, potentially lowering inference costs and boosting overall system performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Domain-Specific Dataset Generation**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data labeling is crucial for machine learning projects, following the principle of \"garbage in, garbage out.\"\n",
    "- Labeling entails generating annotated datasets for training and evaluation purposes.\n",
    "- This process is often time-consuming and costly, particularly for projects with extensive datasets.\n",
    "- Leveraging advancements in Large Language Models (LLMs) could potentially mitigate the cost and effort associated with data labeling tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Utilizing pre-labeled data is more appealing than starting from scratch, as editing is typically less arduous than composing original work.\n",
    "- Leveraging GPT-4 as a prediction engine for pre-labeling data capitalizes on its contextual understanding and ability to generate human-like text.\n",
    "- By incorporating GPT-4 into the labeling process, manual effort can be significantly reduced, leading to cost savings and a less monotonous process.\n",
    "- Prompt engineering, familiar to users of GPT models, involves setting the context for the model to generate specific outputs. Crafting prompts tailored to our desired output format facilitates GPT-4's generation of text resembling model predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Example task: Sentiment analysis - classifying text as positive, negative, or neutral.**\n",
    "\n",
    "- Prompt: \"Given the input text, classify its sentiment as positive, negative, or neutral.\"\n",
    "- Follow-up instructions: \"Ensure the generated output corresponds accurately to the sentiment expressed in the input text.\"\n",
    "- Desired outcome: Text generated should indicate whether the sentiment is positive, negative, or neutral based on the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import re\n",
    "\n",
    "def get_sentiment(input_text):\n",
    "    prompt = f\"Respond in the json format: {{'response': sentiment_classification}}\\nText: {input_text}\\nSentiment (positive, neutral, negative):\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-35-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt,}\n",
    "        ],\n",
    "        max_tokens=40,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "    response_text =  response.choices[0].message.content.strip()\n",
    "    sentiment = re.search(\"negative|neutral|positive\", response_text).group(0)\n",
    "    # Add input_text back in for the result\n",
    "    return {\"text\": input_text, \"response\": sentiment}\n",
    "    # return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test single example\n",
    "\n",
    "sample_text = \"I had a terrible time at the party last night!\"\n",
    "sentiment = get_sentiment(sample_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I had a terrible time at the party last night!',\n",
       " 'response': 'negative'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting input_texts.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile input_texts.txt\n",
    "I love going to the park on a sunny day. \n",
    "The customer service was terrible; they were rude and unhelpful.\n",
    "I am neither happy nor sad about the new policy changes.\n",
    "The cake was delicious and the presentation was fantastic.\n",
    "I had a really bad experience with the product; it broke after two days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "input_file_path = \"input_texts.txt\"\n",
    "output_file_path = \"output_responses.json\"\n",
    "\n",
    "with open(input_file_path, \"r\") as input_file, open(output_file_path, \"w\") as output_file:\n",
    "    examples = []\n",
    "    for line in input_file:\n",
    "        text = line.strip()\n",
    "        if text:\n",
    "            examples.append((get_sentiment(text)))\n",
    "    output_file.write(json.dumps(examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Should I now use it directly for training my model?**\n",
    "\n",
    "- Verification is required!\n",
    "- one approach is to go for some user-friendly tools like label studio to verify some of them easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ls_format(input_dict):\n",
    "    \"\"\"\n",
    "    Convert sentiment analysis output from a simple format to Label Studio's prediction format.\n",
    "    \n",
    "    Args:\n",
    "        input_dict (dict): A dictionary containing text and response keys. Example:\n",
    "            {\n",
    "                \"text\": \"I love going to the park on a sunny day.\",\n",
    "                \"response\": \"positive\"\n",
    "            }\n",
    "            \n",
    "    Returns:\n",
    "        dict: A dictionary in Label Studio's prediction format. \n",
    "    \"\"\"\n",
    "    \n",
    "    score_value = 1.00  # We don't know the model confidence\n",
    "    output_dict = {\n",
    "        \"data\": {\n",
    "            \"text\": input_dict[\"text\"]\n",
    "        },\n",
    "        \"predictions\": [\n",
    "            {\n",
    "                \"result\": [\n",
    "                    {\n",
    "                        \"value\": {\n",
    "                            \"choices\": [\n",
    "                                input_dict[\"response\"].capitalize()\n",
    "                            ]\n",
    "                        },\n",
    "                        \"from_name\": \"sentiment\",\n",
    "                        \"to_name\": \"text\",\n",
    "                        \"type\": \"choices\"\n",
    "                    }\n",
    "                ],\n",
    "                \"score\": score_value,\n",
    "                \"model_version\": \"gpt-3.5-turbo\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'text': 'I had a terrible time at the party last night!'}, 'predictions': [{'result': [{'value': {'choices': ['Negative']}, 'from_name': 'sentiment', 'to_name': 'text', 'type': 'choices'}], 'score': 1.0, 'model_version': 'gpt-3.5-turbo'}]}\n"
     ]
    }
   ],
   "source": [
    "print(convert_ls_format(sentiment))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "input_file_path = \"input_texts.txt\"\n",
    "output_file_path = \"output_responses.json\"\n",
    "\n",
    "with open(input_file_path, \"r\") as input_file, open(output_file_path, \"w\") as output_file:\n",
    "    examples = []\n",
    "    for line in input_file:\n",
    "        text = line.strip()\n",
    "        if text:\n",
    "            examples.append(convert_ls_format(get_sentiment(text)))\n",
    "    output_file.write(json.dumps(examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Set up a Label Studio project: Begin by creating a new project in Label Studio.\n",
    "- Import pre-labeled data: Upload the pre-labeled data into the Label Studio project.\n",
    "- Review annotations: Examine the annotations within Label Studio to ensure accuracy and consistency.\n",
    "- Iterate if necessary: Make any necessary adjustments or corrections to the annotations based on the review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: Install and Launch Label Studio**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting label-studio\n",
      "  Downloading label_studio-1.11.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting Django<3.3.0,>=3.2.23 (from label-studio)\n",
      "  Downloading Django-3.2.25-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting appdirs>=1.4.3 (from label-studio)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting attr==0.3.1 (from label-studio)\n",
      "  Downloading attr-0.3.1.tar.gz (1.7 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.11/site-packages (from label-studio) (23.2.0)\n",
      "Collecting azure-storage-blob>=12.6.0 (from label-studio)\n",
      "  Downloading azure_storage_blob-12.19.1-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting bleach<5.1.0,>=5.0.0 (from label-studio)\n",
      "  Downloading bleach-5.0.1-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting boto<3.0.0,>=2.49.0 (from label-studio)\n",
      "  Downloading boto-2.49.0-py2.py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting boto3<2.0.0,>=1.28.58 (from label-studio)\n",
      "  Downloading boto3-1.34.60-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting botocore<2.0.0,>=1.31.58 (from label-studio)\n",
      "  Downloading botocore-1.34.60-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting boxing>=0.1.4 (from label-studio)\n",
      "  Downloading boxing-0.1.4-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting colorama>=0.4.4 (from label-studio)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting defusedxml>=0.7.1 (from label-studio)\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting django-annoying==0.10.6 (from label-studio)\n",
      "  Downloading django_annoying-0.10.6-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting django-cors-headers==3.6.0 (from label-studio)\n",
      "  Downloading django_cors_headers-3.6.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting django-csp==3.7 (from label-studio)\n",
      "  Downloading django_csp-3.7-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting django-debug-toolbar==3.2.1 (from label-studio)\n",
      "  Downloading django_debug_toolbar-3.2.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting django-environ==0.10.0 (from label-studio)\n",
      "  Downloading django_environ-0.10.0-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Collecting django-extensions==3.1.0 (from label-studio)\n",
      "  Downloading django_extensions-3.1.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting django-filter==2.4.0 (from label-studio)\n",
      "  Downloading django_filter-2.4.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting django-model-utils==4.1.1 (from label-studio)\n",
      "  Downloading django_model_utils-4.1.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting django-ranged-fileresponse>=0.1.2 (from label-studio)\n",
      "  Downloading django-ranged-fileresponse-0.1.2.tar.gz (2.7 kB)\n",
      "  Installing build dependencies ... \u001b[?25l"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting django-rq==2.5.1 (from label-studio)\n",
      "  Downloading django_rq-2.5.1-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting django-storages==1.12.3 (from label-studio)\n",
      "  Downloading django_storages-1.12.3-py3-none-any.whl.metadata (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting django-user-agents==0.4.0 (from label-studio)\n",
      "  Downloading django_user_agents-0.4.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting djangorestframework==3.13.1 (from label-studio)\n",
      "  Downloading djangorestframework-3.13.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting drf-dynamic-fields==0.3.0 (from label-studio)\n",
      "  Downloading drf_dynamic_fields-0.3.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting drf-flex-fields==0.9.5 (from label-studio)\n",
      "  Downloading drf-flex-fields-0.9.5.tar.gz (27 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting drf-generators==0.3.0 (from label-studio)\n",
      "  Downloading drf-generators-0.3.0.tar.gz (9.4 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting google-cloud-storage<3.0.0,>=2.13.0 (from label-studio)\n",
      "  Downloading google_cloud_storage-2.15.0-py2.py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting htmlmin==0.1.12 (from label-studio)\n",
      "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting humansignal-drf-yasg>=1.21.9 (from label-studio)\n",
      "  Downloading humansignal_drf_yasg-1.21.9-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting jsonschema==3.2.0 (from label-studio)\n",
      "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting label-studio-converter==0.0.57 (from label-studio)\n",
      "  Downloading label_studio_converter-0.0.57-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting launchdarkly-server-sdk==7.5.0 (from label-studio)\n",
      "  Downloading launchdarkly-server-sdk-7.5.0.tar.gz (110 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.6/110.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting lockfile>=0.12.0 (from label-studio)\n",
      "  Downloading lockfile-0.12.2-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting lxml>=4.2.5 (from label-studio)\n",
      "  Downloading lxml-5.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.24.3 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.11/site-packages (from label-studio) (1.26.4)\n",
      "Collecting ordered-set==4.0.2 (from label-studio)\n",
      "  Downloading ordered-set-4.0.2.tar.gz (10 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pandas>=0.24.0 (from label-studio)\n",
      "  Using cached pandas-2.2.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Collecting psycopg2-binary==2.9.6 (from label-studio)\n",
      "  Downloading psycopg2_binary-2.9.6-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.4 kB)\n",
      "Collecting pydantic<=1.11.0,>=1.7.3 (from label-studio)\n",
      "  Downloading pydantic-1.10.14-cp311-cp311-macosx_11_0_arm64.whl.metadata (150 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.2/150.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.11/site-packages (from label-studio) (2.9.0.post0)\n",
      "Collecting python-json-logger==2.0.4 (from label-studio)\n",
      "  Downloading python_json_logger-2.0.4-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting pytz<2023.0,>=2022.1 (from label-studio)\n",
      "  Downloading pytz-2022.7.1-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.11/site-packages (from label-studio) (6.0.1)\n",
      "Collecting redis<4.0,>=3.5 (from label-studio)\n",
      "  Downloading redis-3.5.3-py2.py3-none-any.whl.metadata (36 kB)\n",
      "Requirement already satisfied: requests==2.31.0 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.11/site-packages (from label-studio) (2.31.0)\n",
      "Collecting rq==1.10.1 (from label-studio)\n",
      "  Downloading rq-1.10.1-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting rules==2.2 (from label-studio)\n",
      "  Downloading rules-2.2.tar.gz (53 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting sentry-sdk>=1.1.0 (from label-studio)\n",
      "  Downloading sentry_sdk-1.41.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting ujson>=3.0.0 (from label-studio)\n",
      "  Downloading ujson-5.9.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.7 kB)\n",
      "Collecting urllib3<2.0.0,>=1.26.18 (from label-studio)\n",
      "  Using cached urllib3-1.26.18-py2.py3-none-any.whl.metadata (48 kB)\n",
      "Collecting wheel<=0.40.0,>=0.38.1 (from label-studio)\n",
      "  Downloading wheel-0.40.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting xmljson==0.2.0 (from label-studio)\n",
      "  Downloading xmljson-0.2.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: six in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.11/site-packages (from django-annoying==0.10.6->label-studio) (1.16.0)\n",
      "Collecting sqlparse>=0.2.0 (from django-debug-toolbar==3.2.1->label-studio)\n",
      "  Downloading sqlparse-0.4.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting user-agents (from django-user-agents==0.4.0->label-studio)\n",
      "  Downloading user_agents-2.2.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting pyrsistent>=0.14.0 (from jsonschema==3.2.0->label-studio)\n",
      "  Downloading pyrsistent-0.20.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (27 kB)\n",
      "Requirement already satisfied: setuptools in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.11/site-packages (from jsonschema==3.2.0->label-studio) (68.2.2)\n",
      "Collecting Pillow>=10.0.1 (from label-studio-converter==0.0.57->label-studio)\n",
      "  Using cached pillow-10.2.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.7 kB)\n",
      "Collecting nltk==3.6.7 (from label-studio-converter==0.0.57->label-studio)\n",
      "  Downloading nltk-3.6.7-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting label-studio-tools>=0.0.3 (from label-studio-converter==0.0.57->label-studio)\n",
      "  Downloading label_studio_tools-0.0.3-py3-none-any.whl.metadata (566 bytes)\n",
      "Collecting ijson~=3.2.0.post0 (from label-studio-converter==0.0.57->label-studio)\n",
      "  Downloading ijson-3.2.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: certifi>=2018.4.16 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.11/site-packages (from launchdarkly-server-sdk==7.5.0->label-studio) (2024.2.2)\n",
      "Collecting expiringdict>=1.1.4 (from launchdarkly-server-sdk==7.5.0->label-studio)\n",
      "  Downloading expiringdict-1.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting pyRFC3339>=1.0 (from launchdarkly-server-sdk==7.5.0->label-studio)\n",
      "  Downloading pyRFC3339-1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting semver<3.0.0,>=2.10.2 (from launchdarkly-server-sdk==7.5.0->label-studio)\n",
      "  Downloading semver-2.13.0-py2.py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.11/site-packages (from requests==2.31.0->label-studio) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.11/site-packages (from requests==2.31.0->label-studio) (3.6)\n",
      "Collecting click>=5.0.0 (from rq==1.10.1->label-studio)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk==3.6.7->label-studio-converter==0.0.57->label-studio)\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.11/site-packages (from nltk==3.6.7->label-studio-converter==0.0.57->label-studio) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.11/site-packages (from nltk==3.6.7->label-studio-converter==0.0.57->label-studio) (4.66.2)\n",
      "Collecting azure-core<2.0.0,>=1.28.0 (from azure-storage-blob>=12.6.0->label-studio)\n",
      "  Downloading azure_core-1.30.1-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting cryptography>=2.1.4 (from azure-storage-blob>=12.6.0->label-studio)\n",
      "  Downloading cryptography-42.0.5-cp39-abi3-macosx_10_12_universal2.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.11/site-packages (from azure-storage-blob>=12.6.0->label-studio) (4.10.0)\n",
      "Collecting isodate>=0.6.1 (from azure-storage-blob>=12.6.0->label-studio)\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl.metadata (9.6 kB)\n",
      "Collecting webencodings (from bleach<5.1.0,>=5.0.0->label-studio)\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0.0,>=1.28.58->label-studio)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2.0.0,>=1.28.58->label-studio)\n",
      "  Using cached s3transfer-0.10.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting asgiref<4,>=3.3.2 (from Django<3.3.0,>=3.2.23->label-studio)\n",
      "  Using cached asgiref-3.7.2-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting google-auth<3.0dev,>=2.26.1 (from google-cloud-storage<3.0.0,>=2.13.0->label-studio)\n",
      "  Downloading google_auth-2.28.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-api-core<3.0.0dev,>=2.15.0 (from google-cloud-storage<3.0.0,>=2.13.0->label-studio)\n",
      "  Downloading google_api_core-2.17.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-cloud-core<3.0dev,>=2.3.0 (from google-cloud-storage<3.0.0,>=2.13.0->label-studio)\n",
      "  Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-resumable-media>=2.6.0 (from google-cloud-storage<3.0.0,>=2.13.0->label-studio)\n",
      "  Downloading google_resumable_media-2.7.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage<3.0.0,>=2.13.0->label-studio)\n",
      "  Downloading google_crc32c-1.5.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (2.3 kB)\n",
      "Collecting inflection>=0.3.1 (from humansignal-drf-yasg>=1.21.9->label-studio)\n",
      "  Downloading inflection-0.5.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: packaging>=21.0 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.11/site-packages (from humansignal-drf-yasg>=1.21.9->label-studio) (23.2)\n",
      "Collecting uritemplate>=3.0.0 (from humansignal-drf-yasg>=1.21.9->label-studio)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=0.24.0->label-studio)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting cffi>=1.12 (from cryptography>=2.1.4->azure-storage-blob>=12.6.0->label-studio)\n",
      "  Using cached cffi-1.16.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (1.5 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage<3.0.0,>=2.13.0->label-studio)\n",
      "  Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage<3.0.0,>=2.13.0->label-studio)\n",
      "  Using cached protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0dev,>=2.26.1->google-cloud-storage<3.0.0,>=2.13.0->label-studio)\n",
      "  Downloading cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0dev,>=2.26.1->google-cloud-storage<3.0.0,>=2.13.0->label-studio)\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0dev,>=2.26.1->google-cloud-storage<3.0.0,>=2.13.0->label-studio)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting ua-parser>=0.10.0 (from user-agents->django-user-agents==0.4.0->label-studio)\n",
      "  Downloading ua_parser-0.18.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pycparser (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob>=12.6.0->label-studio)\n",
      "  Downloading pycparser-2.21-py2.py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.26.1->google-cloud-storage<3.0.0,>=2.13.0->label-studio)\n",
      "  Using cached pyasn1-0.5.1-py2.py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading label_studio-1.11.0-py3-none-any.whl (81.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading django_annoying-0.10.6-py2.py3-none-any.whl (9.5 kB)\n",
      "Downloading django_cors_headers-3.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading django_csp-3.7-py2.py3-none-any.whl (17 kB)\n",
      "Downloading django_debug_toolbar-3.2.1-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading django_environ-0.10.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading django_extensions-3.1.0-py3-none-any.whl (222 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.0/222.0 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading django_filter-2.4.0-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading django_model_utils-4.1.1-py3-none-any.whl (32 kB)\n",
      "Downloading django_rq-2.5.1-py2.py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.3/48.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading django_storages-1.12.3-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading django_user_agents-0.4.0-py3-none-any.whl (8.6 kB)\n",
      "Downloading djangorestframework-3.13.1-py3-none-any.whl (958 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.3/958.3 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading drf_dynamic_fields-0.3.0-py2.py3-none-any.whl (6.6 kB)\n",
      "Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading label_studio_converter-0.0.57-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading psycopg2_binary-2.9.6-cp311-cp311-macosx_11_0_arm64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_json_logger-2.0.4-py3-none-any.whl (7.8 kB)\n",
      "Downloading rq-1.10.1-py2.py3-none-any.whl (70 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xmljson-0.2.0-py2.py3-none-any.whl (14 kB)\n",
      "Downloading nltk-3.6.7-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading azure_storage_blob-12.19.1-py3-none-any.whl (394 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.5/394.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bleach-5.0.1-py3-none-any.whl (160 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.9/160.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading boto-2.49.0-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading boto3-1.34.60-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.34.60-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading boxing-0.1.4-py3-none-any.whl (3.9 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Downloading Django-3.2.25-py3-none-any.whl (7.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_storage-2.15.0-py2.py3-none-any.whl (123 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading humansignal_drf_yasg-1.21.9-py3-none-any.whl (4.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading lockfile-0.12.2-py2.py3-none-any.whl (13 kB)\n",
      "Downloading lxml-5.1.0-cp311-cp311-macosx_11_0_arm64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pandas-2.2.1-cp311-cp311-macosx_11_0_arm64.whl (11.3 MB)\n",
      "Downloading pydantic-1.10.14-cp311-cp311-macosx_11_0_arm64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.4/499.4 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading redis-3.5.3-py2.py3-none-any.whl (72 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.1/72.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentry_sdk-1.41.0-py2.py3-none-any.whl (258 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.8/258.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ujson-5.9.0-cp311-cp311-macosx_11_0_arm64.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.1/54.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
      "Downloading wheel-0.40.0-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached asgiref-3.7.2-py3-none-any.whl (24 kB)\n",
      "Downloading azure_core-1.30.1-py3-none-any.whl (193 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.4/193.4 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading cryptography-42.0.5-cp39-abi3-macosx_10_12_universal2.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading expiringdict-1.2.2-py3-none-any.whl (8.5 kB)\n",
      "Downloading google_api_core-2.17.1-py3-none-any.whl (137 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.0/137.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.28.2-py2.py3-none-any.whl (186 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.9/186.9 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
      "Downloading google_crc32c-1.5.0-cp311-cp311-macosx_10_9_universal2.whl (32 kB)\n",
      "Downloading google_resumable_media-2.7.0-py2.py3-none-any.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ijson-3.2.3-cp311-cp311-macosx_11_0_arm64.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.1/54.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading inflection-0.5.1-py2.py3-none-any.whl (9.5 kB)\n",
      "Using cached isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading label_studio_tools-0.0.3-py3-none-any.whl (14 kB)\n",
      "Using cached pillow-10.2.0-cp311-cp311-macosx_11_0_arm64.whl (3.3 MB)\n",
      "Downloading pyRFC3339-1.1-py2.py3-none-any.whl (5.7 kB)\n",
      "Downloading pyrsistent-0.20.0-cp311-cp311-macosx_10_9_universal2.whl (83 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached s3transfer-0.10.0-py3-none-any.whl (82 kB)\n",
      "Downloading semver-2.13.0-py2.py3-none-any.whl (12 kB)\n",
      "Downloading sqlparse-0.4.4-py3-none-any.whl (41 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading user_agents-2.2.0-py3-none-any.whl (9.6 kB)\n",
      "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Downloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Using cached cffi-1.16.0-cp311-cp311-macosx_11_0_arm64.whl (176 kB)\n",
      "Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.1/229.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading ua_parser-0.18.0-py2.py3-none-any.whl (38 kB)\n",
      "Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Using cached pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "Building wheels for collected packages: attr, drf-flex-fields, drf-generators, htmlmin, launchdarkly-server-sdk, ordered-set, rules, django-ranged-fileresponse\n",
      "  Building wheel for attr (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for attr: filename=attr-0.3.1-py3-none-any.whl size=2443 sha256=ef72c92470a6cce4a0f396ed27f6c3617297cc880788f187ac9c482b1b97615d\n",
      "  Stored in directory: /Users/mzihayat/Library/Caches/pip/wheels/99/78/34/c9ccebf90ce79b2bd421622108ab849f3669e943257245c315\n",
      "  Building wheel for drf-flex-fields (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for drf-flex-fields: filename=drf_flex_fields-0.9.5-py3-none-any.whl size=14424 sha256=1832847dc678c1744de091e33e583937ba8588fa5a3213d7dc2906f5822734a0\n",
      "  Stored in directory: /Users/mzihayat/Library/Caches/pip/wheels/cb/7a/1c/464c77f394a1d65be212cda616e0e47655f17e80780eac7e14\n",
      "  Building wheel for drf-generators (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for drf-generators: filename=drf_generators-0.3.0-py2.py3-none-any.whl size=9772 sha256=1c794db822a39881139d2422597018198fdcb00562620098b5a069570e0596c3\n",
      "  Stored in directory: /Users/mzihayat/Library/Caches/pip/wheels/12/70/4f/1288a8b5537b011a49bd4f69a9b059edd90fd6e0bc9444ff3e\n",
      "  Building wheel for htmlmin (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27080 sha256=df59f04aba31297953248bf6b999152e520144f8447a550372193c2fd5ab7289\n",
      "  Stored in directory: /Users/mzihayat/Library/Caches/pip/wheels/8d/55/1a/19cd535375ed1ede0c996405ebffe34b196d78e2d9545723a2\n",
      "  Building wheel for launchdarkly-server-sdk (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for launchdarkly-server-sdk: filename=launchdarkly_server_sdk-7.5.0-py3-none-any.whl size=140852 sha256=e0d07e0c85bce2271a732e05ef9dac91dfc78aff0b2d041f39f2c73dcc2e3402\n",
      "  Stored in directory: /Users/mzihayat/Library/Caches/pip/wheels/97/75/a5/e75b44501f8c2fa342846504acbb6d8316299607eb270eaa18\n",
      "  Building wheel for ordered-set (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ordered-set: filename=ordered_set-4.0.2-py2.py3-none-any.whl size=8216 sha256=57de8893ba186d8e3e5784a4d71f81f290288b46c1daad8c98b4543676db7fec\n",
      "  Stored in directory: /Users/mzihayat/Library/Caches/pip/wheels/97/5e/d1/2802f182608830c125f5b3fcd8da4eac788f9156ad92f56b8f\n",
      "  Building wheel for rules (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rules: filename=rules-2.2-py2.py3-none-any.whl size=25814 sha256=3b44e5e889d823be688a4f65a2d37bd3f285169d16a2ebb838ccc5b0305e5398\n",
      "  Stored in directory: /Users/mzihayat/Library/Caches/pip/wheels/3b/2e/a5/cf01ed713e0ab9f40de9da50219097995dc9df09b6f71556c2\n",
      "  Building wheel for django-ranged-fileresponse (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for django-ranged-fileresponse: filename=django_ranged_fileresponse-0.1.2-py3-none-any.whl size=3226 sha256=94e2dea792369e543d9f66b33347e3f8359d0c72efee00c83116d7083e5ed17e\n",
      "  Stored in directory: /Users/mzihayat/Library/Caches/pip/wheels/a5/92/f2/1cb67cc203160ca0fc6d4b91db63bf364b82b4b297d2c8dea0\n",
      "Successfully built attr drf-flex-fields drf-generators htmlmin launchdarkly-server-sdk ordered-set rules django-ranged-fileresponse\n",
      "Installing collected packages: xmljson, webencodings, ua-parser, rules, pytz, lockfile, ijson, htmlmin, expiringdict, drf-flex-fields, drf-dynamic-fields, django-ranged-fileresponse, boxing, boto, attr, appdirs, wheel, user-agents, urllib3, uritemplate, ujson, tzdata, sqlparse, semver, redis, python-json-logger, pyrsistent, pyRFC3339, pydantic, pycparser, pyasn1, psycopg2-binary, protobuf, Pillow, ordered-set, lxml, joblib, jmespath, isodate, inflection, google-crc32c, django-extensions, django-environ, defusedxml, colorama, click, cachetools, bleach, asgiref, sentry-sdk, rsa, rq, pyasn1-modules, pandas, nltk, launchdarkly-server-sdk, label-studio-tools, jsonschema, googleapis-common-protos, google-resumable-media, Django, cffi, botocore, s3transfer, label-studio-converter, google-auth, drf-generators, djangorestframework, django-user-agents, django-storages, django-rq, django-model-utils, django-filter, django-debug-toolbar, django-csp, django-cors-headers, django-annoying, cryptography, azure-core, humansignal-drf-yasg, google-api-core, boto3, azure-storage-blob, google-cloud-core, google-cloud-storage, label-studio\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.1\n",
      "    Uninstalling urllib3-2.2.1:\n",
      "      Successfully uninstalled urllib3-2.2.1\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.6.3\n",
      "    Uninstalling pydantic-2.6.3:\n",
      "      Successfully uninstalled pydantic-2.6.3\n",
      "Successfully installed Django-3.2.25 Pillow-10.2.0 appdirs-1.4.4 asgiref-3.7.2 attr-0.3.1 azure-core-1.30.1 azure-storage-blob-12.19.1 bleach-5.0.1 boto-2.49.0 boto3-1.34.60 botocore-1.34.60 boxing-0.1.4 cachetools-5.3.3 cffi-1.16.0 click-8.1.7 colorama-0.4.6 cryptography-42.0.5 defusedxml-0.7.1 django-annoying-0.10.6 django-cors-headers-3.6.0 django-csp-3.7 django-debug-toolbar-3.2.1 django-environ-0.10.0 django-extensions-3.1.0 django-filter-2.4.0 django-model-utils-4.1.1 django-ranged-fileresponse-0.1.2 django-rq-2.5.1 django-storages-1.12.3 django-user-agents-0.4.0 djangorestframework-3.13.1 drf-dynamic-fields-0.3.0 drf-flex-fields-0.9.5 drf-generators-0.3.0 expiringdict-1.2.2 google-api-core-2.17.1 google-auth-2.28.2 google-cloud-core-2.4.1 google-cloud-storage-2.15.0 google-crc32c-1.5.0 google-resumable-media-2.7.0 googleapis-common-protos-1.63.0 htmlmin-0.1.12 humansignal-drf-yasg-1.21.9 ijson-3.2.3 inflection-0.5.1 isodate-0.6.1 jmespath-1.0.1 joblib-1.3.2 jsonschema-3.2.0 label-studio-1.11.0 label-studio-converter-0.0.57 label-studio-tools-0.0.3 launchdarkly-server-sdk-7.5.0 lockfile-0.12.2 lxml-5.1.0 nltk-3.6.7 ordered-set-4.0.2 pandas-2.2.1 protobuf-4.25.3 psycopg2-binary-2.9.6 pyRFC3339-1.1 pyasn1-0.5.1 pyasn1-modules-0.3.0 pycparser-2.21 pydantic-1.10.14 pyrsistent-0.20.0 python-json-logger-2.0.4 pytz-2022.7.1 redis-3.5.3 rq-1.10.1 rsa-4.9 rules-2.2 s3transfer-0.10.0 semver-2.13.0 sentry-sdk-1.41.0 sqlparse-0.4.4 tzdata-2024.1 ua-parser-0.18.0 ujson-5.9.0 uritemplate-4.1.1 urllib3-1.26.18 user-agents-2.2.0 webencodings-0.5.1 wheel-0.40.0 xmljson-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install label-studio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Database and media directory: /Users/mzihayat/Library/Application Support/label-studio\n",
      "=> Static URL is set to: /static/\n",
      "=> Database and media directory: /Users/mzihayat/Library/Application Support/label-studio\n",
      "=> Static URL is set to: /static/\n",
      "/Users/mzihayat/Library/Application Support/label-studio/.env not found - if you're not configuring your environment separately, check this.\n",
      "get 'SECRET_KEY' casted as '<class 'str'>' with default ''\n",
      "Warning: SECRET_KEY not found in environment variables. Will generate a random key.\n",
      "[Tracing] Create new propagation context: {'trace_id': 'ff1eec1fbdc946d6a32c671316f78a95', 'span_id': '8f3411b48cc99345', 'parent_span_id': None, 'dynamic_sampling_context': None}\n",
      "Starting new HTTPS connection (1): pypi.org:443\n",
      "https://pypi.org:443 \"GET /pypi/label-studio/json HTTP/1.1\" 200 31429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing database..\n",
      "Performing system checks...\n",
      "\n",
      "System check identified no issues (1 silenced).\n",
      "March 11, 2024 - 21:43:02\n",
      "Django version 3.2.25, using settings 'label_studio.core.settings.label_studio'\n",
      "Starting development server at http://0.0.0.0:8080/\n",
      "Quit the server with CONTROL-C.\n",
      "[2024-03-11 21:43:05,205] [django.server::log_message::161] [INFO] \"GET / HTTP/1.1\" 302 0\n",
      "[2024-03-11 21:43:05,205] [django.server::log_message::161] [INFO] \"GET / HTTP/1.1\" 302 0\n",
      "[2024-03-11 21:43:05,237] [django.server::log_message::161] [INFO] \"GET /user/login/ HTTP/1.1\" 200 5402\n",
      "[2024-03-11 21:43:05,237] [django.server::log_message::161] [INFO] \"GET /user/login/ HTTP/1.1\" 200 5402\n",
      "[2024-03-11 21:43:05,303] [django.server::log_message::161] [INFO] \"GET /static/css/login.8194c7aa01b8.css HTTP/1.1\" 200 6270\n",
      "[2024-03-11 21:43:05,303] [django.server::log_message::161] [INFO] \"GET /static/css/login.8194c7aa01b8.css HTTP/1.1\" 200 6270\n",
      "[2024-03-11 21:43:05,306] [django.server::log_message::161] [INFO] \"GET /static/images/human_signal_logo.97adf6f9a70c.svg HTTP/1.1\" 200 5248\n",
      "[2024-03-11 21:43:05,306] [django.server::log_message::161] [INFO] \"GET /static/images/human_signal_logo.97adf6f9a70c.svg HTTP/1.1\" 200 5248\n",
      "[2024-03-11 21:43:05,315] [django.server::log_message::161] [INFO] \"GET /static/css/main.05101f5b0b98.css HTTP/1.1\" 200 15255\n",
      "[2024-03-11 21:43:05,315] [django.server::log_message::161] [INFO] \"GET /static/css/main.05101f5b0b98.css HTTP/1.1\" 200 15255\n",
      "[2024-03-11 21:43:05,323] [django.server::log_message::161] [INFO] \"GET /static/images/label_studio_logo.9e8d57abe160.svg HTTP/1.1\" 200 19612\n",
      "[2024-03-11 21:43:05,323] [django.server::log_message::161] [INFO] \"GET /static/images/label_studio_logo.9e8d57abe160.svg HTTP/1.1\" 200 19612\n",
      "[2024-03-11 21:43:05,326] [django.server::log_message::161] [INFO] \"GET /react-app/main.css?v=3330c3 HTTP/1.1\" 200 73963\n",
      "[2024-03-11 21:43:05,326] [django.server::log_message::161] [INFO] \"GET /react-app/main.css?v=3330c3 HTTP/1.1\" 200 73963\n",
      "[2024-03-11 21:43:05,370] [django.server::log_message::161] [INFO] \"GET /static/images/login-bg.2c7fadf7bd88.svg HTTP/1.1\" 200 529\n",
      "[2024-03-11 21:43:05,370] [django.server::log_message::161] [INFO] \"GET /static/images/login-bg.2c7fadf7bd88.svg HTTP/1.1\" 200 529\n",
      "[2024-03-11 21:43:05,371] [django.server::log_message::161] [INFO] \"GET /static/images/heidi-tip.2e3228516929.svg HTTP/1.1\" 200 39408\n",
      "[2024-03-11 21:43:05,371] [django.server::log_message::161] [INFO] \"GET /static/images/heidi-tip.2e3228516929.svg HTTP/1.1\" 200 39408\n",
      "[2024-03-11 21:43:05,380] [django.server::log_message::161] [INFO] \"GET /static/images/favicon.58c0a5114450.ico HTTP/1.1\" 200 21822\n",
      "[2024-03-11 21:43:05,380] [django.server::log_message::161] [INFO] \"GET /static/images/favicon.58c0a5114450.ico HTTP/1.1\" 200 21822\n",
      "[2024-03-11 21:43:05,798] [django.server::log_message::161] [INFO] \"GET /static/images/favicon.58c0a5114450.ico HTTP/1.1\" 200 21822\n",
      "[2024-03-11 21:43:05,798] [django.server::log_message::161] [INFO] \"GET /static/images/favicon.58c0a5114450.ico HTTP/1.1\" 200 21822\n",
      "[2024-03-11 21:43:09,292] [django.server::log_message::161] [INFO] \"POST /user/login/?next=/projects/ HTTP/1.1\" 200 5541\n",
      "[2024-03-11 21:43:09,292] [django.server::log_message::161] [INFO] \"POST /user/login/?next=/projects/ HTTP/1.1\" 200 5541\n",
      "[2024-03-11 21:43:09,328] [django.server::log_message::161] [INFO] \"GET /static/css/login.8194c7aa01b8.css HTTP/1.1\" 200 6270\n",
      "[2024-03-11 21:43:09,328] [django.server::log_message::161] [INFO] \"GET /static/css/login.8194c7aa01b8.css HTTP/1.1\" 200 6270\n",
      "[2024-03-11 21:43:09,329] [django.server::log_message::161] [INFO] \"GET /static/css/main.05101f5b0b98.css HTTP/1.1\" 200 15255\n",
      "[2024-03-11 21:43:09,329] [django.server::log_message::161] [INFO] \"GET /static/css/main.05101f5b0b98.css HTTP/1.1\" 200 15255\n",
      "[2024-03-11 21:43:09,339] [django.server::log_message::161] [INFO] \"GET /static/images/human_signal_logo.97adf6f9a70c.svg HTTP/1.1\" 200 5248\n",
      "[2024-03-11 21:43:09,339] [django.server::log_message::161] [INFO] \"GET /static/images/human_signal_logo.97adf6f9a70c.svg HTTP/1.1\" 200 5248\n",
      "[2024-03-11 21:43:09,340] [django.server::log_message::161] [INFO] \"GET /static/images/label_studio_logo.9e8d57abe160.svg HTTP/1.1\" 200 19612\n",
      "[2024-03-11 21:43:09,340] [django.server::log_message::161] [INFO] \"GET /static/images/label_studio_logo.9e8d57abe160.svg HTTP/1.1\" 200 19612\n",
      "[2024-03-11 21:43:09,340] [django.server::log_message::161] [INFO] \"GET /react-app/main.css?v=3330c3 HTTP/1.1\" 200 73963\n",
      "[2024-03-11 21:43:09,340] [django.server::log_message::161] [INFO] \"GET /react-app/main.css?v=3330c3 HTTP/1.1\" 200 73963\n",
      "[2024-03-11 21:43:09,358] [django.server::log_message::161] [INFO] \"GET /static/images/favicon.58c0a5114450.ico HTTP/1.1\" 200 21822\n",
      "[2024-03-11 21:43:09,358] [django.server::log_message::161] [INFO] \"GET /static/images/favicon.58c0a5114450.ico HTTP/1.1\" 200 21822\n",
      "[2024-03-11 21:43:09,365] [django.server::log_message::161] [INFO] \"GET /static/images/login-bg.2c7fadf7bd88.svg HTTP/1.1\" 200 529\n",
      "[2024-03-11 21:43:09,365] [django.server::log_message::161] [INFO] \"GET /static/images/login-bg.2c7fadf7bd88.svg HTTP/1.1\" 200 529\n",
      "[2024-03-11 21:43:09,366] [django.server::log_message::161] [INFO] \"GET /static/images/heidi-tip.2e3228516929.svg HTTP/1.1\" 200 39408\n",
      "[2024-03-11 21:43:09,366] [django.server::log_message::161] [INFO] \"GET /static/images/heidi-tip.2e3228516929.svg HTTP/1.1\" 200 39408\n",
      "[2024-03-11 21:43:13,147] [django.server::log_message::161] [INFO] \"POST /user/login/?next=/projects/ HTTP/1.1\" 200 5541\n",
      "[2024-03-11 21:43:13,147] [django.server::log_message::161] [INFO] \"POST /user/login/?next=/projects/ HTTP/1.1\" 200 5541\n",
      "[2024-03-11 21:43:13,193] [django.server::log_message::161] [INFO] \"GET /react-app/main.css?v=3330c3 HTTP/1.1\" 304 0\n",
      "[2024-03-11 21:43:13,193] [django.server::log_message::161] [INFO] \"GET /react-app/main.css?v=3330c3 HTTP/1.1\" 304 0\n",
      "[2024-03-11 21:43:13,194] [django.server::log_message::161] [INFO] \"GET /static/images/label_studio_logo.9e8d57abe160.svg HTTP/1.1\" 304 0\n",
      "[2024-03-11 21:43:13,194] [django.server::log_message::161] [INFO] \"GET /static/images/label_studio_logo.9e8d57abe160.svg HTTP/1.1\" 304 0\n",
      "[2024-03-11 21:43:13,201] [django.server::log_message::161] [INFO] \"GET /static/css/main.05101f5b0b98.css HTTP/1.1\" 304 0\n",
      "[2024-03-11 21:43:13,201] [django.server::log_message::161] [INFO] \"GET /static/css/main.05101f5b0b98.css HTTP/1.1\" 304 0\n",
      "[2024-03-11 21:43:13,202] [django.server::log_message::161] [INFO] \"GET /static/css/login.8194c7aa01b8.css HTTP/1.1\" 304 0\n",
      "[2024-03-11 21:43:13,202] [django.server::log_message::161] [INFO] \"GET /static/css/login.8194c7aa01b8.css HTTP/1.1\" 304 0\n",
      "[2024-03-11 21:43:13,201] [django.server::log_message::161] [INFO] \"GET /static/images/human_signal_logo.97adf6f9a70c.svg HTTP/1.1\" 304 0\n",
      "[2024-03-11 21:43:13,201] [django.server::log_message::161] [INFO] \"GET /static/images/human_signal_logo.97adf6f9a70c.svg HTTP/1.1\" 304 0\n",
      "[2024-03-11 21:43:13,226] [django.server::log_message::161] [INFO] \"GET /static/images/favicon.58c0a5114450.ico HTTP/1.1\" 304 0\n",
      "[2024-03-11 21:43:13,226] [django.server::log_message::161] [INFO] \"GET /static/images/favicon.58c0a5114450.ico HTTP/1.1\" 304 0\n",
      "[2024-03-11 21:43:14,621] [django.server::log_message::161] [INFO] \"GET /user/signup HTTP/1.1\" 200 5977\n",
      "[2024-03-11 21:43:14,621] [django.server::log_message::161] [INFO] \"GET /user/signup HTTP/1.1\" 200 5977\n",
      "[2024-03-11 21:43:14,654] [django.server::log_message::161] [INFO] \"GET /static/images/heidi.a59f20dee6eb.png HTTP/1.1\" 200 6849\n",
      "[2024-03-11 21:43:14,654] [django.server::log_message::161] [INFO] \"GET /static/images/heidi.a59f20dee6eb.png HTTP/1.1\" 200 6849\n",
      "[2024-03-11 21:43:14,684] [django.server::log_message::161] [INFO] \"GET /static/images/favicon.58c0a5114450.ico HTTP/1.1\" 200 21822\n",
      "[2024-03-11 21:43:14,684] [django.server::log_message::161] [INFO] \"GET /static/images/favicon.58c0a5114450.ico HTTP/1.1\" 200 21822\n",
      "[2024-03-11 21:43:15,874] [django.server::log_message::161] [INFO] \"POST /user/signup/?&next=/projects/ HTTP/1.1\" 302 0\n",
      "[2024-03-11 21:43:15,874] [django.server::log_message::161] [INFO] \"POST /user/signup/?&next=/projects/ HTTP/1.1\" 302 0\n",
      "[2024-03-11 21:43:15,884] [django.server::log_message::161] [INFO] \"GET /projects/ HTTP/1.1\" 200 35420\n",
      "[2024-03-11 21:43:15,884] [django.server::log_message::161] [INFO] \"GET /projects/ HTTP/1.1\" 200 35420\n",
      "[2024-03-11 21:43:15,921] [django.server::log_message::161] [INFO] \"GET /static/css/uikit.e49a7a43adbd.css HTTP/1.1\" 200 3892\n",
      "[2024-03-11 21:43:15,921] [django.server::log_message::161] [INFO] \"GET /static/css/uikit.e49a7a43adbd.css HTTP/1.1\" 200 3892\n",
      "[2024-03-11 21:43:15,939] [django.server::log_message::161] [INFO] \"GET /static/css/Toast.min.0479912dd9c5.css HTTP/1.1\" 200 1213\n",
      "[2024-03-11 21:43:15,939] [django.server::log_message::161] [INFO] \"GET /static/css/Toast.min.0479912dd9c5.css HTTP/1.1\" 200 1213\n",
      "[2024-03-11 21:43:15,940] [django.server::log_message::161] [INFO] \"GET /static/fonts/roboto/roboto.css HTTP/1.1\" 200 3431\n",
      "[2024-03-11 21:43:15,940] [django.server::log_message::161] [INFO] \"GET /static/fonts/roboto/roboto.css HTTP/1.1\" 200 3431\n",
      "[2024-03-11 21:43:15,942] [django.server::log_message::161] [INFO] \"GET /static/js/jquery.min.e6c2415c0ace.js HTTP/1.1\" 200 87462\n",
      "[2024-03-11 21:43:15,942] [django.server::log_message::161] [INFO] \"GET /static/js/jquery.min.e6c2415c0ace.js HTTP/1.1\" 200 87462\n",
      "[2024-03-11 21:43:15,942] [django.server::log_message::161] [INFO] \"GET /static/js/helpers.9a01b074ff58.js HTTP/1.1\" 200 13336\n",
      "[2024-03-11 21:43:15,942] [django.server::log_message::161] [INFO] \"GET /static/js/helpers.9a01b074ff58.js HTTP/1.1\" 200 13336\n",
      "[2024-03-11 21:43:15,943] [django.server::log_message::161] [INFO] \"GET /static/js/Toast.min.9135be1633df.js HTTP/1.1\" 200 2371\n",
      "[2024-03-11 21:43:15,943] [django.server::log_message::161] [INFO] \"GET /static/js/Toast.min.9135be1633df.js HTTP/1.1\" 200 2371\n",
      "[2024-03-11 21:43:15,950] [django.server::log_message::161] [INFO] \"GET /react-app/main.js?v=3330c3 HTTP/1.1\" 200 1181765\n",
      "[2024-03-11 21:43:15,950] [django.server::log_message::161] [INFO] \"GET /react-app/main.js?v=3330c3 HTTP/1.1\" 200 1181765\n",
      "[2024-03-11 21:43:16,015] [django.server::log_message::161] [INFO] \"GET /api/projects?page=1&page_size=30&include=id%2Ctitle%2Ccreated_by%2Ccreated_at%2Ccolor%2Cis_published%2Cassignment_settings HTTP/1.1\" 200 52\n",
      "[2024-03-11 21:43:16,015] [django.server::log_message::161] [INFO] \"GET /api/projects?page=1&page_size=30&include=id%2Ctitle%2Ccreated_by%2Ccreated_at%2Ccolor%2Cis_published%2Cassignment_settings HTTP/1.1\" 200 52\n",
      "[2024-03-11 21:43:16,016] [django.server::log_message::161] [INFO] \"GET /api/version HTTP/1.1\" 200 562\n",
      "[2024-03-11 21:43:16,016] [django.server::log_message::161] [INFO] \"GET /api/version HTTP/1.1\" 200 562\n",
      "[2024-03-11 21:43:16,016] [django.server::log_message::161] [INFO] \"GET /static/icons/logo-black.svg HTTP/1.1\" 200 10236\n",
      "[2024-03-11 21:43:16,016] [django.server::log_message::161] [INFO] \"GET /static/icons/logo-black.svg HTTP/1.1\" 200 10236\n",
      "[2024-03-11 21:43:16,021] [django.server::log_message::161] [INFO] \"GET /static/fonts/roboto/roboto-v20-latin_cyrillic-500.woff2 HTTP/1.1\" 200 22880\n",
      "[2024-03-11 21:43:16,021] [django.server::log_message::161] [INFO] \"GET /static/fonts/roboto/roboto-v20-latin_cyrillic-500.woff2 HTTP/1.1\" 200 22880\n",
      "[2024-03-11 21:43:16,025] [django.server::log_message::161] [INFO] \"GET /sw.js HTTP/1.1\" 200 6086\n",
      "[2024-03-11 21:43:16,025] [django.server::log_message::161] [INFO] \"GET /sw.js HTTP/1.1\" 200 6086\n",
      "[2024-03-11 21:43:16,035] [django.server::log_message::161] [INFO] \"GET /static/images/opossum_looking.png HTTP/1.1\" 200 105719\n",
      "[2024-03-11 21:43:16,035] [django.server::log_message::161] [INFO] \"GET /static/images/opossum_looking.png HTTP/1.1\" 200 105719\n",
      "[2024-03-11 21:43:16,038] [django.server::log_message::161] [INFO] \"GET /static/fonts/roboto/roboto-v20-latin_cyrillic-regular.woff2 HTTP/1.1\" 200 22428\n",
      "[2024-03-11 21:43:16,038] [django.server::log_message::161] [INFO] \"GET /static/fonts/roboto/roboto-v20-latin_cyrillic-regular.woff2 HTTP/1.1\" 200 22428\n",
      "[2024-03-11 21:43:18,534] [django.server::log_message::161] [INFO] \"GET /api/projects HTTP/1.1\" 200 52\n",
      "[2024-03-11 21:43:18,534] [django.server::log_message::161] [INFO] \"GET /api/projects HTTP/1.1\" 200 52\n",
      "[2024-03-11 21:43:18,564] [django.server::log_message::161] [INFO] \"POST /api/projects HTTP/1.1\" 201 1243\n",
      "[2024-03-11 21:43:18,564] [django.server::log_message::161] [INFO] \"POST /api/projects HTTP/1.1\" 201 1243\n",
      "[2024-03-11 21:43:18,580] [django.server::log_message::161] [INFO] \"GET /api/projects/1/file-uploads HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:43:18,580] [django.server::log_message::161] [INFO] \"GET /api/projects/1/file-uploads HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:43:29,363] [django.server::log_message::161] [INFO] \"PATCH /api/projects/1 HTTP/1.1\" 200 1231\n",
      "[2024-03-11 21:43:29,363] [django.server::log_message::161] [INFO] \"PATCH /api/projects/1 HTTP/1.1\" 200 1231\n",
      "[2024-03-11 21:43:29,407] [django.server::log_message::161] [INFO] \"POST /api/projects/1/reimport HTTP/1.1\" 200 129\n",
      "[2024-03-11 21:43:29,407] [django.server::log_message::161] [INFO] \"POST /api/projects/1/reimport HTTP/1.1\" 200 129\n",
      "[2024-03-11 21:43:29,424] [core.label_config::parse_config::52] [WARNING] Using deprecated method - switch to label_studio.tools.label_config.parse_config!\n",
      "[2024-03-11 21:43:29,425] [core.label_config::parse_config::52] [WARNING] Using deprecated method - switch to label_studio.tools.label_config.parse_config!\n",
      "[2024-03-11 21:43:29,449] [django.server::log_message::161] [INFO] \"PATCH /api/projects/1 HTTP/1.1\" 200 1231\n",
      "[2024-03-11 21:43:29,449] [django.server::log_message::161] [INFO] \"PATCH /api/projects/1 HTTP/1.1\" 200 1231\n",
      "[2024-03-11 21:43:29,570] [django.server::log_message::161] [INFO] \"GET /dm/main.css?v=3330c3 HTTP/1.1\" 200 75052\n",
      "[2024-03-11 21:43:29,570] [django.server::log_message::161] [INFO] \"GET /dm/main.css?v=3330c3 HTTP/1.1\" 200 75052\n",
      "[2024-03-11 21:43:29,576] [django.server::log_message::161] [INFO] \"GET /api/projects/1 HTTP/1.1\" 200 1231\n",
      "[2024-03-11 21:43:29,576] [django.server::log_message::161] [INFO] \"GET /api/projects/1 HTTP/1.1\" 200 1231\n",
      "[2024-03-11 21:43:29,601] [django.server::log_message::161] [INFO] \"GET /dm/main.js?v=3330c3 HTTP/1.1\" 200 1497261\n",
      "[2024-03-11 21:43:29,601] [django.server::log_message::161] [INFO] \"GET /dm/main.js?v=3330c3 HTTP/1.1\" 200 1497261\n",
      "[2024-03-11 21:43:29,603] [django.server::log_message::161] [INFO] \"GET /label-studio-frontend/main.css?v=3330c3 HTTP/1.1\" 200 2009455\n",
      "[2024-03-11 21:43:29,603] [django.server::log_message::161] [INFO] \"GET /label-studio-frontend/main.css?v=3330c3 HTTP/1.1\" 200 2009455\n",
      "[2024-03-11 21:43:29,608] [django.server::log_message::161] [INFO] \"GET /label-studio-frontend/main.js?v=3330c3 HTTP/1.1\" 200 3716703\n",
      "[2024-03-11 21:43:29,608] [django.server::log_message::161] [INFO] \"GET /label-studio-frontend/main.js?v=3330c3 HTTP/1.1\" 200 3716703\n",
      "[2024-03-11 21:43:29,748] [django.server::log_message::161] [INFO] \"GET /api/ml?project=1 HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:43:29,748] [django.server::log_message::161] [INFO] \"GET /api/ml?project=1 HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:43:29,759] [django.server::log_message::161] [INFO] \"GET /api/dm/columns?project=1 HTTP/1.1\" 200 4075\n",
      "[2024-03-11 21:43:29,759] [django.server::log_message::161] [INFO] \"GET /api/dm/columns?project=1 HTTP/1.1\" 200 4075\n",
      "[2024-03-11 21:43:29,807] [django.server::log_message::161] [INFO] \"GET /api/users?project=1 HTTP/1.1\" 200 228\n",
      "[2024-03-11 21:43:29,807] [django.server::log_message::161] [INFO] \"GET /api/users?project=1 HTTP/1.1\" 200 228\n",
      "[2024-03-11 21:43:29,807] [django.server::log_message::161] [INFO] \"GET /api/dm/actions?project=1 HTTP/1.1\" 200 1537\n",
      "[2024-03-11 21:43:29,807] [django.server::log_message::161] [INFO] \"GET /api/dm/actions?project=1 HTTP/1.1\" 200 1537\n",
      "[2024-03-11 21:43:29,807] [django.server::log_message::161] [INFO] \"GET /api/dm/views?project=1 HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:43:29,807] [django.server::log_message::161] [INFO] \"GET /api/dm/views?project=1 HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:43:29,813] [django.server::log_message::161] [INFO] \"GET /api/dm/project?project=1 HTTP/1.1\" 200 1415\n",
      "[2024-03-11 21:43:29,813] [django.server::log_message::161] [INFO] \"GET /api/dm/project?project=1 HTTP/1.1\" 200 1415\n",
      "[2024-03-11 21:43:29,824] [django.server::log_message::161] [INFO] \"POST /api/dm/views?tabID=0&project=1 HTTP/1.1\" 201 963\n",
      "[2024-03-11 21:43:29,824] [django.server::log_message::161] [INFO] \"POST /api/dm/views?tabID=0&project=1 HTTP/1.1\" 201 963\n",
      "[2024-03-11 21:43:29,889] [django.server::log_message::161] [INFO] \"GET /api/tasks?page=1&page_size=30&view=1&project=1 HTTP/1.1\" 200 66\n",
      "[2024-03-11 21:43:29,889] [django.server::log_message::161] [INFO] \"GET /api/tasks?page=1&page_size=30&view=1&project=1 HTTP/1.1\" 200 66\n",
      "[2024-03-11 21:43:29,907] [django.server::log_message::161] [INFO] \"GET /api/tasks?page=1&page_size=30&view=1&project=1 HTTP/1.1\" 200 66\n",
      "[2024-03-11 21:43:29,907] [django.server::log_message::161] [INFO] \"GET /api/tasks?page=1&page_size=30&view=1&project=1 HTTP/1.1\" 200 66\n",
      "[2024-03-11 21:43:29,921] [django.server::log_message::161] [INFO] \"GET /api/tasks?page=1&page_size=30&view=1&project=1 HTTP/1.1\" 200 66\n",
      "[2024-03-11 21:43:29,921] [django.server::log_message::161] [INFO] \"GET /api/tasks?page=1&page_size=30&view=1&project=1 HTTP/1.1\" 200 66\n",
      "[2024-03-11 21:43:55,125] [django.server::log_message::161] [INFO] \"GET /api/projects/1/file-uploads HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:43:55,125] [django.server::log_message::161] [INFO] \"GET /api/projects/1/file-uploads HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:43:55,133] [django.server::log_message::161] [INFO] \"GET /api/projects/1 HTTP/1.1\" 200 1231\n",
      "[2024-03-11 21:43:55,133] [django.server::log_message::161] [INFO] \"GET /api/projects/1 HTTP/1.1\" 200 1231\n",
      "[2024-03-11 21:43:55,139] [django.server::log_message::161] [INFO] \"GET /api/projects/1/file-uploads HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:43:55,139] [django.server::log_message::161] [INFO] \"GET /api/projects/1/file-uploads HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:43:55,157] [django.server::log_message::161] [INFO] \"GET /api/projects/1/file-uploads HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:43:55,157] [django.server::log_message::161] [INFO] \"GET /api/projects/1/file-uploads HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:43:55,157] [django.server::log_message::161] [INFO] \"GET /api/projects/1 HTTP/1.1\" 200 1231\n",
      "[2024-03-11 21:43:55,157] [django.server::log_message::161] [INFO] \"GET /api/projects/1 HTTP/1.1\" 200 1231\n",
      "[2024-03-11 21:44:06,729] [django.server::log_message::161] [INFO] \"POST /api/projects/1/import?commit_to_project=false HTTP/1.1\" 201 198\n",
      "[2024-03-11 21:44:06,729] [django.server::log_message::161] [INFO] \"POST /api/projects/1/import?commit_to_project=false HTTP/1.1\" 201 198\n",
      "[2024-03-11 21:44:06,746] [django.server::log_message::161] [INFO] \"GET /api/projects/1/file-uploads?ids=%5B1%5D HTTP/1.1\" 200 59\n",
      "[2024-03-11 21:44:06,746] [django.server::log_message::161] [INFO] \"GET /api/projects/1/file-uploads?ids=%5B1%5D HTTP/1.1\" 200 59\n",
      "[2024-03-11 21:44:14,513] [django.server::log_message::161] [INFO] \"POST /api/projects/1/reimport HTTP/1.1\" 201 162\n",
      "[2024-03-11 21:44:14,513] [django.server::log_message::161] [INFO] \"POST /api/projects/1/reimport HTTP/1.1\" 201 162\n",
      "[2024-03-11 21:44:14,576] [django.server::log_message::161] [INFO] \"GET /api/projects/1 HTTP/1.1\" 200 1244\n",
      "[2024-03-11 21:44:14,576] [django.server::log_message::161] [INFO] \"GET /api/projects/1 HTTP/1.1\" 200 1244\n",
      "[2024-03-11 21:44:14,589] [django.server::log_message::161] [INFO] \"GET /api/ml?project=1 HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:44:14,589] [django.server::log_message::161] [INFO] \"GET /api/ml?project=1 HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:44:14,607] [django.server::log_message::161] [INFO] \"GET /api/dm/columns?project=1 HTTP/1.1\" 200 4252\n",
      "[2024-03-11 21:44:14,607] [django.server::log_message::161] [INFO] \"GET /api/dm/columns?project=1 HTTP/1.1\" 200 4252\n",
      "[2024-03-11 21:44:14,642] [django.server::log_message::161] [INFO] \"GET /api/users?project=1 HTTP/1.1\" 200 228\n",
      "[2024-03-11 21:44:14,642] [django.server::log_message::161] [INFO] \"GET /api/users?project=1 HTTP/1.1\" 200 228\n",
      "[2024-03-11 21:44:14,648] [django.server::log_message::161] [INFO] \"GET /api/dm/project?project=1 HTTP/1.1\" 200 1428\n",
      "[2024-03-11 21:44:14,648] [django.server::log_message::161] [INFO] \"GET /api/dm/project?project=1 HTTP/1.1\" 200 1428\n",
      "[2024-03-11 21:44:14,653] [django.server::log_message::161] [INFO] \"GET /api/dm/views?project=1 HTTP/1.1\" 200 965\n",
      "[2024-03-11 21:44:14,653] [django.server::log_message::161] [INFO] \"GET /api/dm/views?project=1 HTTP/1.1\" 200 965\n",
      "[2024-03-11 21:44:14,653] [django.server::log_message::161] [INFO] \"GET /api/dm/actions?project=1 HTTP/1.1\" 200 1550\n",
      "[2024-03-11 21:44:14,653] [django.server::log_message::161] [INFO] \"GET /api/dm/actions?project=1 HTTP/1.1\" 200 1550\n",
      "[2024-03-11 21:44:14,711] [django.server::log_message::161] [INFO] \"GET /api/tasks?page=1&page_size=30&view=1&project=1 HTTP/1.1\" 200 3150\n",
      "[2024-03-11 21:44:14,711] [django.server::log_message::161] [INFO] \"GET /api/tasks?page=1&page_size=30&view=1&project=1 HTTP/1.1\" 200 3150\n",
      "[2024-03-11 21:44:21,551] [django.server::log_message::161] [INFO] \"PATCH /api/dm/views/1?project=1 HTTP/1.1\" 200 985\n",
      "[2024-03-11 21:44:21,551] [django.server::log_message::161] [INFO] \"PATCH /api/dm/views/1?project=1 HTTP/1.1\" 200 985\n",
      "[2024-03-11 21:44:21,592] [django.server::log_message::161] [INFO] \"GET /api/tasks?page=1&page_size=30&view=1&project=1 HTTP/1.1\" 200 3150\n",
      "[2024-03-11 21:44:21,592] [django.server::log_message::161] [INFO] \"GET /api/tasks?page=1&page_size=30&view=1&project=1 HTTP/1.1\" 200 3150\n",
      "[2024-03-11 21:44:37,175] [django.server::log_message::161] [INFO] \"GET /api/projects/1/summary HTTP/1.1\" 200 189\n",
      "[2024-03-11 21:44:37,175] [django.server::log_message::161] [INFO] \"GET /api/projects/1/summary HTTP/1.1\" 200 189\n",
      "[2024-03-11 21:44:37,177] [django.server::log_message::161] [INFO] \"GET /api/projects/1 HTTP/1.1\" 200 1244\n",
      "[2024-03-11 21:44:37,177] [django.server::log_message::161] [INFO] \"GET /api/projects/1 HTTP/1.1\" 200 1244\n",
      "[2024-03-11 21:44:37,195] [core.label_config::parse_config::52] [WARNING] Using deprecated method - switch to label_studio.tools.label_config.parse_config!\n",
      "[2024-03-11 21:44:37,197] [django.server::log_message::161] [INFO] \"GET /api/projects/1/summary HTTP/1.1\" 200 189\n",
      "[2024-03-11 21:44:37,197] [django.server::log_message::161] [INFO] \"GET /api/projects/1/summary HTTP/1.1\" 200 189\n",
      "[2024-03-11 21:44:37,198] [core.label_config::parse_config::52] [WARNING] Using deprecated method - switch to label_studio.tools.label_config.parse_config!\n",
      "[2024-03-11 21:44:37,219] [django.server::log_message::161] [INFO] \"POST /api/projects/1/validate HTTP/1.1\" 200 42\n",
      "[2024-03-11 21:44:37,219] [django.server::log_message::161] [INFO] \"POST /api/projects/1/validate HTTP/1.1\" 200 42\n",
      "[2024-03-11 21:44:37,232] [django.server::log_message::161] [INFO] \"GET /api/projects/1/summary HTTP/1.1\" 200 189\n",
      "[2024-03-11 21:44:37,232] [django.server::log_message::161] [INFO] \"GET /api/projects/1/summary HTTP/1.1\" 200 189\n",
      "[2024-03-11 21:44:37,236] [django.server::log_message::161] [INFO] \"GET /api/projects/1 HTTP/1.1\" 200 1244\n",
      "[2024-03-11 21:44:37,236] [django.server::log_message::161] [INFO] \"GET /api/projects/1 HTTP/1.1\" 200 1244\n",
      "[2024-03-11 21:44:37,256] [django.server::log_message::161] [INFO] \"GET /api/projects/1/summary HTTP/1.1\" 200 189\n",
      "[2024-03-11 21:44:37,256] [django.server::log_message::161] [INFO] \"GET /api/projects/1/summary HTTP/1.1\" 200 189\n",
      "[2024-03-11 21:44:37,273] [django.server::log_message::161] [INFO] \"POST /api/projects/1/sample-task HTTP/1.1\" 200 18\n",
      "[2024-03-11 21:44:37,273] [django.server::log_message::161] [INFO] \"POST /api/projects/1/sample-task HTTP/1.1\" 200 18\n",
      "[2024-03-11 21:44:37,333] [django.server::log_message::161] [INFO] \"GET /api/templates HTTP/1.1\" 200 73961\n",
      "[2024-03-11 21:44:37,333] [django.server::log_message::161] [INFO] \"GET /api/templates HTTP/1.1\" 200 73961\n",
      "[2024-03-11 21:44:37,415] [django.server::log_message::161] [INFO] \"GET /api/templates HTTP/1.1\" 200 73961\n",
      "[2024-03-11 21:44:37,415] [django.server::log_message::161] [INFO] \"GET /api/templates HTTP/1.1\" 200 73961\n",
      "[2024-03-11 21:44:39,183] [django.server::log_message::161] [INFO] \"GET /api/projects/1 HTTP/1.1\" 200 1244\n",
      "[2024-03-11 21:44:39,183] [django.server::log_message::161] [INFO] \"GET /api/projects/1 HTTP/1.1\" 200 1244\n",
      "[2024-03-11 21:44:41,836] [django.server::log_message::161] [INFO] \"GET /api/projects/1/model-versions HTTP/1.1\" 200 19\n",
      "[2024-03-11 21:44:41,836] [django.server::log_message::161] [INFO] \"GET /api/projects/1/model-versions HTTP/1.1\" 200 19\n",
      "[2024-03-11 21:44:41,838] [django.server::log_message::161] [INFO] \"GET /api/ml?project=1 HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:44:41,838] [django.server::log_message::161] [INFO] \"GET /api/ml?project=1 HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:44:41,843] [django.server::log_message::161] [INFO] \"GET /api/projects/1 HTTP/1.1\" 200 1244\n",
      "[2024-03-11 21:44:41,843] [django.server::log_message::161] [INFO] \"GET /api/projects/1 HTTP/1.1\" 200 1244\n",
      "[2024-03-11 21:44:41,857] [django.server::log_message::161] [INFO] \"GET /api/ml?project=1 HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:44:41,857] [django.server::log_message::161] [INFO] \"GET /api/ml?project=1 HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:44:41,857] [django.server::log_message::161] [INFO] \"GET /api/projects/1/model-versions HTTP/1.1\" 200 19\n",
      "[2024-03-11 21:44:41,857] [django.server::log_message::161] [INFO] \"GET /api/projects/1/model-versions HTTP/1.1\" 200 19\n",
      "[2024-03-11 21:44:41,869] [django.server::log_message::161] [INFO] \"GET /api/ml?project=1 HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:44:41,869] [django.server::log_message::161] [INFO] \"GET /api/ml?project=1 HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:44:44,264] [django.server::log_message::161] [INFO] \"GET /api/storages/export/types HTTP/1.1\" 200 198\n",
      "[2024-03-11 21:44:44,265] [django.server::log_message::161] [INFO] \"GET /api/storages/types HTTP/1.1\" 200 198\n",
      "[2024-03-11 21:44:44,265] [django.server::log_message::161] [INFO] \"GET /api/storages/types HTTP/1.1\" 200 198\n",
      "[2024-03-11 21:44:44,264] [django.server::log_message::161] [INFO] \"GET /api/storages/export/types HTTP/1.1\" 200 198\n",
      "[2024-03-11 21:44:44,286] [django.server::log_message::161] [INFO] \"GET /api/projects/1 HTTP/1.1\" 200 1244\n",
      "[2024-03-11 21:44:44,286] [django.server::log_message::161] [INFO] \"GET /api/projects/1 HTTP/1.1\" 200 1244\n",
      "[2024-03-11 21:44:44,299] [django.server::log_message::161] [INFO] \"GET /api/storages/export?project=1 HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:44:44,299] [django.server::log_message::161] [INFO] \"GET /api/storages/export?project=1 HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:44:44,301] [django.server::log_message::161] [INFO] \"GET /api/storages?project=1 HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:44:44,301] [django.server::log_message::161] [INFO] \"GET /api/storages?project=1 HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:44:44,318] [django.server::log_message::161] [INFO] \"GET /api/storages/export/types HTTP/1.1\" 200 198\n",
      "[2024-03-11 21:44:44,318] [django.server::log_message::161] [INFO] \"GET /api/storages/export/types HTTP/1.1\" 200 198\n",
      "[2024-03-11 21:44:44,323] [django.server::log_message::161] [INFO] \"GET /api/storages/types HTTP/1.1\" 200 198\n",
      "[2024-03-11 21:44:44,323] [django.server::log_message::161] [INFO] \"GET /api/storages/types HTTP/1.1\" 200 198\n",
      "[2024-03-11 21:44:44,335] [django.server::log_message::161] [INFO] \"GET /api/storages/export?project=1 HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:44:44,335] [django.server::log_message::161] [INFO] \"GET /api/storages/export?project=1 HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:44:44,339] [django.server::log_message::161] [INFO] \"GET /api/storages?project=1 HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:44:44,339] [django.server::log_message::161] [INFO] \"GET /api/storages?project=1 HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:44:44,359] [django.server::log_message::161] [INFO] \"GET /api/storages/export/types HTTP/1.1\" 200 198\n",
      "[2024-03-11 21:44:44,359] [django.server::log_message::161] [INFO] \"GET /api/storages/export/types HTTP/1.1\" 200 198\n",
      "[2024-03-11 21:44:44,367] [django.server::log_message::161] [INFO] \"GET /api/storages/export?project=1 HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:44:44,367] [django.server::log_message::161] [INFO] \"GET /api/storages/export?project=1 HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:44:44,370] [django.server::log_message::161] [INFO] \"GET /api/storages/types HTTP/1.1\" 200 198\n",
      "[2024-03-11 21:44:44,370] [django.server::log_message::161] [INFO] \"GET /api/storages/types HTTP/1.1\" 200 198\n",
      "[2024-03-11 21:44:44,373] [django.server::log_message::161] [INFO] \"GET /api/storages?project=1 HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:44:44,373] [django.server::log_message::161] [INFO] \"GET /api/storages?project=1 HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:44:44,384] [django.server::log_message::161] [INFO] \"GET /api/storages/types HTTP/1.1\" 200 198\n",
      "[2024-03-11 21:44:44,384] [django.server::log_message::161] [INFO] \"GET /api/storages/types HTTP/1.1\" 200 198\n",
      "[2024-03-11 21:44:44,384] [django.server::log_message::161] [INFO] \"GET /api/storages/export/types HTTP/1.1\" 200 198\n",
      "[2024-03-11 21:44:44,384] [django.server::log_message::161] [INFO] \"GET /api/storages/export/types HTTP/1.1\" 200 198\n",
      "[2024-03-11 21:44:45,402] [django.server::log_message::161] [INFO] \"GET /api/projects/1 HTTP/1.1\" 200 1244\n",
      "[2024-03-11 21:44:45,402] [django.server::log_message::161] [INFO] \"GET /api/projects/1 HTTP/1.1\" 200 1244\n",
      "[2024-03-11 21:44:46,797] [django.server::log_message::161] [INFO] \"GET /api/projects?page=1&page_size=30&include=id%2Ctitle%2Ccreated_by%2Ccreated_at%2Ccolor%2Cis_published%2Cassignment_settings HTTP/1.1\" 200 275\n",
      "[2024-03-11 21:44:46,797] [django.server::log_message::161] [INFO] \"GET /api/projects?page=1&page_size=30&include=id%2Ctitle%2Ccreated_by%2Ccreated_at%2Ccolor%2Cis_published%2Cassignment_settings HTTP/1.1\" 200 275\n",
      "[2024-03-11 21:44:46,838] [django.server::log_message::161] [INFO] \"GET /projects HTTP/1.1\" 200 35420\n",
      "[2024-03-11 21:44:46,838] [django.server::log_message::161] [INFO] \"GET /projects HTTP/1.1\" 200 35420\n",
      "[2024-03-11 21:44:46,841] [django.server::log_message::161] [INFO] \"GET /api/projects?ids=1&include=id%2Cdescription%2Cnum_tasks_with_annotations%2Ctask_number%2Cskipped_annotations_number%2Ctotal_annotations_number%2Ctotal_predictions_number%2Cground_truth_number%2Cfinished_task_number&page_size=30 HTTP/1.1\" 200 262\n",
      "[2024-03-11 21:44:46,841] [django.server::log_message::161] [INFO] \"GET /api/projects?ids=1&include=id%2Cdescription%2Cnum_tasks_with_annotations%2Ctask_number%2Cskipped_annotations_number%2Ctotal_annotations_number%2Ctotal_predictions_number%2Cground_truth_number%2Cfinished_task_number&page_size=30 HTTP/1.1\" 200 262\n",
      "[2024-03-11 21:44:47,930] [django.server::log_message::161] [INFO] \"GET /api/projects HTTP/1.1\" 200 1296\n",
      "[2024-03-11 21:44:47,930] [django.server::log_message::161] [INFO] \"GET /api/projects HTTP/1.1\" 200 1296\n",
      "[2024-03-11 21:44:47,952] [django.server::log_message::161] [INFO] \"POST /api/projects HTTP/1.1\" 201 1243\n",
      "[2024-03-11 21:44:47,952] [django.server::log_message::161] [INFO] \"POST /api/projects HTTP/1.1\" 201 1243\n",
      "[2024-03-11 21:44:47,963] [django.server::log_message::161] [INFO] \"GET /api/projects/2/file-uploads HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:44:47,963] [django.server::log_message::161] [INFO] \"GET /api/projects/2/file-uploads HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:44:57,457] [django.server::log_message::161] [INFO] \"PATCH /api/projects/2 HTTP/1.1\" 200 1235\n",
      "[2024-03-11 21:44:57,457] [django.server::log_message::161] [INFO] \"PATCH /api/projects/2 HTTP/1.1\" 200 1235\n",
      "[2024-03-11 21:45:02,513] [django.server::log_message::161] [INFO] \"POST /api/projects/2/import?commit_to_project=false HTTP/1.1\" 201 199\n",
      "[2024-03-11 21:45:02,513] [django.server::log_message::161] [INFO] \"POST /api/projects/2/import?commit_to_project=false HTTP/1.1\" 201 199\n",
      "[2024-03-11 21:45:02,526] [django.server::log_message::161] [INFO] \"GET /api/projects/2/file-uploads?ids=%5B2%5D HTTP/1.1\" 200 59\n",
      "[2024-03-11 21:45:02,526] [django.server::log_message::161] [INFO] \"GET /api/projects/2/file-uploads?ids=%5B2%5D HTTP/1.1\" 200 59\n",
      "[2024-03-11 21:45:03,800] [django.server::log_message::161] [INFO] \"GET /api/templates HTTP/1.1\" 200 73961\n",
      "[2024-03-11 21:45:03,800] [django.server::log_message::161] [INFO] \"GET /api/templates HTTP/1.1\" 200 73961\n",
      "[2024-03-11 21:45:03,820] [django.server::log_message::161] [INFO] \"GET /static/templates/inventory-tracking.png HTTP/1.1\" 200 378386\n",
      "[2024-03-11 21:45:03,820] [django.server::log_message::161] [INFO] \"GET /static/templates/inventory-tracking.png HTTP/1.1\" 200 378386\n",
      "[2024-03-11 21:45:03,842] [django.server::log_message::161] [INFO] \"GET /static/templates/object-detection-with-bounding-boxes.png HTTP/1.1\" 200 116076\n",
      "[2024-03-11 21:45:03,842] [django.server::log_message::161] [INFO] \"GET /static/templates/object-detection-with-bounding-boxes.png HTTP/1.1\" 200 116076\n",
      "[2024-03-11 21:45:03,844] [django.server::log_message::161] [INFO] \"GET /static/templates/semantic-segmentation-with-masks.png HTTP/1.1\" 200 125386\n",
      "[2024-03-11 21:45:03,844] [django.server::log_message::161] [INFO] \"GET /static/templates/semantic-segmentation-with-masks.png HTTP/1.1\" 200 125386\n",
      "[2024-03-11 21:45:03,847] [django.server::log_message::161] [INFO] \"GET /static/templates/keypoints.png HTTP/1.1\" 200 152969\n",
      "[2024-03-11 21:45:03,847] [django.server::log_message::161] [INFO] \"GET /static/templates/keypoints.png HTTP/1.1\" 200 152969\n",
      "[2024-03-11 21:45:03,848] [django.server::log_message::161] [INFO] \"GET /static/templates/semantic-segmentation-with-polygons.png HTTP/1.1\" 200 125827\n",
      "[2024-03-11 21:45:03,848] [django.server::log_message::161] [INFO] \"GET /static/templates/semantic-segmentation-with-polygons.png HTTP/1.1\" 200 125827\n",
      "[2024-03-11 21:45:03,849] [django.server::log_message::161] [INFO] \"GET /static/templates/image-classification.png HTTP/1.1\" 200 118704\n",
      "[2024-03-11 21:45:03,849] [django.server::log_message::161] [INFO] \"GET /static/templates/image-classification.png HTTP/1.1\" 200 118704\n",
      "[2024-03-11 21:45:03,851] [django.server::log_message::161] [INFO] \"GET /static/templates/visual-genome.png HTTP/1.1\" 200 324792\n",
      "[2024-03-11 21:45:03,851] [django.server::log_message::161] [INFO] \"GET /static/templates/visual-genome.png HTTP/1.1\" 200 324792\n",
      "[2024-03-11 21:45:03,866] [django.server::log_message::161] [INFO] \"GET /static/templates/optical-character-recognition.png HTTP/1.1\" 200 29234\n",
      "[2024-03-11 21:45:03,866] [django.server::log_message::161] [INFO] \"GET /static/templates/optical-character-recognition.png HTTP/1.1\" 200 29234\n",
      "[2024-03-11 21:45:03,869] [django.server::log_message::161] [INFO] \"GET /static/templates/visual-question-answering.png HTTP/1.1\" 200 40961\n",
      "[2024-03-11 21:45:03,869] [django.server::log_message::161] [INFO] \"GET /static/templates/visual-question-answering.png HTTP/1.1\" 200 40961\n",
      "[2024-03-11 21:45:03,873] [django.server::log_message::161] [INFO] \"GET /static/templates/image-captioning.png HTTP/1.1\" 200 153283\n",
      "[2024-03-11 21:45:03,873] [django.server::log_message::161] [INFO] \"GET /static/templates/image-captioning.png HTTP/1.1\" 200 153283\n",
      "[2024-03-11 21:45:03,874] [django.server::log_message::161] [INFO] \"GET /static/templates/multipage.png HTTP/1.1\" 200 283217\n",
      "[2024-03-11 21:45:03,874] [django.server::log_message::161] [INFO] \"GET /static/templates/multipage.png HTTP/1.1\" 200 283217\n",
      "[2024-03-11 21:45:10,503] [django.server::log_message::161] [INFO] \"GET /static/templates/taxonomy.png HTTP/1.1\" 200 15582\n",
      "[2024-03-11 21:45:10,503] [django.server::log_message::161] [INFO] \"GET /static/templates/taxonomy.png HTTP/1.1\" 200 15582\n",
      "[2024-03-11 21:45:10,504] [django.server::log_message::161] [INFO] \"GET /static/templates/named-entity-recognition.png HTTP/1.1\" 200 14917\n",
      "[2024-03-11 21:45:10,504] [django.server::log_message::161] [INFO] \"GET /static/templates/named-entity-recognition.png HTTP/1.1\" 200 14917\n",
      "[2024-03-11 21:45:10,505] [django.server::log_message::161] [INFO] \"GET /static/templates/text-classification.png HTTP/1.1\" 200 11323\n",
      "[2024-03-11 21:45:10,505] [django.server::log_message::161] [INFO] \"GET /static/templates/text-classification.png HTTP/1.1\" 200 11323\n",
      "[2024-03-11 21:45:10,513] [django.server::log_message::161] [INFO] \"GET /static/templates/relation-extraction.png HTTP/1.1\" 200 15540\n",
      "[2024-03-11 21:45:10,513] [django.server::log_message::161] [INFO] \"GET /static/templates/relation-extraction.png HTTP/1.1\" 200 15540\n",
      "[2024-03-11 21:45:10,514] [django.server::log_message::161] [INFO] \"GET /static/templates/question-answering.png HTTP/1.1\" 200 38957\n",
      "[2024-03-11 21:45:10,514] [django.server::log_message::161] [INFO] \"GET /static/templates/question-answering.png HTTP/1.1\" 200 38957\n",
      "[2024-03-11 21:45:10,517] [django.server::log_message::161] [INFO] \"GET /static/templates/machine-translation.png HTTP/1.1\" 200 57977\n",
      "[2024-03-11 21:45:10,517] [django.server::log_message::161] [INFO] \"GET /static/templates/machine-translation.png HTTP/1.1\" 200 57977\n",
      "[2024-03-11 21:45:10,523] [django.server::log_message::161] [INFO] \"GET /static/templates/text-summarization.png HTTP/1.1\" 200 49890\n",
      "[2024-03-11 21:45:10,523] [django.server::log_message::161] [INFO] \"GET /static/templates/text-summarization.png HTTP/1.1\" 200 49890\n",
      "[2024-03-11 21:45:19,869] [core.label_config::parse_config::52] [WARNING] Using deprecated method - switch to label_studio.tools.label_config.parse_config!\n",
      "[2024-03-11 21:45:19,870] [core.label_config::parse_config::52] [WARNING] Using deprecated method - switch to label_studio.tools.label_config.parse_config!\n",
      "[2024-03-11 21:45:19,884] [django.server::log_message::161] [INFO] \"POST /api/projects/2/validate HTTP/1.1\" 200 42\n",
      "[2024-03-11 21:45:19,884] [django.server::log_message::161] [INFO] \"POST /api/projects/2/validate HTTP/1.1\" 200 42\n",
      "[2024-03-11 21:45:19,899] [django.server::log_message::161] [INFO] \"POST /api/projects/2/sample-task HTTP/1.1\" 200 103\n",
      "[2024-03-11 21:45:19,899] [django.server::log_message::161] [INFO] \"POST /api/projects/2/sample-task HTTP/1.1\" 200 103\n",
      "[2024-03-11 21:45:36,373] [django.server::log_message::161] [INFO] \"POST /api/projects/2/reimport HTTP/1.1\" 201 163\n",
      "[2024-03-11 21:45:36,373] [django.server::log_message::161] [INFO] \"POST /api/projects/2/reimport HTTP/1.1\" 201 163\n",
      "[2024-03-11 21:45:36,403] [core.label_config::parse_config::52] [WARNING] Using deprecated method - switch to label_studio.tools.label_config.parse_config!\n",
      "[2024-03-11 21:45:36,403] [core.label_config::parse_config::52] [WARNING] Using deprecated method - switch to label_studio.tools.label_config.parse_config!\n",
      "[2024-03-11 21:45:36,424] [django.server::log_message::161] [INFO] \"PATCH /api/projects/2 HTTP/1.1\" 200 2174\n",
      "[2024-03-11 21:45:36,424] [django.server::log_message::161] [INFO] \"PATCH /api/projects/2 HTTP/1.1\" 200 2174\n",
      "[2024-03-11 21:45:36,491] [django.server::log_message::161] [INFO] \"GET /api/projects/2 HTTP/1.1\" 200 2174\n",
      "[2024-03-11 21:45:36,491] [django.server::log_message::161] [INFO] \"GET /api/projects/2 HTTP/1.1\" 200 2174\n",
      "[2024-03-11 21:45:36,518] [django.server::log_message::161] [INFO] \"GET /api/ml?project=2 HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:45:36,518] [django.server::log_message::161] [INFO] \"GET /api/ml?project=2 HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:45:36,538] [django.server::log_message::161] [INFO] \"GET /api/dm/columns?project=2 HTTP/1.1\" 200 4250\n",
      "[2024-03-11 21:45:36,538] [django.server::log_message::161] [INFO] \"GET /api/dm/columns?project=2 HTTP/1.1\" 200 4250\n",
      "[2024-03-11 21:45:36,575] [django.server::log_message::161] [INFO] \"GET /api/users?project=2 HTTP/1.1\" 200 228\n",
      "[2024-03-11 21:45:36,575] [django.server::log_message::161] [INFO] \"GET /api/users?project=2 HTTP/1.1\" 200 228\n",
      "[2024-03-11 21:45:36,577] [django.server::log_message::161] [INFO] \"GET /api/dm/views?project=2 HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:45:36,577] [django.server::log_message::161] [INFO] \"GET /api/dm/views?project=2 HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:45:36,582] [django.server::log_message::161] [INFO] \"GET /api/dm/project?project=2 HTTP/1.1\" 200 2358\n",
      "[2024-03-11 21:45:36,582] [django.server::log_message::161] [INFO] \"GET /api/dm/project?project=2 HTTP/1.1\" 200 2358\n",
      "[2024-03-11 21:45:36,583] [django.server::log_message::161] [INFO] \"GET /api/dm/actions?project=2 HTTP/1.1\" 200 1550\n",
      "[2024-03-11 21:45:36,583] [django.server::log_message::161] [INFO] \"GET /api/dm/actions?project=2 HTTP/1.1\" 200 1550\n",
      "[2024-03-11 21:45:36,595] [django.server::log_message::161] [INFO] \"POST /api/dm/views?tabID=0&project=2 HTTP/1.1\" 201 963\n",
      "[2024-03-11 21:45:36,595] [django.server::log_message::161] [INFO] \"POST /api/dm/views?tabID=0&project=2 HTTP/1.1\" 201 963\n",
      "[2024-03-11 21:45:36,657] [django.server::log_message::161] [INFO] \"GET /api/tasks?page=1&page_size=30&view=2&project=2 HTTP/1.1\" 200 3151\n",
      "[2024-03-11 21:45:36,657] [django.server::log_message::161] [INFO] \"GET /api/tasks?page=1&page_size=30&view=2&project=2 HTTP/1.1\" 200 3151\n",
      "[2024-03-11 21:45:36,687] [django.server::log_message::161] [INFO] \"GET /api/tasks?page=1&page_size=30&view=2&project=2 HTTP/1.1\" 200 3151\n",
      "[2024-03-11 21:45:36,687] [django.server::log_message::161] [INFO] \"GET /api/tasks?page=1&page_size=30&view=2&project=2 HTTP/1.1\" 200 3151\n",
      "[2024-03-11 21:45:36,715] [django.server::log_message::161] [INFO] \"GET /api/tasks?page=1&page_size=30&view=2&project=2 HTTP/1.1\" 200 3151\n",
      "[2024-03-11 21:45:36,715] [django.server::log_message::161] [INFO] \"GET /api/tasks?page=1&page_size=30&view=2&project=2 HTTP/1.1\" 200 3151\n",
      "[2024-03-11 21:45:39,007] [django.server::log_message::161] [INFO] \"GET /api/projects/2/label-stream-history?project=2 HTTP/1.1\" 200 2\n",
      "[2024-03-11 21:45:39,007] [django.server::log_message::161] [INFO] \"GET /api/projects/2/label-stream-history?project=2 HTTP/1.1\" 200 2\n",
      "/Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.11/site-packages/rest_framework/pagination.py:200: UnorderedObjectListWarning: Pagination may yield inconsistent results with an unordered object_list: <class 'labels_manager.models.LabelLink'> QuerySet.\n",
      "  paginator = self.django_paginator_class(queryset, page_size)\n",
      "[2024-03-11 21:45:39,033] [django.server::log_message::161] [INFO] \"GET /api/label_links?project=2&expand=label HTTP/1.1\" 200 52\n",
      "[2024-03-11 21:45:39,033] [django.server::log_message::161] [INFO] \"GET /api/label_links?project=2&expand=label HTTP/1.1\" 200 52\n",
      "[2024-03-11 21:45:39,039] [django.server::log_message::161] [INFO] \"GET /api/tasks/6?project=2 HTTP/1.1\" 200 1163\n",
      "[2024-03-11 21:45:39,039] [django.server::log_message::161] [INFO] \"GET /api/tasks/6?project=2 HTTP/1.1\" 200 1163\n",
      "[2024-03-11 21:45:55,045] [django.server::log_message::161] [INFO] \"GET /api/label_links?project=2&expand=label HTTP/1.1\" 200 52\n",
      "[2024-03-11 21:45:55,045] [django.server::log_message::161] [INFO] \"GET /api/label_links?project=2&expand=label HTTP/1.1\" 200 52\n",
      "[2024-03-11 21:45:55,101] [django.server::log_message::161] [INFO] \"GET /api/tasks/7?project=2 HTTP/1.1\" 200 1187\n",
      "[2024-03-11 21:45:55,101] [django.server::log_message::161] [INFO] \"GET /api/tasks/7?project=2 HTTP/1.1\" 200 1187\n",
      "[2024-03-11 21:45:55,635] [django.server::log_message::161] [INFO] \"GET /api/label_links?project=2&expand=label HTTP/1.1\" 200 52\n",
      "[2024-03-11 21:45:55,635] [django.server::log_message::161] [INFO] \"GET /api/label_links?project=2&expand=label HTTP/1.1\" 200 52\n",
      "[2024-03-11 21:45:55,685] [django.server::log_message::161] [INFO] \"GET /api/tasks/8?project=2 HTTP/1.1\" 200 1177\n",
      "[2024-03-11 21:45:55,685] [django.server::log_message::161] [INFO] \"GET /api/tasks/8?project=2 HTTP/1.1\" 200 1177\n",
      "[2024-03-11 21:45:56,251] [django.server::log_message::161] [INFO] \"GET /api/label_links?project=2&expand=label HTTP/1.1\" 200 52\n",
      "[2024-03-11 21:45:56,251] [django.server::log_message::161] [INFO] \"GET /api/label_links?project=2&expand=label HTTP/1.1\" 200 52\n",
      "[2024-03-11 21:45:56,302] [django.server::log_message::161] [INFO] \"GET /api/tasks/9?project=2 HTTP/1.1\" 200 1181\n",
      "[2024-03-11 21:45:56,302] [django.server::log_message::161] [INFO] \"GET /api/tasks/9?project=2 HTTP/1.1\" 200 1181\n",
      "[2024-03-11 21:45:56,792] [django.server::log_message::161] [INFO] \"GET /api/label_links?project=2&expand=label HTTP/1.1\" 200 52\n",
      "[2024-03-11 21:45:56,792] [django.server::log_message::161] [INFO] \"GET /api/label_links?project=2&expand=label HTTP/1.1\" 200 52\n",
      "[2024-03-11 21:45:56,835] [django.server::log_message::161] [INFO] \"GET /api/tasks/10?project=2 HTTP/1.1\" 200 1198\n",
      "[2024-03-11 21:45:56,835] [django.server::log_message::161] [INFO] \"GET /api/tasks/10?project=2 HTTP/1.1\" 200 1198\n",
      "[2024-03-11 21:46:01,205] [django.server::log_message::161] [INFO] \"GET /api/label_links?project=2&expand=label HTTP/1.1\" 200 52\n",
      "[2024-03-11 21:46:01,205] [django.server::log_message::161] [INFO] \"GET /api/label_links?project=2&expand=label HTTP/1.1\" 200 52\n",
      "[2024-03-11 21:46:01,274] [django.server::log_message::161] [INFO] \"GET /api/tasks/9?project=2 HTTP/1.1\" 200 1181\n",
      "[2024-03-11 21:46:01,274] [django.server::log_message::161] [INFO] \"GET /api/tasks/9?project=2 HTTP/1.1\" 200 1181\n",
      "[2024-03-11 21:46:01,702] [django.server::log_message::161] [INFO] \"GET /api/label_links?project=2&expand=label HTTP/1.1\" 200 52\n",
      "[2024-03-11 21:46:01,702] [django.server::log_message::161] [INFO] \"GET /api/label_links?project=2&expand=label HTTP/1.1\" 200 52\n",
      "[2024-03-11 21:46:01,746] [django.server::log_message::161] [INFO] \"GET /api/tasks/8?project=2 HTTP/1.1\" 200 1177\n",
      "[2024-03-11 21:46:01,746] [django.server::log_message::161] [INFO] \"GET /api/tasks/8?project=2 HTTP/1.1\" 200 1177\n",
      "[2024-03-11 21:46:07,336] [django.server::log_message::161] [INFO] \"GET /api/label_links?project=2&expand=label HTTP/1.1\" 200 52\n",
      "[2024-03-11 21:46:07,336] [django.server::log_message::161] [INFO] \"GET /api/label_links?project=2&expand=label HTTP/1.1\" 200 52\n",
      "[2024-03-11 21:46:07,388] [django.server::log_message::161] [INFO] \"GET /api/tasks/7?project=2 HTTP/1.1\" 200 1187\n",
      "[2024-03-11 21:46:07,388] [django.server::log_message::161] [INFO] \"GET /api/tasks/7?project=2 HTTP/1.1\" 200 1187\n",
      "[2024-03-11 21:49:22,910] [django.server::log_message::161] [INFO] \"GET /api/label_links?project=2&expand=label HTTP/1.1\" 200 52\n",
      "[2024-03-11 21:49:22,910] [django.server::log_message::161] [INFO] \"GET /api/label_links?project=2&expand=label HTTP/1.1\" 200 52\n",
      "[2024-03-11 21:49:22,926] [django.server::log_message::161] [INFO] \"GET /api/tasks/8?project=2 HTTP/1.1\" 200 1177\n",
      "[2024-03-11 21:49:22,926] [django.server::log_message::161] [INFO] \"GET /api/tasks/8?project=2 HTTP/1.1\" 200 1177\n",
      "[2024-03-11 21:49:42,780] [django.server::log_message::161] [INFO] \"POST /api/tasks/8/drafts?project=2 HTTP/1.1\" 201 420\n",
      "[2024-03-11 21:49:42,780] [django.server::log_message::161] [INFO] \"POST /api/tasks/8/drafts?project=2 HTTP/1.1\" 201 420\n",
      "[2024-03-11 21:49:53,833] [django.server::log_message::161] [INFO] \"PATCH /api/drafts/1?project=2 HTTP/1.1\" 200 420\n",
      "[2024-03-11 21:49:53,833] [django.server::log_message::161] [INFO] \"PATCH /api/drafts/1?project=2 HTTP/1.1\" 200 420\n",
      "[2024-03-11 21:50:02,378] [django.server::log_message::161] [INFO] \"GET /api/label_links?project=2&expand=label HTTP/1.1\" 200 52\n",
      "[2024-03-11 21:50:02,378] [django.server::log_message::161] [INFO] \"GET /api/label_links?project=2&expand=label HTTP/1.1\" 200 52\n",
      "[2024-03-11 21:50:02,446] [django.server::log_message::161] [INFO] \"GET /api/tasks/6?project=2 HTTP/1.1\" 200 1163\n",
      "[2024-03-11 21:50:02,446] [django.server::log_message::161] [INFO] \"GET /api/tasks/6?project=2 HTTP/1.1\" 200 1163\n",
      "[2024-03-11 21:50:41,048] [django.server::log_message::161] [INFO] \"GET /api/label_links?project=2&expand=label HTTP/1.1\" 200 52\n",
      "[2024-03-11 21:50:41,048] [django.server::log_message::161] [INFO] \"GET /api/label_links?project=2&expand=label HTTP/1.1\" 200 52\n",
      "[2024-03-11 21:50:41,068] [django.server::log_message::161] [INFO] \"GET /api/tasks/7?project=2 HTTP/1.1\" 200 1187\n",
      "[2024-03-11 21:50:41,068] [django.server::log_message::161] [INFO] \"GET /api/tasks/7?project=2 HTTP/1.1\" 200 1187\n",
      "^C\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!label-studio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Create a New Project**\n",
    "\n",
    "- Create Project: Click on \"Create Project\" and input a project name, such as \"Review Bootstrapped Labels.\"\n",
    "- Define Labeling Configuration: Choose the \"Sentiment Analysis Text Classification\" template for Sentiment Analysis tasks.\n",
    "- Configuration Flexibility: These templates are customizable, allowing for easy adjustment of properties as needed.\n",
    "- Default Labeling Configuration: Below is the default labeling configuration for reference.\n",
    "  \n",
    "<img src=\"./images/lbl_studio_1.png\" width=\"800\" align=\"center\"/>\n",
    "\n",
    "<img src=\"./images/lbl_studio_2.png\" width=\"800\" align=\"center\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Import Pre-labeled Data**\n",
    "\n",
    "<img src=\"./images/lbl_studio_3.png\" width=\"800\" align=\"center\"/>\n",
    "\n",
    "<img src=\"./images/lbl_studio_4.png\" width=\"800\" align=\"center\"/>\n",
    "\n",
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>\n",
    "\n",
    "**Step 4: Review and Update Labels**\n",
    "\n",
    "\n",
    "<img src=\"./images/lbl_studio_5.png\" width=\"800\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beyond Sentiment Analysis: Label Any NLP Task**\n",
    "\n",
    "- **Summarization**\n",
    "```\n",
    "Respond in the json format with a summary for the following text: {‘summary’: summary}\n",
    "\n",
    "Text: I love going to the park on a sunny day. The customer service was terrible; they were rude and unhelpful. I am neither happy nor sad about the new policy changes. The cake was delicious and the presentation was fantastic. I had a really bad experience with the product; it broke after two days.\n",
    "\n",
    "Summary:\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Named Entity Recognition (NER)**\n",
    "  \n",
    "  ```\n",
    "  You are an expert NER labeler. Only return JSON. Do not return explanations. Return the CoNLL format for the following sentence in JSON format.\n",
    "  \n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Human Evaluation: There is no replacement for human assessment in certain contexts.\n",
    "- GPT Models as Starting Point: Utilizing GPT models to provide initial insights can offer significant advantages.\n",
    "- Balancing Human and AI Contributions: Combining human evaluation with AI-generated insights can enhance efficiency and accuracy in various tasks.\n",
    "- Leveraging GPT Models: Incorporating GPT models provides a valuable starting point, which can streamline processes and improve productivity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prioritize responsible manual annotation, preparing around **20 examples** and randomly **selecting 2-8 for prompts** to enhance data diversity.\n",
    "- Ensure examples are representative, correctly formatted, and detail specifics like query length and tone.\n",
    "- Precision in examples and instructions improves synthetic data quality for Retriever training.\n",
    "- Low-quality few-shot examples can detrimentally affect the trained model's quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Utilizing an affordable model like ChatGPT is often adequate for non-English languages and unusual domains.\n",
    "- A typical prompt with instructions and 4-5 examples might use about 700 tokens, plus 25 tokens for generation, under Retriever's 128-token constraint per passage.\n",
    "- The cost of generating a synthetic dataset for 50,000 documents, considering GPT-3.5 Turbo API pricing, is approximately $55.\n",
    "  - Calculation: 50,000 * (700 * 0.001 * $0.0015 + 25 * 0.001 * $0.002)\n",
    "- Generating multiple (2-4) query examples per document is feasible and can enhance local model fine-tuning.\n",
    "- Further training, despite additional costs, often yields significant benefits, particularly for specialized domains such as Czech law."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dai et al. (2022) found that around 50,000 manually labeled data are needed for a model to match synthetic data quality.\n",
    "- Gathering 10,000 manual examples before launch takes time and costs over a thousand dollars.\n",
    "- Synthetic data and local Retriever Model training are more cost-effective.\n",
    "- With the new technique, double-digit metric growth can be achieved in a few days.\n",
    "  \n",
    "<img src=\"./images/synthetic_rag_3.webp\" width=\"800\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Synthetic Data for RAG Setup**\n",
    "\n",
    "- The Retrieval model is pivotal in the RAG (Retriever-And-Generator) framework, as it identifies relevant documents and forwards them to the Large Language Model (LLM) for subsequent processing.\n",
    "- The effectiveness of the Retrieval model directly impacts the quality of the product or feature outcome.\n",
    "- Ideally, the Retrieval model should exhibit satisfactory performance without requiring extensive fine-tuning.\n",
    "- The performance of the Retrieval model may diminish when operating in diverse languages or specialized domains.\n",
    "- Strategies such as domain adaptation or multilingual training may be employed to enhance the Retrieval model's performance in various contexts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Scenario:**\n",
    "- Consider the task of developing a chatbot to answer questions regarding Czech laws and legal practices, or designing a tax assistant customized for the Indian market.\n",
    "- In such specialized domains and languages, the Retrieval model may struggle to identify the most pertinent documents, leading to suboptimal performance and impacting the overall quality of the system.\n",
    "- The Retrieval model's limitations may result in missing crucial information and hindering the chatbot or tax assistant's ability to provide accurate and comprehensive responses.\n",
    "- Addressing these challenges requires tailored approaches such as domain-specific prompting, language adaptation, or incorporating specialized knowledge bases to enhance the Retrieval model's effectiveness in retrieving relevant information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## **Solution:**\n",
    "-  Leveraging existing Large Language Models (LLMs) to synthesize data for training new generations of LLMs, Retrievers, and other models.\n",
    "   - This approach involves distilling LLMs into standard-sized encoders through prompt-based query generation.\n",
    "   - The distillation process requires significant computational resources.\n",
    "- Despite its computational demands, this method significantly reduces inference costs and has the potential to greatly enhance model performance, especially in scenarios involving low-resource languages or specialized domains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use?\n",
    "\n",
    "- Users typically need to supply a brief description and manually label a few examples.\n",
    "- Different retrieval tasks exhibit diverse search intents, resulting in varying interpretations of \"relevance\" for a given (Query, Document) pair.\n",
    "- Relevance can differ significantly based on the specific search intent of the task.\n",
    "  - For example, in an argument retrieval task, relevance might entail identifying supporting arguments, whereas in other scenarios, counter-arguments might be sought.\n",
    "\n",
    "**Prompt:**\n",
    "Task: Identify a counter-argument for the given argument.\n",
    "\n",
    "Argument #1: {insert passage X1 here}\n",
    "\n",
    "A concise counter-argument query related to the argument #1: {insert manually prepared query Y1 here}\n",
    "\n",
    "Argument #2: {insert passage X2 here}\n",
    "A concise counter-argument query related to the argument #2: {insert manually prepared query Y2 here}\n",
    "\n",
    "**Examples:**\n",
    "\n",
    "Argument N: Even if a fine is made proportional to income, you will not get the equality of impact you desire. This is because the impact is not proportional simply to income, but must take into account a number of other factors. For example, someone supporting a family will face a greater impact than someone who is not, because they have a smaller disposable income. Further, a fine based on income ignores overall wealth (i.e. how much money someone actually has: someone might have a lot of assets but not have a high income). The proposition does not cater for these inequalities, which may well have a much greater skewing effect, and therefore the argument is being applied inconsistently.\n",
    "\n",
    "A concise counter-argument query related to the argument #N:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**output:**\n",
    "\n",
    "```\n",
    "punishment house would make fines relative income\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/synthetic_rag_2.webp\" width=\"800\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Suppose Information Retrieval isn't your primary task, such as when working on a legal document classification problem without the option to utilize external APIs.\n",
    "  - In such cases, training a local model becomes necessary to maintain data privacy and comply with restrictions on data sharing.\n",
    "  - However, gathering sufficient data locally can present a significant hurdle, potentially leading to delays in product development.\n",
    "  - Limited access to data may hinder model training and subsequent performance, necessitating innovative strategies to overcome this obstacle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Consider the task of generating children's stories, as explored in the research by Eldan et al. (2023).\n",
    "- Each story typically comprises 2-3 paragraphs, following a simple plot and theme, with the dataset covering vocabulary and factual knowledge suitable for children.\n",
    "- Language serves not only as a system of rules and symbols but also as a medium for conveying and interpreting meaning.\n",
    "- A key challenge in using large language models for generating training data is ensuring **dataset diversity**. \n",
    "  - Even with high generation temperatures, models may produce repetitive datasets lacking the necessary variety, particularly concerning children's language.\n",
    "- Additionally, natural language generation faces challenges related to **coherence** and **relevance**, which are crucial for producing meaningful and engaging children's stories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To address the diversity challenge, the authors curated a vocabulary comprising approximately 1500 basic words, reminiscent of a typical child's vocabulary, categorized into nouns, verbs, and adjectives.\n",
    "- During each generation process, one verb, one noun, and one adjective were randomly chosen from the curated vocabulary.\n",
    "- The model then proceeded to generate a story incorporating these randomly selected words, thereby ensuring diversity in the generated datasets.\n",
    "- By integrating random words from the curated vocabulary, the model diversified the stories it produced, enhancing the overall diversity of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Write a short story (3-5 paragraphs) which only uses very simple words that a 3 year old child would likely understand. The story should use the verb ”{random.choice(verbs_list)}”, the noun ”{random.choice(nouns_list)}” and the adjective ”{random.choice(adjectives_list)}”. The story should have the following features: {random.choice(features_list)}, {random.choice(features_list)}. Remember to only use simple words!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The technique significantly expanded the dataset's diversity by ensuring that stories encompassed a child's entire vocabulary and various combinations of concepts.\n",
    "- Additionally, the authors incorporated potential story features such as dialogue, plot twists, bad endings, or moral lessons.\n",
    "- A random subset of these features was selected for each story generation process.\n",
    "- The model was prompted to include the chosen story features, thereby enriching the narratives with diverse elements and enhancing the overall quality and variety of the generated stories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Write a short story (3-5 paragraphs) which only uses very simple words that a 3 year old child would likely understand. The story should use the verb ”decorate”, the noun ”thunder” and the adjective ”ancient”. The story should have the following features: the story should contain at least one dialogue, the story has a bad ending. Remember to only use simple words!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output:**\n",
    "\n",
    "```\n",
    "Once upon a time, in an ancient house, there lived a girl named Lily. She loved to decorate her room with pretty things. One day, she found a big box in the attic. She opened it and saw many shiny decorations. Lily was very happy and decided to use them in her room. As Lily was decorating her room, the sky outside became dark. There was a loud thunder sound, and Lily got scared. She ran to her mom and said, ”Mommy, the thunder is so loud!” Her mom hugged her and said, ”Don’t worry, it will pass soon.” But the thunder did not stop. It got louder and louder, and the ancient house started to shake. Suddenly, the roof fell down on the pretty decorations. Lily was sad because her room was not pretty anymore. The end.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative (Hierarchical) Synthetic Data Generation\n",
    "\n",
    "- The format can be further enriched by incorporating additional entities, some of which are generated beforehand by the LLM itself.\n",
    "  - For instance, one could initiate the process by requesting the generation of a story summary and specifying a particular sentence that must be included in the story.\n",
    "  - The LLM generates this intermediate data, which is then utilized in subsequent requests.\n",
    "  - In the final request, the previously generated intermediate data is incorporated, allowing for the creation of more complex and intricate story narratives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Summary: {a short summary generated by LLM, using the approach above}\n",
    "Features: {copy the features from the initial prompt}\n",
    "Sentence: {a sentence generated by LLM, which should be present in the story}\n",
    "Words: {copy the words from the initial prompt}\n",
    "Story:\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Example:**\n",
    "```\n",
    "Summary: Lily and Timmy build a sandcastle together and learn to compromise, but it gets knocked over by a gust of wind. They find beauty in the broken sandcastle and play happily with a butterfly.\n",
    "Features: Dialogue, Foreshadowing, Twist\n",
    "Sentence: One day, she went to the park and saw a beautiful butterfly.\n",
    "Words: disagree, network, beautiful\n",
    "Story:\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output:**\n",
    "\n",
    "```\n",
    "Once upon a time, there was a little girl named Lily. She loved to play with her toys and her friends. One day, she went to the park and saw a beautiful butterfly. She tried to catch it, but it flew away. Lily’s friend, Timmy, came to play with her. They decided to build a sandcastle, but they disagreed on how to build it. Lily wanted to make it tall, while Timmy wanted to make it wide. They argued for a while, but finally agreed to make it both tall and wide. As they were building the sandcastle, they noticed a group of ants working together. They realized that the ants were building a network of tunnels. Suddenly, a gust of wind came and knocked over their sandcastle. They were sad, but then they saw the butterfly again. It landed on the remains of their sandcastle and they realized that it was still beautiful, even in its broken state. They smiled and played together happily.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Generating Code**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Language Models like ChatGPT demonstrate high effectiveness in generating code.\n",
    "-  Similar to other chat models from OpenAI, a System Message is employed to define response behavior and format for the prompt examples.\n",
    "- Below is the System Message utilized for the prompt examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "You are a helpful code assistant that can teach a junior developer how to code. Your language of choice is Python. Don't explain the code, just generate the code block itself.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The code generation capabilities of LLMs can also be employed to generate code solely from comments.\n",
    "- Instructions are provided within a comment block to guide the code generation process.\n",
    "- By leveraging comments as input, LLMs can interpret the instructions and generate corresponding code snippets.\n",
    "- This approach offers versatility in generating code from various types of input, such as comments or descriptions of desired functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\"\"\"\n",
    "1. Create a list of movies\n",
    "2. Create a list of ratings for these movies\n",
    "3. Combine them to make a json object of 10 movies with their ratings.\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"The Shawshank Redemption\": 9.3,\n",
      "    \"The Godfather\": 9.2,\n",
      "    \"The Dark Knight\": 9.0,\n",
      "    \"Schindler's List\": 8.9,\n",
      "    \"Pulp Fiction\": 8.9,\n",
      "    \"The Lord of the Rings: The Return of the King\": 8.9,\n",
      "    \"Forrest Gump\": 8.8,\n",
      "    \"Star Wars: Episode V - The Empire Strikes Back\": 8.7,\n",
      "    \"Inception\": 8.7,\n",
      "    \"The Silence of the Lambs\": 8.6\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "movies = [\"The Shawshank Redemption\", \"The Godfather\", \"The Dark Knight\", \"Schindler's List\", \"Pulp Fiction\", \"The Lord of the Rings: The Return of the King\", \"Forrest Gump\", \"Star Wars: Episode V - The Empire Strikes Back\", \"Inception\", \"The Silence of the Lambs\"]\n",
    " \n",
    "ratings = [9.3, 9.2, 9.0, 8.9, 8.9, 8.9, 8.8, 8.7, 8.7, 8.6]\n",
    " \n",
    "movie_ratings = {}\n",
    " \n",
    "for i in range(len(movies)):\n",
    "    movie_ratings[movies[i]] = ratings[i]\n",
    " \n",
    "json_object = json.dumps(movie_ratings, indent=4)\n",
    " \n",
    "print(json_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Complete Functions or Next Line**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# function to multiply two numbers and add 75 to it\n",
    " \n",
    "def multiply(\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output:**\n",
    "\n",
    "```\n",
    "a, b):\n",
    "    result = a * b\n",
    "    result += 75\n",
    "    return result\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Explain Code**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When learning a programming language, prompting the model to explain specific code segments can be highly beneficial.\n",
    "- Queries generated previously can be repurposed to request explanations for code snippets.\n",
    "- It's essential to consider the System Message used, as the model's behavior may vary based on its instructions.\n",
    "  - For instance, if the System Message restricts the model to acting as a Python code assistant, it might refuse certain requests that deviate from this instruction.\n",
    "- The model may still provide explanations for code snippets, demonstrating its adaptability and utility in aiding programming education."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "SELECT students.StudentId, students.StudentName\n",
    "FROM students\n",
    "INNER JOIN departments\n",
    "ON students.DepartmentId = departments.DepartmentId\n",
    "WHERE departments.DepartmentName = 'Computer Science';\n",
    "\n",
    "Explain the above SQL statement.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output:**\n",
    "\n",
    "```\n",
    "Sorry, as a code assistant in Python, I cannot generate SQL code. However, I can explain the purpose of the SQL statement provided. \n",
    "\n",
    "This SQL statement selects the `StudentId` and `StudentName` columns from the `students` table, where the `DepartmentName` column in the `departments` table is equal to 'Computer Science'. To achieve this, the statement performs an inner join on the `DepartmentId` column between the `students` and `departments` tables. \n",
    "\n",
    "In simpler terms, it is selecting the names and IDs of students who are enrolled in the Computer Science department.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Graduate Job Classification Case Study**\n",
    "\n",
    "- Clavié et al., 2023 present a case study on prompt engineering applied to a text classification task within a production system.\n",
    "- **Task Description:** \n",
    "  - Classifying whether a job is suitable as an entry-level position for recent graduates or not.\n",
    "- The study evaluates various prompt engineering techniques using GPT-3.5 (gpt-3.5-turbo), comparing its performance against other models, including DeBERTa-V3.\n",
    "  - Few-shot CoT prompting underperforms compared to Zero-shot prompting when expert knowledge is not required.\n",
    "  - The prompt significantly influences the model's reasoning, with post-prompt engineering models achieving substantially higher F1 scores.\n",
    "  - Attempts to enforce template adherence reduce performance across all cases.\n",
    "  - Small modifications have a disproportionate impact on performance.\n",
    "  - Clear instructions and repetition of key points are crucial for enhancing performance.\n",
    "  - Even simple modifications, such as assigning a human name to the model, lead to measurable improvements in F1 score.\n",
    "- The observed template adherence issue diminishes in early testing with GPT-4, which is subsequent to the period covered in the paper.\n",
    "\n",
    "\n",
    "<img src=\"./images/study_1.png\" width=\"800\" align=\"center\"/>\n",
    "\n",
    "\n",
    "<img src=\"./images/study_2.png\" width=\"800\" align=\"center\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Prompt Function**\n",
    "\n",
    "- Drawing a parallel between GPT's dialogue interface and a programming language's shell\n",
    "  - The prompt can be likened to forming a function.\n",
    "- The encapsulated prompt acts as a **function** with a unique name. \n",
    "  - When invoked with input text, it produces results based on predefined internal rules.\n",
    "- Creating a reusable prompt with a name simplifies engagement with GPT, akin to having a handy tool to delegate specific tasks.\n",
    "  - Inputting text triggers the function, generating the desired output.\n",
    "- Encapsulating prompts into functions enables the creation of a series of functions to establish a workflow.\n",
    "  - Each function represents a distinct step or task, and when sequenced appropriately, they automate complex processes or enhance problem-solving efficiency.\n",
    "\n",
    "\n",
    "- **Before** we can use a function, we need to **let GPT know about it**. \n",
    "\n",
    "\n",
    "```\n",
    "Hello, ChatGPT! I hope you are doing well. I am reaching out to you for assistance with a specific function. I understand that you have the capability to process information and perform various tasks based on the instructions provided. In order to help you understand my request more easily, I will be using a template to describe the function, input, and instructions on what to do with the input. Please find the details below:\n",
    "\n",
    "function_name: [Function Name]\n",
    "input: [Input]\n",
    "rule: [Instructions on how to process the input]\n",
    "\n",
    "I kindly request you to provide the output for this function, based on the details I have provided. Your assistance is greatly appreciated. Thank you!\n",
    "I will replace the text inside the brackets with the relevant information for the function I want you to perform. This detailed introduction should help you understand my request more efficiently and provide the desired output. The format is function_name(input) If you understand, just answer one word with ok.\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Examples: English Study Assistant**\n",
    "\n",
    "```\n",
    "function_name: [trans_word]\n",
    "input: [\"text\"]\n",
    "rule: [I want you to act as an English translator, spelling corrector and improver. I will provide you with input forms including \"text\" in any language and you will detect the language, translate it and answer in the corrected of my text, in English.]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "function_name: [fix_english]\n",
    "input: [\"text\"]\n",
    "rule: [Please serve as an English master, spelling corrector, and language enhancer. I will provide you with input forms including \"text\", I want you to improve the text's vocabulary and sentences with more natural and elegent. Keep the meaning same.]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "trans_word('婆罗摩火山处于享有“千岛之国”美称的印度尼西亚. 多岛之国印尼有4500座之多的火山, 世界著名的十大活火山有三座在这里.')\n",
    "fix_english('Finally, you can run the function independently or chain them together.')\n",
    "fix_english(expand_word(trans_word('婆罗摩火山处于享有“千岛之国”美称的印度尼西亚. 多岛之国印尼有4500座之多的火山, 世界著名的十大活火山有三座在这里.')))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If you don't want ChatGPT to output excessive information, you can simply add a sentence after defining the function's rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Multiple params function**\n",
    "\n",
    "```\n",
    "function_name: [pg]\n",
    "input: [\"length\", \"capitalized\", \"lowercase\", \"numbers\", \"special\"]\n",
    "rule: [I want you to act as a password generator for individuals in need of a secure password. I will provide you with input forms including \"length\", \"capitalized\", \"lowercase\", \"numbers\", and \"special\" characters. Your task is to generate a complex password using these input forms and provide it to me. Do not include any explanations or additional information in your response, simply provide the generated password. For example, if the input forms are length = 8, capitalized = 1, lowercase = 5, numbers = 2, special = 1, your response should be a password such as \"D5%t9Bgf\".]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
