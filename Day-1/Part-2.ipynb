{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Outline**\n",
    "\n",
    "- Deep Dive into OpenAI's LLMs: GPT family\n",
    "- Setting Up the Environment for Using OpenAI APIs\n",
    "- Basic Prompt Engineering: Principles, Practices, and Examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding GPT Models\n",
    "\n",
    "- **GPT (Generative Pre-trained Transformers)**: A sophisticated Large Language Model (LLM) developed using deep learning techniques.\n",
    "  - Built upon a decoder-only transformer architecture.\n",
    "  - Primary goal:\n",
    "    - To analyze text data and produce outputs that closely mimic human language patterns.\n",
    "\n",
    "- Key Components:\n",
    "  - Generative\n",
    "  - Pre-trained\n",
    "  - Transformers\n",
    "\n",
    "## Generative Aspect\n",
    "- Highlights the model's proficiency in creating text by analyzing and reacting to text inputs.\n",
    "- Prior to GPT:\n",
    "  - Methods primarily involved reordering or selecting words directly from the given inputs.\n",
    "  - GPT's generative abilities significantly surpass previous models by:\n",
    "    - Generating text that is both more coherent and resembles human writing more closely.\n",
    "\n",
    "- Training Approach: **Autoregressive language modeling**,\n",
    "  - The model sequentially processes input words.\n",
    "    - It predicts the next word by calculating probability distributions, aiming to select the most likely subsequent word or phrase.\n",
    "\n",
    "## Pre-Trained Nature\n",
    "- Refers to models prepped on vast datasets before application to specific tasks.\n",
    "- For GPT:\n",
    "  - Trained on a broad collection of text, employing an unsupervised learning strategy.\n",
    "  - This pre-training phase enables the model to identify language patterns and relationships autonomously.\n",
    "- Post-training, GPT can apply its learned language understanding to tasks like answering questions or summarizing texts.\n",
    "\n",
    "## Transformers Architecture\n",
    "- A neural network design engineered for managing texts of various lengths.\n",
    "- Became well-known following the release of the \"Attention Is All You Need\" paper in 2017.\n",
    "- GPT's architecture:\n",
    "   - Is centered around the **decoder-only** model.\n",
    "   - Utilizes a \"self-attention mechanism\" that:\n",
    "      - Allows the model to understand the significance of each word in relation to others within the same sentence.\n",
    "\n",
    "## Practical Example\n",
    "\n",
    "- Consider the sentences:\n",
    "  - \"A dog is sitting on the bank of the River Ganga.\"\n",
    "  - \"I’ll withdraw some money from the bank.\"\n",
    "- Through self-attention, the model evaluates words in context:\n",
    "  - In the first scenario, \"bank\" is linked to \"River,\" indicating a riverbank.\n",
    "  - In the second, \"bank\" in connection with \"money\" refers to a financial institution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolution of GPT Models\n",
    "\n",
    "<img src=\"./images/GPTEvolution.webp\" width=\"800\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-1 Overview\n",
    "\n",
    "- **Introduction to GPT-1**: Marking the beginning of the GPT series, this initial model was a pioneer in the field of deep learning and natural language processing.\n",
    "  - **Data Training Volume**: GPT-1's knowledge comes from a substantial 40GB of text data, setting the groundwork for its comprehension and text generation skills.\n",
    "  - **Achievements**: It set new benchmarks in language modeling tasks like LAMBADA and showed commendable performance in GLUE and SQuAD, highlighting its understanding and application of language.\n",
    "  - **Memory and Context**: Capable of handling up to 512 tokens (equivalent to approximately 380 words), GPT-1 could process and remember details from short texts effectively.\n",
    "  - **Impact**: Its ability to generate text and perform well across various tasks spurred further research and development, leading to the creation of more advanced models in the GPT lineage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-2: Advancements and Features\n",
    "\n",
    "- **Evolution from GPT-1**: GPT-2 builds on its predecessor by maintaining the foundational architecture while significantly expanding its training data corpus and processing capabilities.\n",
    "  - **Increased Data and Capacity**: Trained on a much larger dataset, GPT-2 supports double the input size of GPT-1 and boasts nearly 1.5 billion parameters, enhancing its language modeling prowess.\n",
    "\n",
    "#### Major Enhancements in GPT-2\n",
    "- **Modified Objective Training**: Introduces advanced pre-training techniques to improve language model accuracy by incorporating additional linguistic context, such as parts of speech and subject-object relationships, for more coherent output.\n",
    "- **Layer Normalization**: Employs normalization at each layer to stabilize the internal state of the neural network, addressing the internal covariate shift and enhancing model training efficiency.\n",
    "- **Enhanced Sampling Algorithms**:\n",
    "  - **Top-p Sampling**: Filters tokens based on cumulative probability, favoring those with higher relevance and diversity.\n",
    "  - **Temperature Scaling**: Adjusts prediction randomness, allowing for a balance between predictability and creativity in text generation.\n",
    "  - **Unconditional Sampling**: Offers an option for purely random sampling, unlocking new possibilities for creative text generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-3: A Leap Forward in AI\n",
    "\n",
    "- **Massive Training Data Scale**: GPT-3's knowledge base exceeds 570 GB from diverse sources like Common Crawl, Wikipedia, and more, significantly larger than its predecessors.\n",
    "  - **Parametric Growth**: With 175 billion parameters, GPT-3's capacity for language understanding and generation is unparalleled.\n",
    "\n",
    "## Key Innovations in GPT-3\n",
    "- **GShard Implementation**: Facilitates model operation over multiple processors, enabling efficient handling of its extensive parameters for training and inference.\n",
    "- **Advanced Learning Abilities**:\n",
    "  - **Zero-shot Learning**: Empowers GPT-3 to tackle tasks without prior specific training, using its vast learned knowledge.\n",
    "  - **Few-shot Learning**: Demonstrates rapid adaptability to new tasks with minimal examples, showcasing its learning efficiency.\n",
    "- **Multilingual Proficiency**: Supports about 30 languages, making GPT-3 highly versatile for global language tasks.\n",
    "- **Refined Sampling Techniques**:\n",
    "  - Enhances text generation customization with improved algorithms and \"prompted\" sampling, allowing more controlled and varied text outputs based on user inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-3.5: Enhancements and Ethical Considerations\n",
    "\n",
    "- **Training Data and Size**: Inherits the vast data corpus of over 570 GB from GPT-3, ensuring a broad knowledge base.\n",
    "  - **Evolutionary Step**: GPT-3.5 builds upon GPT-3's capabilities, focusing on refining model behavior and output.\n",
    "\n",
    "## Distinguishing Features of GPT-3.5\n",
    "- **Reinforcement Learning with Human Feedback (RLHF)**: A novel approach to model training that aligns GPT-3.5 more closely with human values, emphasizing ethical AI usage.\n",
    "  - **Objective**: To reduce toxicity and enhance the truthfulness of the content, making interactions with GPT-3.5 safer and more aligned with user intentions.\n",
    "  - **Implementation**: Through RLHF, GPT-3.5 receives feedback on its outputs, learning to produce responses that are not only relevant and engaging but also ethically considerate.\n",
    "\n",
    "## Advancements Over GPT-3\n",
    "- **Fine-Tuning with RLHF**: This process allows GPT-3.5 to understand and follow a wider range of instructions more accurately, by incorporating direct human feedback into its learning cycle.\n",
    "  - **Outcome**: The model can correct its course based on evaluator feedback, leading to outputs that better reflect natural, engaging, and responsible language use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-4: Breakthroughs and Multimodal Processing\n",
    "\n",
    "- **Innovative Multimodal Capabilities**: GPT-4 elevates the GPT series by introducing the ability to interpret and generate text from both textual and visual inputs, supporting a variety of image formats for comprehensive understanding.\n",
    "  - **Versatile Input Handling**: Capable of analyzing documents, photos, diagrams, and more to produce relevant textual outputs, showcasing its advanced AI processing abilities.\n",
    "\n",
    "## Technical Aspects and Performance\n",
    "- **Unprecedented Scale**: Although specific details remain undisclosed, GPT-4 is believed to possess nearly 1 trillion parameters, indicating a substantial leap in modeling complexity and potential.\n",
    "  - **Core Training Objective**: Continues the tradition of predicting subsequent words based on preceding context, leveraging an extensive dataset for enhanced learning.\n",
    "  - **Performance Excellence**: Demonstrates remarkable improvements in factuality and reliability over GPT-3.5, validated through rigorous internal and external evaluations.\n",
    "\n",
    "## Continued Evolution and RLHF Integration\n",
    "- **RLHF Integration**: Inherits and refines the Reinforcement Learning with Human Feedback techniques from GPT-3.5, emphasizing ethical AI development and application.\n",
    "  - **Dynamic Enhancement**: OpenAI commits to ongoing optimization based on user interactions and feedback, ensuring GPT-4 remains at the forefront of AI technology.\n",
    "\n",
    "GPT-4's introduction of multimodal capabilities represents a significant advancement in AI, offering new possibilities for applications requiring sophisticated understanding and generation of content across various formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Evolution Across GPT Models\n",
    "\n",
    "## Overview of Model Achievements\n",
    "- **Consistent Progress**: The GPT series has shown remarkable advancements in NLP tasks, with each version outperforming the previous across standard benchmarks like GLUE, LAMBADA, and SQuAD.\n",
    "\n",
    "<img src=\"./images/GPTGLUE.png\" width=\"800\" align=\"center\"/>\n",
    "\n",
    "## Detailed Performance Metrics\n",
    "- **GPT-1 to GPT-4 Improvements**:\n",
    "  - Scores have consistently risen, reflecting enhancements in language understanding, reasoning, and specific task performance.\n",
    "- **GPT-3.5 and GPT-4**:\n",
    "  - These versions excel in newer, more demanding tests that assess reasoning and domain-specific knowledge.\n",
    "\n",
    "## Benchmarking Excellence\n",
    "- **MBE Exam Results**:\n",
    "  - GPT models have been evaluated against challenging benchmarks such as the MBE Exam, showcasing their growing proficiency in complex reasoning and knowledge areas, with GPT-4 surpassing average human scores.\n",
    "\n",
    "<img src=\"./images/GPTMBE.png\" width=\"800\" align=\"center\"/>\n",
    "\n",
    "\n",
    "<img src=\"./images/GPTLegalSubject.png\" width=\"800\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Industry Applications of OpenAI API\n",
    "\n",
    "## Overview\n",
    "The OpenAI API, powered by models like GPT-3 and GPT-4, is revolutionizing various industries with over 300 applications globally. \n",
    "\n",
    "## Key Use-Cases\n",
    "\n",
    "### Chatbots and Virtual Assistants\n",
    "- **Application**: Enhancing customer service and user interaction through intelligent, conversational agents.\n",
    "- **Benefits**: Provides natural and intuitive user experiences across digital platforms.\n",
    "\n",
    "### Sentiment Analysis\n",
    "- **Application**: Analyzing textual data to understand public opinion or customer satisfaction.\n",
    "- **Benefits**: Offers valuable insights for shaping business strategies and product development.\n",
    "\n",
    "### Image Recognition with CLIP\n",
    "- **Application**: Extends capabilities to visual tasks like object detection and classification.\n",
    "- **Benefits**: Opens avenues in healthcare for diagnosing conditions from medical images, among other applications.\n",
    "\n",
    "### Gaming and Reinforcement Learning\n",
    "- **Application**: Improving gaming experiences and developing autonomous gameplay strategies.\n",
    "- **Innovations**: Models like Dactyl and OpenAI Five demonstrate the potential in complex problem-solving and competitive gaming.\n",
    "\n",
    "These applications illustrate the versatility and impact of the OpenAI API across different sectors, driving innovation and enhancing user engagement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Environment\n",
    "\n",
    "### Creating an OpenAI Platform Account\n",
    "\n",
    "- Start by creating an account on the OpenAI platform to access its API services.\n",
    "- **Steps**:\n",
    "  1. Visit the [OpenAI website](https://openai.com/blog/openai-api).\n",
    "  2. Click on the sign-up option and follow the on-screen instructions to create an account.\n",
    "\n",
    "This initial step is crucial for obtaining the API key needed to make API calls.\n",
    "\n",
    "\n",
    "<img src=\"./images/OpenAIMenu.png\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "## OpenAI Playground\n",
    "\n",
    "- It is a web-based tool that makes it easy to test prompts and get familiar with how the API works. \n",
    "\n",
    "\n",
    "<img src=\"./images/OpenAIPlayGround.png\" height=\"500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are prompts?\n",
    "\n",
    "- Prompts involve instructions and context passed to a language model to achieve a desired task\n",
    "  - Prompt engineering is the practice of developing and optimizing prompts to efficiently use language models (LMs) for a variety of applications\n",
    "- Prompt engineering is a useful skill for AI engineers and researchers to improve and efficiently use language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Settings\n",
    "\n",
    "- **Interacting with LLMs via API**\n",
    "  - Utilize APIs to design and test prompts with Language Learning Models (LLMs).\n",
    "  - Configurable parameters enable varied prompt results.\n",
    "\n",
    "- **Parameter Configuration for Enhanced Outcomes**\n",
    "  - Adjusting settings is crucial for optimizing response reliability and desirability.\n",
    "  - Experimentation helps identify optimal settings for specific applications.\n",
    "\n",
    "\n",
    "- **Temperature:** Balancing Determinism and Creativity\n",
    "  - Lower temperatures yield more predictable results by favoring the most probable next token.\n",
    "  - Higher temperatures introduce randomness, fostering diverse or creative outputs.\n",
    "  - Application-specific settings:\n",
    "    - Lower temperature for fact-based queries to ensure accuracy and conciseness.\n",
    "    - Higher temperature for creative tasks like poetry to encourage innovation.\n",
    "\n",
    "- **Top P: Nucleus Sampling for Response Diversity**\n",
    "  - Controls model determinism alongside temperature.\n",
    "  - Lower values for precise, factual answers.\n",
    "  - Higher values for varied, innovative responses.\n",
    "  - Top P selection considers only the most probable tokens, balancing confidence and creativity.\n",
    "\n",
    "- **Max Length: Controlling Response Length**\n",
    "  - Adjusting max length manages the output token count.\n",
    "  - Helps avoid overly long or irrelevant responses, optimizing cost.\n",
    "\n",
    "- **Stop Sequences: Structuring Model Output**\n",
    "  - Defines a specific string to halt token generation.\n",
    "  - Enables precise control over response length and structure, like limiting list items.\n",
    "\n",
    "- **Frequency Penalty: Reducing Repetition**\n",
    "  - Applies penalties to repeated tokens based on occurrence frequency.\n",
    "  - Discourages word repetition, enhancing response diversity.\n",
    "\n",
    "- **Presence Penalty: Encouraging Uniqueness**\n",
    "  - Imposes penalties on all repeated tokens equally, regardless of frequency.\n",
    "  - Prevents phrase repetition, supporting text variety or focus.\n",
    "\n",
    "- **Parameter Adjustment Recommendations**\n",
    "  - Advise altering temperature or Top P, and frequency or presence penalty, but not both simultaneously for balanced outcomes.\n",
    "\n",
    "- **LLM Version Considerations**\n",
    "  - Outcomes may vary with different LLM versions, emphasizing the importance of version awareness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics of Prompting\n",
    "- Simple prompts can lead to significant achievements.\n",
    "- The quality of outcomes is influenced by the prompt's detail.\n",
    "- Prompts should encompass:\n",
    "  - Instructions or questions directed at the model.\n",
    "  - Contextual information to clarify the prompt.\n",
    "  - Relevant inputs or data points.\n",
    "  - Examples to guide expected responses.\n",
    "\n",
    "## Roles in Prompting\n",
    "- When using OpenAI chat models (e.g., GPT-3.5-turbo, GPT-4),\n",
    "  - Prompts can be structured with three roles: **system**, **user**, and **assistant**.\n",
    "- The system message, while not mandatory, can influence the assistant's overall behavior.\n",
    "- Typically, examples focus on *user messages* for direct model prompting.\n",
    "- Except for specific mentions, examples primarily utilize the user message to interact with the GPT-3.5-turbo model.\n",
    "- The assistant message reflects the model's response and can be crafted to showcase desired outcomes.\n",
    "\n",
    "- **Example**\n",
    "<img src=\"./images/basicPrompt.png\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "- This llustrates its ability to generate contextually relevant sequences of tokens.\n",
    "- Outputs may not always align with the intended task or expectation.\n",
    "- This basic interaction emphasizes the need for detailed context and precise instructions within prompts to guide the model towards desired outcomes.\n",
    "\n",
    "Let's try to improve it a bit:\n",
    "\n",
    "<img src=\"./images/improvedPrompt.png\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "- Refining the prompt to specifically instruct the model to \"complete the sentence\" \n",
    "  - Significantly improves the clarity and relevance of the response.\n",
    "- Such an approach not only enhances response quality but also showcases the broad capabilities of current language learning models (LLMs).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Formatting\n",
    "\n",
    "\n",
    "- A standard prompt has the following format\n",
    "  - <Question>?\n",
    "  - <Instruction>\n",
    "  \n",
    "- A question answering format\n",
    "  - Q: <Question>?\n",
    "  - A: \n",
    "  - This is also called Zero-shot prompting\n",
    "    - Asking a model directly without examples.\n",
    "    - It depends on the model's built-in knowledge and training.\n",
    "    - Effectiveness varies by task complexity and model optimization.\n",
    "    - LLMs' ability for zero-shot tasks differs based on their training.\n",
    "\n",
    "\n",
    "**Example**\n",
    "- Q: What is prompt engineering?\n",
    "\n",
    "<img src=\"./images/questionprompt.png\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Few-shot prompting involves providing exemplars (demonstrations).\n",
    "- This technique enhances model understanding and response accuracy.\n",
    "- Format involves directly integrating examples within the prompt.\n",
    "\n",
    "```\n",
    "\n",
    "<Question>?\n",
    "<Answer>\n",
    "\n",
    "<Question>?\n",
    "<Answer>\n",
    "\n",
    "<Question>?\n",
    "<Answer>\n",
    "\n",
    "<Question>?\n",
    "\n",
    "```\n",
    "\n",
    "- QA format is not mandatory for few-shot prompting.\n",
    "- Prompt format should align with the specific task.\n",
    "- For classification tasks, include exemplars demonstrating the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example: **\n",
    "\n",
    "Prompt:\n",
    "```\n",
    "This is awesome! // Positive\n",
    "This is bad! // Negative\n",
    "Wow that movie was rad! // Positive\n",
    "What a horrible show! //\n",
    "```\n",
    "**Output:**\n",
    "<img src=\"./images/QAprompt.png\" height=\"300\" align=\"center\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Few-shot prompts facilitate in-context learning for language models.\n",
    "- Demonstrations within prompts teach models to perform tasks.\n",
    "- Zero-shot and few-shot prompting explored in detail in further sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Elements of a Prompt**\n",
    "\n",
    "- Elements of a prompt include:\n",
    "  - **Instruction**: Task or direction for the model.\n",
    "  - **Context**: Additional information to guide responses.\n",
    "  - **Input Data**: The question or input seeking a response.\n",
    "  - **Output Indicator**: Desired type/format of output.\n",
    "- Example provided illustrates a text classification task prompt.\n",
    "\n",
    "```\n",
    "Classify the text into neutral, negative, or positive\n",
    "\n",
    "Text: I think the food was okay.\n",
    "\n",
    "Sentiment:\n",
    "```\n",
    "\n",
    "- **Instruction Example**: \"Classify the text into neutral, negative, or positive.\"\n",
    "- **Input Data Example**: \"I think the food was okay.\"\n",
    "- **Output Indicator Example**: \"Sentiment:\"\n",
    "- **Context**: Not used in this basic example, but can include additional examples within the prompt to aid the model's understanding and direct expected outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **General Tips to Desing Prompts**\n",
    "\n",
    "- **Start with Simple Prompts**\n",
    "  - Start with simple prompts using platforms like OpenAI.\n",
    "  - Iterative process: Experiment and refine for optimal results.\n",
    "  - Add elements and context gradually to improve responses.\n",
    "  - Specificity, simplicity, and conciseness often yield better outcomes.\n",
    "  - For complex tasks, break down into simpler subtasks and build up progressively.\n",
    "  - Avoid initial complexity in prompt design for ease of iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **General Tips to Desing Prompts**\n",
    "\n",
    "- **Be clear in the Instruction**\n",
    "  - Use clear commands in prompts: \n",
    "    - \"Write,\" \n",
    "    - \"Classify,\" \n",
    "    - \"Summarize,\" \n",
    "    - \"Translate,\"\n",
    "    -  \"Order,\"\n",
    "    -   etc.\n",
    "  - **Experimentation** is key: Test various instructions, keywords, contexts, and data.\n",
    "  - Specificity and relevance of context enhance task performance.\n",
    "  - Instructions often placed at prompt start for clarity.\n",
    "  - Consider using separators (e.g., \"###\") to distinguish instruction and context.\n",
    "- Example\n",
    "```\n",
    "### Instruction ###\n",
    "Translate the text below to Spanish:\n",
    "\n",
    "Text: \"hello!\"\n",
    "```\n",
    "\n",
    "<img src=\"./images/instruction.png\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **General Tips to Desing Prompts**\n",
    "- Be Specific\n",
    "  - Aim for detailed, descriptive instructions for clearer outcomes.\n",
    "  - Specificity and detail enhance response accuracy and relevance.\n",
    "    - Include examples within prompts for format-specific outputs.\n",
    "  - Be mindful of prompt length due to limitations.\n",
    "  - Focus on relevant details that contribute directly to the task.\n",
    "  - Experiment and iterate prompts to find the optimal structure and content.\n",
    "\n",
    "- **Example**\n",
    "```\n",
    "Extract the name of places in the following text. \n",
    "\n",
    "Desired format:\n",
    "Place: <comma_separated_list_of_company_names>\n",
    "\n",
    "Input: \"Although these developments are encouraging to researchers, much is still a mystery. “We often have a black box between the brain and the effect we see in the periphery,” says Henrique Veiga-Fernandes, a neuroimmunologist at the Champalimaud Centre for the Unknown in Lisbon. “If we want to use it in the therapeutic context, we actually need to understand the mechanism.“\"\n",
    "```\n",
    "\n",
    "<img src=\"./images/specificity.png\" height=\"400\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Be precise**\n",
    "  - Avoid overcomplicating prompts with cleverness that may lead to imprecision.\n",
    "  - Specificity and directness enhance prompt clarity and effectiveness.\n",
    "  - Effective communication principles apply: directness ensures message clarity.\n",
    "  - For learning concepts like prompt engineering, straightforward approaches are recommended.\n",
    "\n",
    "Explain the concept prompt engineering. Keep the explanation short, only a few sentences, and don't be too descriptive.\n",
    "\n",
    "```\n",
    "Explain the concept prompt engineering. Keep the explanation short, only a few sentences, and don't be too descriptive.\n",
    "```\n",
    "\n",
    "<img src=\"./images/vague_1.png\" height=\"400\" align=\"center\"/>\n",
    "\n",
    "\n",
    "- While general prompts may yield acceptable responses, specificity improves outcome quality.\n",
    "- Ideal prompts are specific, concise, and directly address the task.\n",
    "\n",
    "a better version:\n",
    "\n",
    "```\n",
    "Use 2-3 sentences to explain the concept of prompt engineering to a high school student.\n",
    "```\n",
    "\n",
    "<img src=\"./images/vague_2.png\" height=\"400\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Focus prompts on actions to perform rather than actions to avoid.\n",
    "- Encourages specificity and directs attention to desired outcomes.\n",
    "- Example illustrates a movie recommendation chatbot misunderstanding due to negative instruction focus.\n",
    "```\n",
    "The following is an agent that recommends movies to a customer. DO NOT ASK FOR INTERESTS. DO NOT ASK FOR PERSONAL INFORMATION.\n",
    "\n",
    "Customer: Please recommend a movie based on my interests.\n",
    "Agent: \n",
    "```\n",
    "<img src=\"./images/ex_1.png\" height=\"400\" align=\"center\"/>\n",
    "\n",
    "Better Prompt:\n",
    "\n",
    "```\n",
    "The following is an agent that recommends movies to a customer. The agent is responsible to recommend a movie from the top global trending movies. It should refrain from asking users for their preferences and avoid asking for personal information. If the agent doesn't have a movie to recommend, it should respond \"Sorry, couldn't find a movie to recommend today.\".\n",
    "\n",
    "Customer: Please recommend a movie based on my interests.\n",
    "Agent:\n",
    "```\n",
    "\n",
    "<img src=\"./images/ex_2.png\" height=\"400\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Exmaples of Prompts**\n",
    "  - Building on basic examples to explore diverse tasks.\n",
    "  - Key concepts introduced through practical examples.\n",
    "  - Demonstrates the power of well-crafted prompts.\n",
    "  - Each example tailored to specific tasks for optimal results.\n",
    "\n",
    "- **Tasks**\n",
    "  - **Text Summarization**: Condensing large texts into concise summaries.\n",
    "  - **Information Extraction**: Pulling specific data or facts from text.\n",
    "  - **Question Answering**: Providing direct answers to posed questions.\n",
    "  - **Text Classification**: Categorizing text into predefined classes.\n",
    "  - **Conversation**: Engaging in dialogue with a set purpose or spontaneity.\n",
    "  - **Code Generation**: Creating code snippets based on requirements.\n",
    "  - **Reasoning**: Solving problems or deducing conclusions from given information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Understanding Text Summarization**\n",
    "  - A key task in natural language generation.\n",
    "  - Involves creating concise summaries from longer texts.\n",
    "  - Applicable across various flavors and domains.\n",
    "\n",
    "- **Applications of Language Models**\n",
    "  - Summarizing articles and concepts into accessible summaries.\n",
    "  - Enhances quick understanding and knowledge acquisition.\n",
    "\n",
    "- **Example**\n",
    "  - Interest in learning about antibiotics.\n",
    "  - Example prompt: Requesting a summary on antibiotics for quick learning.\n",
    "  ```\n",
    "  Explain antibiotics\n",
    "    A:\n",
    "    \n",
    "  ```\n",
    "<img src=\"./images/summary_1.png\" height=\"400\" align=\"center\"/>\n",
    "  - **Using Explicit Prompt Formats**\n",
    "  - \"A:\" format signals an expected answer, useful in Q&A tasks.\n",
    "  - Demonstrates how to guide model responses.\n",
    "\n",
    "- **Assessing Information Overload**\n",
    "  - Identifying when details may be excessive for the task.\n",
    "\n",
    "- **Further Summarization Instruction**\n",
    "  - Directive to condense information into a single sentence.\n",
    "  - Enhances focus and brevity in model output.\n",
    "\n",
    "```\n",
    "Antibiotics are a type of medication used to treat bacterial infections. They work by either killing the bacteria or preventing them from reproducing, allowing the body’s immune system to fight off the infection. Antibiotics are usually taken orally in the form of pills, capsules, or liquid solutions, or sometimes administered intravenously. They are not effective against viral infections, and using them inappropriately can lead to antibiotic resistance.\n",
    "\n",
    "Explain the above in one sentence:\n",
    "\n",
    "```\n",
    "\n",
    "<img src=\"./images/summary_2.png\" height=\"400\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Information Extraction**\n",
    "\n",
    "     - They are capable of doing NLP tasks such as classification among a broad range of capabilities.\n",
    "\n",
    "- **Information Extraction Example**\n",
    "  - Demonstrates using a prompt to extract specific details from a paragraph.\n",
    "\n",
    "```\n",
    "Author-contribution statements and acknowledgements in research papers should state clearly and specifically whether, and to what extent, the authors used AI technologies such as ChatGPT in the preparation of their manuscript and analysis. They should also indicate which LLMs were used. This will alert editors and reviewers to scrutinize manuscripts more carefully for potential biases, inaccuracies and improper source crediting. Likewise, scientific journals should be transparent about their use of LLMs, for example when selecting submitted manuscripts.\n",
    "\n",
    "Mention the large language model based product mentioned in the paragraph above:\n",
    "\n",
    "```\n",
    "\n",
    "<img src=\"./images/ie_1.png\" height=\"400\" align=\"center\"/>\n",
    "\n",
    "- **Enhancing Model Performance**\n",
    "  - Multiple strategies exist to refine and improve results.\n",
    "  - Initial outcomes often already provide substantial utility.\n",
    "\n",
    "- Direct instructions enable varied task execution by the model.\n",
    "- AI's capacity to follow explicit prompts is a key tool for developers.\n",
    "  - Facilitates the creation of innovative products and user experiences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question Answering**\n",
    "\n",
    "- **Enhancing Response Quality**\n",
    "  - Structured prompts significantly improve model accuracy.\n",
    "  - Key components: clear instructions, relevant context, precise input, and specific output expectations.\n",
    "\n",
    "- **Specificity Leads to Accuracy**\n",
    "  - Detailed and direct instructions yield better model performance.\n",
    "  - A structured prompt is essential for clear and effective communication.\n",
    "\n",
    "- **Example of a Structured Prompt**\n",
    "  - Showcases the effectiveness of combining all elements for clear guidance.\n",
    "  - Emphasizes the role of each component in achieving desired results.\n",
    "\n",
    "```\n",
    "Answer the question based on the context below. Keep the answer short and concise. Respond \"Unsure about answer\" if not sure about the answer.\n",
    "\n",
    "Context: Teplizumab traces its roots to a New Jersey drug company called Ortho Pharmaceutical. There, scientists generated an early version of the antibody, dubbed OKT3. Originally sourced from mice, the molecule was able to bind to the surface of T cells and limit their cell-killing potential. In 1986, it was approved to help prevent organ rejection after kidney transplants, making it the first therapeutic antibody allowed for human use.\n",
    "\n",
    "Question: What was OKT3 originally sourced from?\n",
    "\n",
    "Answer:\n",
    "```\n",
    "\n",
    "<img src=\"./images/qa_1.png\" height=\"400\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Text Classification**\n",
    "\n",
    "- This is more complicated than previous tasks\n",
    "- Effective instruction goes hand in hand with understanding task complexity.\n",
    "- **Enhancing Prompts with Additional Elements**\n",
    "  - For complex scenarios, instructions alone may not suffice.\n",
    "  - Adding context, input data, and examples enriches the prompt, aiding in task execution.\n",
    "\n",
    "- **Demonstration through Text Classification**\n",
    "  - Providing a clear, enriched prompt example for classifying text.\n",
    "  - Illustrates how incorporating various elements can lead to more accurate outcomes.\n",
    "\n",
    "```\n",
    "Classify the text into neutral, negative or positive. \n",
    "\n",
    "Text: I think the food was okay. \n",
    "Sentiment:\n",
    "```\n",
    "<img src=\"./images/cls_1.png\" height=\"400\" align=\"center\"/>\n",
    "\n",
    "- Instruction given for text classification; model correctly responded with 'Neutral'.\n",
    "- Requirement for output in a specific format, e.g., 'neutral' instead of 'Neutral'.\n",
    "- Achieving desired format involves various strategies focused on prompt specificity.\n",
    "- Providing more information within the prompt leads to better accuracy.\n",
    "- Utilizing examples within the prompt to demonstrate the correct output behavior.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Successful output adjustment to 'neutral' as specified.\n",
    "- The inclusion of an example in the prompt guided the model to the precise output.\n",
    "- Importance of specificity in achieving desired response formats.\n",
    "\n",
    "```\n",
    "Classify the text into nutral, negative or positive. \n",
    "\n",
    "Text: I think the vacation is okay.\n",
    "Sentiment:\n",
    "```\n",
    "<img src=\"./images/cls_2.png\" height=\"400\" align=\"center\"/>\n",
    "\n",
    "- Model ignores the custom label 'nutral', defaulting to 'Neutral'.\n",
    "- Model bias towards standard labels over custom ones highlighted.\n",
    "- To achieve the desired 'nutral' label, consider:\n",
    "  - Enhancing prompts with label descriptions.\n",
    "  - Incorporating additional examples demonstrating the 'nutral' usage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Conversation**\n",
    "\n",
    "- Prompt engineering allows for specifying LLM system behavior, intent, and identity.\n",
    "- Especially useful in creating conversational systems, such as customer service chatbots.\n",
    "- Example: Crafting a system for technical and scientific question responses.\n",
    "- Employing explicit instructions to guide system behavior is known as role prompting.\n",
    "\n",
    "```\n",
    "The following is a conversation with an AI research assistant. The assistant tone is technical and scientific.\n",
    "\n",
    "Human: Hello, who are you?\n",
    "AI: Greeting! I am an AI research assistant. How can I help you today?\n",
    "Human: Can you tell me about the creation of blackholes?\n",
    "AI:\n",
    "\n",
    "```\n",
    "\n",
    "<img src=\"./images/con_1.png\" height=\"400\" align=\"center\"/>\n",
    "\n",
    "\n",
    "- Adjusting the AI research assistant's tone from technical to more accessible.\n",
    "\n",
    "<img src=\"./images/con_2.png\" height=\"400\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Code Generation**\n",
    "- LLMs excel in code generation tasks, exemplified by Copilot.\n",
    "- Clever prompts enable a wide range of code-generation applications.\n",
    "- Examples illustrate the versatility and capability of LLMs in coding contexts.\n",
    "\n",
    "```\n",
    "code for a function \n",
    "/*\n",
    "Ask the user for their name and say \"Hello\"\n",
    "*/\n",
    "\n",
    "```\n",
    "\n",
    "<img src=\"./images/cod_1.png\" height=\"400\" align=\"center\"/>\n",
    "\n",
    "Notice that you didn't even need to specify the language to use.\n",
    "\n",
    "```\n",
    "\n",
    "\"\"\"\n",
    "Table departments, columns = [DepartmentId, DepartmentName]\n",
    "Table students, columns = [DepartmentId, StudentId, StudentName]\n",
    "Create a MySQL query for all students in the Computer Science Department\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "<img src=\"./images/cod_2.png\" height=\"400\" align=\"center\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Reasoning**\n",
    "\n",
    "- Reasoning represents a challenging yet fascinating domain for LLMs.\n",
    "- Complex applications can arise from LLMs' ability to reason.\n",
    "- Improvements noted in LLMs' mathematical reasoning capabilities.\n",
    "- Despite advancements, LLMs still face challenges with reasoning tasks.\n",
    "- Advanced prompt engineering techniques necessary for enhancing LLM reasoning.\n",
    "- Upcoming guides to detail these advanced techniques.\n",
    "- Initial examples will demonstrate LLMs' arithmetic capabilities.\n",
    "\n",
    "\n",
    "simple prompt:\n",
    "\n",
    "```\n",
    "What is 9,000 * 9,000?\n",
    "\n",
    "```\n",
    "\n",
    "<img src=\"./images/re_1.png\" height=\"400\" align=\"center\"/>\n",
    "\n",
    "More complicated:\n",
    "\n",
    "```\n",
    "The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1. \n",
    "\n",
    "A: \n",
    "```\n",
    "\n",
    "<img src=\"./images/re_2.png\" height=\"400\" align=\"center\"/>\n",
    "\n",
    "Ooops!!!\n",
    "\n",
    "```\n",
    "The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1. \n",
    "\n",
    "Solve by breaking the problem into steps. First, identify the odd numbers, add them, and indicate whether the result is odd or even. \n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "<img src=\"./images/re_3.png\" height=\"400\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Prompt Engeering in Python!**\n",
    "\n",
    "- Load the libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade openai\n",
    "!pip install --upgrade langchain\n",
    "!pip install --upgrade python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/mzihayat/VSC/Prompt_Engineering/Day-1/Part-2.ipynb Cell 67\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mzihayat/VSC/Prompt_Engineering/Day-1/Part-2.ipynb#Y126sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mopenai\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mzihayat/VSC/Prompt_Engineering/Day-1/Part-2.ipynb#Y126sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mzihayat/VSC/Prompt_Engineering/Day-1/Part-2.ipynb#Y126sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mIPython\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openai'"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import IPython\n",
    "from langchain.llms import OpenAi\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# API configuration\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# for LangChain\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_open_params(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=256,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "):\n",
    "    \"\"\" set openai parameters\"\"\"\n",
    "\n",
    "    openai_params = {}    \n",
    "\n",
    "    openai_params['model'] = model\n",
    "    openai_params['temperature'] = temperature\n",
    "    openai_params['max_tokens'] = max_tokens\n",
    "    openai_params['top_p'] = top_p\n",
    "    openai_params['frequency_penalty'] = frequency_penalty\n",
    "    openai_params['presence_penalty'] = presence_penalty\n",
    "    return openai_params\n",
    "\n",
    "def get_completion(params, messages):\n",
    "    \"\"\" GET completion from openai api\"\"\"\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model = params['model'],\n",
    "        messages = messages,\n",
    "        temperature = params['temperature'],\n",
    "        max_tokens = params['max_tokens'],\n",
    "        top_p = params['top_p'],\n",
    "        frequency_penalty = params['frequency_penalty'],\n",
    "        presence_penalty = params['presence_penalty'],\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Text Summarization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = set_open_params(temperature=0.7)\n",
    "prompt = \"\"\"Antibiotics are a type of medication used to treat bacterial infections. They work by either killing the bacteria or preventing them from reproducing, allowing the body's immune system to fight off the infection. Antibiotics are usually taken orally in the form of pills, capsules, or liquid solutions, or sometimes administered intravenously. They are not effective against viral infections, and using them inappropriately can lead to antibiotic resistance. \n",
    "\n",
    "Explain the above in one sentence:\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Code Generation**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\\\"\\\"\\\"\\nTable departments, columns = [DepartmentId, DepartmentName]\\nTable students, columns = [DepartmentId, StudentId, StudentName]\\nCreate a MySQL query for all students in the Computer Science Department\\n\\\"\\\"\\\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
