{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Outline**\n",
    "\n",
    "- Generating Data and Synthetic Datasets\n",
    "- Case Study: Graduate Job Classification\n",
    "- Workshop: Tackling Generated Datasets Diversity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m venv openai-env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!source openai-env/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (1.13.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from openai) (2.6.1)\n",
      "Requirement already satisfied: sniffio in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI()\n",
    "# defaults to getting the key using os.environ.get(\"OPENAI_API_KEY\")\n",
    "# if you saved the key under a different environment variable name, you can do something like:\n",
    "client = OpenAI(\n",
    "  api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"In the realm of code, there lies a magical loop,\\nWhere functions call themselves, in a dance so smooth.\\nRecursion, they call it, a mystical art,\\nUnraveling problems, touching every part.\\n\\nLike a never-ending mirror reflecting its own face,\\nA function calls itself, with elegance and grace.\\nBreaking down tasks into smaller bites,\\nSolving complexities, reaching new heights.\\n\\nA journey through layers, deep and profound,\\nIn a world where solutions are easily found.\\nEach recursive call a story untold,\\nUnfolding mysteries, turning lead into gold.\\n\\nBut caution is key, in this recursive domain,\\nFor infinite loops could drive one insane.\\nBase case guards the path, to set one free,\\nFrom the cycle of endless reverie.\\n\\nSo embrace recursion, with courage in your heart,\\nLet your code intertwine, like vines that never part.\\nIn the symphony of functions, let beauty bloom,\\nFor in the depths of recursion, lies a programmer's room.\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Function Calling with LLMs**\n",
    "  - Enables LLMs like GPT-4 and GPT-3.5 to reliably connect with external tools and APIs.\n",
    "  - Detects the need for a function call within a chat and outputs JSON with arguments to execute the function.\n",
    "\n",
    "- **Tool Integration:**\n",
    "  - Functions act as tools within AI applications, allowing for multiple tools to be defined and called in a single request.\n",
    "\n",
    "- **Importance for AI Applications:**\n",
    "  - Essential for developing LLM-powered chatbots or agents that require context retrieval or need to interact with external tools.\n",
    "  - Transforms natural language instructions into actionable API calls, enhancing the utility and interactivity of chatbots.\n",
    "\n",
    "- **Enhancing Chatbot Capabilities:**\n",
    "  - Facilitates seamless integration of LLMs with a wide range of external services and data sources.\n",
    "  - Enables chatbots to perform complex tasks, such as data retrieval, content creation, and more, by calling specific functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Applications Enabled by Functional Calling**\n",
    "\n",
    "- **Conversational Agents with External Tool Usage:**\n",
    "  - Allows conversational agents to efficiently utilize external tools to answer user questions.\n",
    "  - Example: Querying weather information translates to function calls like `get_current_weather(location: string, unit: 'celsius' | 'fahrenheit')`.\n",
    "\n",
    "- **Data Extraction and Tagging Solutions:**\n",
    "  - Empowers LLM-powered solutions to extract and tag data from various sources.\n",
    "  - Example: Extracting people names from a Wikipedia article.\n",
    "\n",
    "- **Natural Language to API Conversion:**\n",
    "  - Facilitates the creation of applications that translate natural language into API calls or database queries.\n",
    "  - Enhances the usability and accessibility of data and services.\n",
    "\n",
    "- **Conversational Knowledge Retrieval Engines:**\n",
    "  - Enables conversational engines to interact with knowledge bases, facilitating knowledge retrieval through natural language queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Function Calling with GPT-4**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Integration of LLM with External Tool for Weather Query**\n",
    "  - **Challenge:**\n",
    "    - LLM alone cannot respond to dynamic queries like checking the weather due to dataset limitations.\n",
    "  - **Solution:**\n",
    "    - Utilize function calling capabilities of the LLM to invoke an external tool for weather information retrieval.\n",
    "\n",
    "  - **Implementation Example:**\n",
    "    - User query: \"What is the weather like in a given location?\"\n",
    "    - LLM processes the query and recognizes the need for external information.\n",
    "    - Function calling mechanism selects appropriate function and arguments (e.g., `get_current_weather(location: string, unit: 'celsius' | 'fahrenheit')`).\n",
    "    - OpenAI APIs facilitate the interaction between the LLM and the weather API.\n",
    "    - Final response generated based on the retrieved weather data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "What is the weather like in London?\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To handle this request using function calling,\n",
    "  - Define a weather function or set of functions that you will be passing as part of the OpenAI API request\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
    "                    },\n",
    "                    \"unit\": {\n",
    "                        \"type\": \"string\", \n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"]\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Function Details:\n",
    "  - Name: get_current_weather\n",
    "  - Description: Retrieves the current weather in a specified location.\n",
    "  - Parameters:\n",
    "    - location: Specifies the city and state (e.g., San Francisco, CA).\n",
    "    - unit: Specifies the temperature unit (celsius or fahrenheit).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a completion function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(client, messages, model=\"gpt-3.5-turbo-1106\", temperature=0, max_tokens=300, tools=None):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        tools=tools\n",
    "    )\n",
    "    return response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compose the user question:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What is the weather like in London?\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_completion(client, messages, tools=tools)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
