{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Outline**\n",
    "\n",
    "- Generating Data and Synthetic Datasets\n",
    "- Case Study: Sentiment Analysis\n",
    "- Workshop: Tackling Generated Datasets Diversity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m venv openai-env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!source openai-env/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (1.13.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from openai) (2.6.1)\n",
      "Requirement already satisfied: sniffio in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI()\n",
    "# defaults to getting the key using os.environ.get(\"OPENAI_API_KEY\")\n",
    "# if you saved the key under a different environment variable name, you can do something like:\n",
    "client = OpenAI(\n",
    "  api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"In the realm of code, a concept quite grand,\\nIs recursion, a magical hand,\\nLike a mirror reflecting its own image,\\nA function that calls itself with courage.\\n\\nA puzzle solved by breaking it down,\\nInto smaller tasks, it wears the crown,\\nWith elegance and power it repeats,\\nSolving problems in defining feats.\\n\\nThrough layers of depth, it delves,\\nInto the unknown, where mystery dwells,\\nEach recursive call, a journey anew,\\nUnraveling complexity, it's true.\\n\\nA loop within a loop, a cycle unbroken,\\nInfinite possibilities, words unspoken,\\nA dance of logic, a pattern that gleams,\\nRecursion in programming, a poet's dreams.\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Function Calling with LLMs**\n",
    "  - Enables LLMs like GPT-4 and GPT-3.5 to reliably connect with external tools and APIs.\n",
    "  - Detects the need for a function call within a chat and outputs JSON with arguments to execute the function.\n",
    "\n",
    "- **Tool Integration:**\n",
    "  - Functions act as tools within AI applications, allowing for multiple tools to be defined and called in a single request.\n",
    "\n",
    "- **Importance for AI Applications:**\n",
    "  - Essential for developing LLM-powered chatbots or agents that require context retrieval or need to interact with external tools.\n",
    "  - Transforms natural language instructions into actionable API calls, enhancing the utility and interactivity of chatbots.\n",
    "\n",
    "- **Enhancing Chatbot Capabilities:**\n",
    "  - Facilitates seamless integration of LLMs with a wide range of external services and data sources.\n",
    "  - Enables chatbots to perform complex tasks, such as data retrieval, content creation, and more, by calling specific functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Applications Enabled by Functional Calling**\n",
    "\n",
    "- **Conversational Agents with External Tool Usage:**\n",
    "  - Allows conversational agents to efficiently utilize external tools to answer user questions.\n",
    "  - Example: Querying weather information translates to function calls like `get_current_weather(location: string, unit: 'celsius' | 'fahrenheit')`.\n",
    "\n",
    "- **Data Extraction and Tagging Solutions:**\n",
    "  - Empowers LLM-powered solutions to extract and tag data from various sources.\n",
    "  - Example: Extracting people names from a Wikipedia article.\n",
    "\n",
    "- **Natural Language to API Conversion:**\n",
    "  - Facilitates the creation of applications that translate natural language into API calls or database queries.\n",
    "  - Enhances the usability and accessibility of data and services.\n",
    "\n",
    "- **Conversational Knowledge Retrieval Engines:**\n",
    "  - Enables conversational engines to interact with knowledge bases, facilitating knowledge retrieval through natural language queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Function Calling with GPT-4**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Integration of LLM with External Tool for Weather Query**\n",
    "  - **Challenge:**\n",
    "    - LLM alone cannot respond to dynamic queries like checking the weather due to dataset limitations.\n",
    "  - **Solution:**\n",
    "    - Utilize function calling capabilities of the LLM to invoke an external tool for weather information retrieval.\n",
    "\n",
    "  - **Implementation Example:**\n",
    "    - User query: \"What is the weather like in a given location?\"\n",
    "    - LLM processes the query and recognizes the need for external information.\n",
    "    - Function calling mechanism selects appropriate function and arguments (e.g., `get_current_weather(location: string, unit: 'celsius' | 'fahrenheit')`).\n",
    "    - OpenAI APIs facilitate the interaction between the LLM and the weather API.\n",
    "    - Final response generated based on the retrieved weather data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "What is the weather like in London?\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To handle this request using function calling,\n",
    "  - Define a weather function or set of functions that you will be passing as part of the OpenAI API request\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
    "                    },\n",
    "                    \"unit\": {\n",
    "                        \"type\": \"string\", \n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"]\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Function Details:\n",
    "  - Name: get_current_weather\n",
    "  - Description: Retrieves the current weather in a specified location.\n",
    "  - Parameters:\n",
    "    - location: Specifies the city and state (e.g., San Francisco, CA).\n",
    "    - unit: Specifies the temperature unit (celsius or fahrenheit).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a completion function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(client, messages, model=\"gpt-3.5-turbo-1106\", temperature=0, max_tokens=300, tools=None, tool_choice=None):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        tools=tools,\n",
    "        tool_choice=tool_choice\n",
    "    )\n",
    "    return response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compose the user question:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What is the weather like in London?\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_q17T7UG98lVTh9XMuZcb0yrv', function=Function(arguments='{\"location\":\"London\",\"unit\":\"celsius\"}', name='get_current_weather'), type='function')])\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(client, messages, tools=tools)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capture the arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "args = json.loads(response.tool_calls[0].function.arguments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines a dummy function to get the current weather\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    weather = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": \"50\",\n",
    "        \"unit\": unit,\n",
    "    }\n",
    "\n",
    "    return json.dumps(weather)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"location\": \"London\", \"temperature\": \"50\", \"unit\": \"celsius\"}'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_weather(**args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **An LLM-powered conversational agent**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Hello! How are you?\",\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_completion() missing 1 required positional argument: 'messages'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/mzihayat/VSC/Prompt_Engineering/Day-3/Part-1.ipynb Cell 30\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mzihayat/VSC/Prompt_Engineering/Day-3/Part-1.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m get_completion(messages, tools\u001b[39m=\u001b[39;49mtools)\n",
      "\u001b[0;31mTypeError\u001b[0m: get_completion() missing 1 required positional argument: 'messages'"
     ]
    }
   ],
   "source": [
    "get_completion(messages, tools=tools)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Specify desired behavior for function calling to tailor the response generation process according to specific requirements.\n",
    "- By default, the model autonomously determines whether to call a function and which function to call.\n",
    "-  Utilize the tool_choice parameter to control the behavior of the system.\n",
    "- Default setting: tool_choice: \"auto\".\n",
    "\n",
    "- In \"auto\" mode, the model automatically decides whether and which function to call based on the context of the user query.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=\"Hello! I'm here and ready to assist you. How can I help you today?\", role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(client, messages, tools=tools, tool_choice=\"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=\"Hello! I'm here and ready to assist you. How can I help you today?\", role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(client, messages, tools=tools, tool_choice=\"none\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forces the model to not use any of the functions provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='I will check the current weather in London for you.', role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's the weather like in London?\",\n",
    "    }\n",
    "]\n",
    "get_completion(client, messages, tools=tools, tool_choice=\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Force the model to choose a function if that's the behavior you want in your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_dh0nudIqqUzA3YLm51IXh2EJ', function=Function(arguments='{\"location\":\"London\",\"unit\":\"celsius\"}', name='get_current_weather'), type='function')])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's the weather like in London?\",\n",
    "    }\n",
    "]\n",
    "get_completion(client, messages, tools=tools, tool_choice={\"type\": \"function\", \"function\": {\"name\": \"get_current_weather\"}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Develop an agent that passes back the result obtained after calling your APIs with the inputs generated from function calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"user\", \"content\": \"What's the weather like in Boston!\"})\n",
    "assistant_message = get_completion(client, messages, tools=tools, tool_choice=\"auto\")\n",
    "assistant_message = json.loads(assistant_message.model_dump_json())\n",
    "assistant_message[\"content\"] = str(assistant_message[\"tool_calls\"][0][\"function\"])\n",
    "\n",
    "#a temporary patch but this should be handled differently\n",
    "# remove \"function_call\" from assistant message\n",
    "del assistant_message[\"function_call\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(assistant_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the weather information to pass back to the model\n",
    "weather = get_current_weather(messages[1][\"tool_calls\"][0][\"function\"][\"arguments\"])\n",
    "\n",
    "messages.append({\"role\": \"tool\",\n",
    "                 \"tool_call_id\": assistant_message[\"tool_calls\"][0][\"id\"],\n",
    "                 \"name\": assistant_message[\"tool_calls\"][0][\"function\"][\"name\"],\n",
    "                 \"content\": weather})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_response = get_completion(client, messages, tools=tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='The current weather in Boston, MA is 50°F.', role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Generating Data**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LLMs possess powerful text generation capabilities for creating coherent text.\n",
    "- Implementing effective prompt strategies enhances the quality, consistency, and factual accuracy of the model's outputs.\n",
    "- LLMs are invaluable for generating datasets, facilitating a wide range of experiments and evaluations.\n",
    "- They can be utilized for quick sample generation in applications, such as training a sentiment classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Produce 10 exemplars for sentiment analysis. Examples are categorized as either positive or negative. Produce 2 negative examples and 8 positive examples. Use this format for the examples:\n",
    "Q: <sentence>\n",
    "A: <sentiment>\n",
    "```\n",
    "\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Q: I just got the best news ever!\n",
    "A: Positive\n",
    "\n",
    "Q: We just got a raise at work!\n",
    "A: Positive\n",
    "\n",
    "Q: I'm so proud of what I accomplished today.\n",
    "A: Positive\n",
    "\n",
    "Q: I'm having the best day ever!\n",
    "A: Positive\n",
    "\n",
    "Q: I'm really looking forward to the weekend.\n",
    "A: Positive\n",
    "\n",
    "Q: I just got the best present ever!\n",
    "A: Positive\n",
    "\n",
    "Q: I'm so happy right now.\n",
    "A: Positive\n",
    "\n",
    "Q: I'm so blessed to have such an amazing family.\n",
    "A: Positive\n",
    "\n",
    "Q: The weather outside is so gloomy.\n",
    "A: Negative\n",
    "\n",
    "Q: I just got some terrible news.\n",
    "A: Negative\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Machine Learning projects often face challenges due to insufficient labeled data, leading to prolonged data collection and labeling phases.\n",
    "- The emergence of LLMs has transformed this paradigm, enabling the testing and development of ideas or AI-powered features with minimal delay.\n",
    "- LLMs leverage their generalization capabilities to provide immediate insights and preliminary results.\n",
    "- Successful initial testing with LLMs can justify and lead into the traditional, more time-consuming development process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/synthetic_rag_1.webp\" width=\"800\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Retrieval Augmented Generation (RAG) is a method that combines\n",
    "  -  information retrieval with LLM text generation for knowledge-intensive tasks.\n",
    "- The Retrieval model is key,\n",
    "  - Selecting relevant documents for the LLM to process, with its performance directly impacting the quality of the output.\n",
    "- RAG's effectiveness can vary across languages and specific domains, \n",
    "  - Sometimes struggling with tasks like creating a chatbot for Czech legal advice or a tax assistant for the Indian market.\n",
    "- A solution to enhance RAG's performance \n",
    "  - Using LLMs to synthesize training data for new models, a method that can improve accuracy in underrepresented languages or specialized areas.\n",
    "- This approach, while computationally demanding, aims at distilling LLMs into more efficient models, potentially lowering inference costs and boosting overall system performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Domain-Specific Dataset Generation**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data labeling is crucial for machine learning projects, following the principle of \"garbage in, garbage out.\"\n",
    "- Labeling entails generating annotated datasets for training and evaluation purposes.\n",
    "- This process is often time-consuming and costly, particularly for projects with extensive datasets.\n",
    "- Leveraging advancements in Large Language Models (LLMs) could potentially mitigate the cost and effort associated with data labeling tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Utilizing pre-labeled data is more appealing than starting from scratch, as editing is typically less arduous than composing original work.\n",
    "- Leveraging GPT-4 as a prediction engine for pre-labeling data capitalizes on its contextual understanding and ability to generate human-like text.\n",
    "- By incorporating GPT-4 into the labeling process, manual effort can be significantly reduced, leading to cost savings and a less monotonous process.\n",
    "- Prompt engineering, familiar to users of GPT models, involves setting the context for the model to generate specific outputs. Crafting prompts tailored to our desired output format facilitates GPT-4's generation of text resembling model predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Example task: Sentiment analysis - classifying text as positive, negative, or neutral.**\n",
    "\n",
    "- Prompt: \"Given the input text, classify its sentiment as positive, negative, or neutral.\"\n",
    "- Follow-up instructions: \"Ensure the generated output corresponds accurately to the sentiment expressed in the input text.\"\n",
    "- Desired outcome: Text generated should indicate whether the sentiment is positive, negative, or neutral based on the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import re\n",
    "\n",
    "def get_sentiment(input_text):\n",
    "    prompt = f\"Respond in the json format: {{'response': sentiment_classification}}\\nText: {input_text}\\nSentiment (positive, neutral, negative):\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt,}\n",
    "        ],\n",
    "        max_tokens=40,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "    response_text =  response.choices[0].message.content.strip()\n",
    "    sentiment = re.search(\"negative|neutral|positive\", response_text).group(0)\n",
    "    # Add input_text back in for the result\n",
    "    return {\"text\": input_text, \"response\": sentiment}\n",
    "    # return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I had a terrible time at the party last night!',\n",
       " 'response': 'negative'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test single example\n",
    "\n",
    "sample_text = \"I had a terrible time at the party last night!\"\n",
    "sentiment = get_sentiment(sample_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input_texts.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile input_texts.txt\n",
    "I love going to the park on a sunny day.\n",
    "The customer service was terrible; they were rude and unhelpful.\n",
    "I am neither happy nor sad about the new policy changes.\n",
    "The cake was delicious and the presentation was fantastic.\n",
    "I had a really bad experience with the product; it broke after two days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "input_file_path = \"input_texts.txt\"\n",
    "output_file_path = \"output_responses.json\"\n",
    "\n",
    "with open(input_file_path, \"r\") as input_file, open(output_file_path, \"w\") as output_file:\n",
    "    examples = []\n",
    "    for line in input_file:\n",
    "        text = line.strip()\n",
    "        if text:\n",
    "            examples.append((get_sentiment(text)))\n",
    "    output_file.write(json.dumps(examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Should I now use it directly for training my model?**\n",
    "\n",
    "- Verification is required!\n",
    "- one approach is to go for some user-friendly tools like label studio to verify some of them easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ls_format(input_dict):\n",
    "    \"\"\"\n",
    "    Convert sentiment analysis output from a simple format to Label Studio's prediction format.\n",
    "    \n",
    "    Args:\n",
    "        input_dict (dict): A dictionary containing text and response keys. Example:\n",
    "            {\n",
    "                \"text\": \"I love going to the park on a sunny day.\",\n",
    "                \"response\": \"positive\"\n",
    "            }\n",
    "            \n",
    "    Returns:\n",
    "        dict: A dictionary in Label Studio's prediction format. \n",
    "    \"\"\"\n",
    "    \n",
    "    score_value = 1.00  # We don't know the model confidence\n",
    "    output_dict = {\n",
    "        \"data\": {\n",
    "            \"text\": input_dict[\"text\"]\n",
    "        },\n",
    "        \"predictions\": [\n",
    "            {\n",
    "                \"result\": [\n",
    "                    {\n",
    "                        \"value\": {\n",
    "                            \"choices\": [\n",
    "                                input_dict[\"response\"].capitalize()\n",
    "                            ]\n",
    "                        },\n",
    "                        \"from_name\": \"sentiment\",\n",
    "                        \"to_name\": \"text\",\n",
    "                        \"type\": \"choices\"\n",
    "                    }\n",
    "                ],\n",
    "                \"score\": score_value,\n",
    "                \"model_version\": \"gpt-3.5-turbo\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'text': 'I had a terrible time at the party last night!'}, 'predictions': [{'result': [{'value': {'choices': ['Negative']}, 'from_name': 'sentiment', 'to_name': 'text', 'type': 'choices'}], 'score': 1.0, 'model_version': 'gpt-3.5-turbo'}]}\n"
     ]
    }
   ],
   "source": [
    "print(convert_ls_format(sentiment))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "input_file_path = \"input_texts.txt\"\n",
    "output_file_path = \"output_responses.json\"\n",
    "\n",
    "with open(input_file_path, \"r\") as input_file, open(output_file_path, \"w\") as output_file:\n",
    "    examples = []\n",
    "    for line in input_file:\n",
    "        text = line.strip()\n",
    "        if text:\n",
    "            examples.append(convert_ls_format(get_sentiment(text)))\n",
    "    output_file.write(json.dumps(examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Set up a Label Studio project: Begin by creating a new project in Label Studio.\n",
    "- Import pre-labeled data: Upload the pre-labeled data into the Label Studio project.\n",
    "- Review annotations: Examine the annotations within Label Studio to ensure accuracy and consistency.\n",
    "- Iterate if necessary: Make any necessary adjustments or corrections to the annotations based on the review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: Install and Launch Label Studio**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting label-studio\n",
      "  Downloading label_studio-1.11.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting Django<3.3.0,>=3.2.23 (from label-studio)\n",
      "  Downloading Django-3.2.24-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting appdirs>=1.4.3 (from label-studio)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting attr==0.3.1 (from label-studio)\n",
      "  Downloading attr-0.3.1.tar.gz (1.7 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from label-studio) (23.2.0)\n",
      "Collecting azure-storage-blob>=12.6.0 (from label-studio)\n",
      "  Downloading azure_storage_blob-12.19.0-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting bleach<5.1.0,>=5.0.0 (from label-studio)\n",
      "  Downloading bleach-5.0.1-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting boto<3.0.0,>=2.49.0 (from label-studio)\n",
      "  Downloading boto-2.49.0-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting boto3<2.0.0,>=1.28.58 (from label-studio)\n",
      "  Downloading boto3-1.34.53-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting botocore<2.0.0,>=1.31.58 (from label-studio)\n",
      "  Downloading botocore-1.34.53-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting boxing>=0.1.4 (from label-studio)\n",
      "  Downloading boxing-0.1.4-py3-none-any.whl (3.9 kB)\n",
      "Collecting colorama>=0.4.4 (from label-studio)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting defusedxml>=0.7.1 (from label-studio)\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting django-annoying==0.10.6 (from label-studio)\n",
      "  Downloading django_annoying-0.10.6-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting django-cors-headers==3.6.0 (from label-studio)\n",
      "  Downloading django_cors_headers-3.6.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting django-csp==3.7 (from label-studio)\n",
      "  Downloading django_csp-3.7-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting django-debug-toolbar==3.2.1 (from label-studio)\n",
      "  Downloading django_debug_toolbar-3.2.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting django-environ==0.10.0 (from label-studio)\n",
      "  Downloading django_environ-0.10.0-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Collecting django-extensions==3.1.0 (from label-studio)\n",
      "  Downloading django_extensions-3.1.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting django-filter==2.4.0 (from label-studio)\n",
      "  Downloading django_filter-2.4.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting django-model-utils==4.1.1 (from label-studio)\n",
      "  Downloading django_model_utils-4.1.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting django-ranged-fileresponse>=0.1.2 (from label-studio)\n",
      "  Downloading django-ranged-fileresponse-0.1.2.tar.gz (2.7 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting django-rq==2.5.1 (from label-studio)\n",
      "  Downloading django_rq-2.5.1-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting django-storages==1.12.3 (from label-studio)\n",
      "  Downloading django_storages-1.12.3-py3-none-any.whl.metadata (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting django-user-agents==0.4.0 (from label-studio)\n",
      "  Downloading django_user_agents-0.4.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting djangorestframework==3.13.1 (from label-studio)\n",
      "  Downloading djangorestframework-3.13.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting drf-dynamic-fields==0.3.0 (from label-studio)\n",
      "  Downloading drf_dynamic_fields-0.3.0-py2.py3-none-any.whl (6.6 kB)\n",
      "Collecting drf-flex-fields==0.9.5 (from label-studio)\n",
      "  Downloading drf-flex-fields-0.9.5.tar.gz (27 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting drf-generators==0.3.0 (from label-studio)\n",
      "  Downloading drf-generators-0.3.0.tar.gz (9.4 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting google-cloud-storage<3.0.0,>=2.13.0 (from label-studio)\n",
      "  Downloading google_cloud_storage-2.14.0-py2.py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting htmlmin==0.1.12 (from label-studio)\n",
      "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting humansignal-drf-yasg>=1.21.9 (from label-studio)\n",
      "  Downloading humansignal_drf_yasg-1.21.9-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting jsonschema==3.2.0 (from label-studio)\n",
      "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting label-studio-converter==0.0.57 (from label-studio)\n",
      "  Downloading label_studio_converter-0.0.57-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting launchdarkly-server-sdk==7.5.0 (from label-studio)\n",
      "  Downloading launchdarkly-server-sdk-7.5.0.tar.gz (110 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.6/110.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting lockfile>=0.12.0 (from label-studio)\n",
      "  Downloading lockfile-0.12.2-py2.py3-none-any.whl (13 kB)\n",
      "Collecting lxml>=4.2.5 (from label-studio)\n",
      "  Downloading lxml-5.1.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.24.3 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from label-studio) (1.26.4)\n",
      "Collecting ordered-set==4.0.2 (from label-studio)\n",
      "  Downloading ordered-set-4.0.2.tar.gz (10 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.24.0 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from label-studio) (2.2.1)\n",
      "Collecting psycopg2-binary==2.9.6 (from label-studio)\n",
      "  Downloading psycopg2_binary-2.9.6-cp310-cp310-macosx_10_9_x86_64.whl.metadata (4.4 kB)\n",
      "Collecting pydantic<=1.11.0,>=1.7.3 (from label-studio)\n",
      "  Downloading pydantic-1.10.14-cp310-cp310-macosx_10_9_x86_64.whl.metadata (150 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.2/150.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from label-studio) (2.8.2)\n",
      "Collecting python-json-logger==2.0.4 (from label-studio)\n",
      "  Downloading python_json_logger-2.0.4-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting pytz<2023.0,>=2022.1 (from label-studio)\n",
      "  Downloading pytz-2022.7.1-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from label-studio) (6.0.1)\n",
      "Collecting redis<4.0,>=3.5 (from label-studio)\n",
      "  Downloading redis-3.5.3-py2.py3-none-any.whl.metadata (36 kB)\n",
      "Requirement already satisfied: requests==2.31.0 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from label-studio) (2.31.0)\n",
      "Collecting rq==1.10.1 (from label-studio)\n",
      "  Downloading rq-1.10.1-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting rules==2.2 (from label-studio)\n",
      "  Downloading rules-2.2.tar.gz (53 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting sentry-sdk>=1.1.0 (from label-studio)\n",
      "  Downloading sentry_sdk-1.40.6-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting ujson>=3.0.0 (from label-studio)\n",
      "  Downloading ujson-5.9.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (8.7 kB)\n",
      "Collecting urllib3<2.0.0,>=1.26.18 (from label-studio)\n",
      "  Using cached urllib3-1.26.18-py2.py3-none-any.whl.metadata (48 kB)\n",
      "Collecting wheel<=0.40.0,>=0.38.1 (from label-studio)\n",
      "  Downloading wheel-0.40.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting xmljson==0.2.0 (from label-studio)\n",
      "  Downloading xmljson-0.2.0-py2.py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: six in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from django-annoying==0.10.6->label-studio) (1.16.0)\n",
      "Collecting sqlparse>=0.2.0 (from django-debug-toolbar==3.2.1->label-studio)\n",
      "  Downloading sqlparse-0.4.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting user-agents (from django-user-agents==0.4.0->label-studio)\n",
      "  Downloading user_agents-2.2.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting pyrsistent>=0.14.0 (from jsonschema==3.2.0->label-studio)\n",
      "  Downloading pyrsistent-0.20.0-cp310-cp310-macosx_10_9_universal2.whl.metadata (27 kB)\n",
      "Requirement already satisfied: setuptools in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from jsonschema==3.2.0->label-studio) (68.2.2)\n",
      "Requirement already satisfied: Pillow>=10.0.1 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from label-studio-converter==0.0.57->label-studio) (10.2.0)\n",
      "Collecting nltk==3.6.7 (from label-studio-converter==0.0.57->label-studio)\n",
      "  Downloading nltk-3.6.7-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting label-studio-tools>=0.0.3 (from label-studio-converter==0.0.57->label-studio)\n",
      "  Downloading label_studio_tools-0.0.3-py3-none-any.whl.metadata (566 bytes)\n",
      "Collecting ijson~=3.2.0.post0 (from label-studio-converter==0.0.57->label-studio)\n",
      "  Downloading ijson-3.2.3-cp310-cp310-macosx_10_9_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: certifi>=2018.4.16 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from launchdarkly-server-sdk==7.5.0->label-studio) (2024.2.2)\n",
      "Collecting expiringdict>=1.1.4 (from launchdarkly-server-sdk==7.5.0->label-studio)\n",
      "  Downloading expiringdict-1.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting pyRFC3339>=1.0 (from launchdarkly-server-sdk==7.5.0->label-studio)\n",
      "  Downloading pyRFC3339-1.1-py2.py3-none-any.whl (5.7 kB)\n",
      "Collecting semver<3.0.0,>=2.10.2 (from launchdarkly-server-sdk==7.5.0->label-studio)\n",
      "  Downloading semver-2.13.0-py2.py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from requests==2.31.0->label-studio) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from requests==2.31.0->label-studio) (3.6)\n",
      "Requirement already satisfied: click>=5.0.0 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from rq==1.10.1->label-studio) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from nltk==3.6.7->label-studio-converter==0.0.57->label-studio) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from nltk==3.6.7->label-studio-converter==0.0.57->label-studio) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from nltk==3.6.7->label-studio-converter==0.0.57->label-studio) (4.66.2)\n",
      "Collecting azure-core<2.0.0,>=1.28.0 (from azure-storage-blob>=12.6.0->label-studio)\n",
      "  Downloading azure_core-1.30.1-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting cryptography>=2.1.4 (from azure-storage-blob>=12.6.0->label-studio)\n",
      "  Downloading cryptography-42.0.5-cp39-abi3-macosx_10_12_universal2.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from azure-storage-blob>=12.6.0->label-studio) (4.9.0)\n",
      "Collecting isodate>=0.6.1 (from azure-storage-blob>=12.6.0->label-studio)\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl.metadata (9.6 kB)\n",
      "Collecting webencodings (from bleach<5.1.0,>=5.0.0->label-studio)\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0.0,>=1.28.58->label-studio)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2.0.0,>=1.28.58->label-studio)\n",
      "  Using cached s3transfer-0.10.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: asgiref<4,>=3.3.2 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from Django<3.3.0,>=3.2.23->label-studio) (3.7.2)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=2.23.3 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=2.13.0->label-studio) (2.28.1)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 (from google-cloud-storage<3.0.0,>=2.13.0->label-studio)\n",
      "  Downloading google_api_core-2.17.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-cloud-core<3.0dev,>=2.3.0 (from google-cloud-storage<3.0.0,>=2.13.0->label-studio)\n",
      "  Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-resumable-media>=2.6.0 (from google-cloud-storage<3.0.0,>=2.13.0->label-studio)\n",
      "  Downloading google_resumable_media-2.7.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage<3.0.0,>=2.13.0->label-studio)\n",
      "  Downloading google_crc32c-1.5.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (2.3 kB)\n",
      "Collecting inflection>=0.3.1 (from humansignal-drf-yasg>=1.21.9->label-studio)\n",
      "  Downloading inflection-0.5.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: packaging>=21.0 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from humansignal-drf-yasg>=1.21.9->label-studio) (23.2)\n",
      "Collecting uritemplate>=3.0.0 (from humansignal-drf-yasg>=1.21.9->label-studio)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from pandas>=0.24.0->label-studio) (2024.1)\n",
      "Collecting cffi>=1.12 (from cryptography>=2.1.4->azure-storage-blob>=12.6.0->label-studio)\n",
      "  Downloading cffi-1.16.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage<3.0.0,>=2.13.0->label-studio) (1.62.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage<3.0.0,>=2.13.0->label-studio) (4.25.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage<3.0.0,>=2.13.0->label-studio) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage<3.0.0,>=2.13.0->label-studio) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage<3.0.0,>=2.13.0->label-studio) (4.9)\n",
      "Collecting ua-parser>=0.10.0 (from user-agents->django-user-agents==0.4.0->label-studio)\n",
      "  Downloading ua_parser-0.18.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pycparser (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob>=12.6.0->label-studio)\n",
      "  Downloading pycparser-2.21-py2.py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/mzihayat/VSC/Prompt_Engineering/.venv/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.23.3->google-cloud-storage<3.0.0,>=2.13.0->label-studio) (0.5.1)\n",
      "Downloading label_studio-1.11.0-py3-none-any.whl (81.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading django_annoying-0.10.6-py2.py3-none-any.whl (9.5 kB)\n",
      "Downloading django_cors_headers-3.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading django_csp-3.7-py2.py3-none-any.whl (17 kB)\n",
      "Downloading django_debug_toolbar-3.2.1-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading django_environ-0.10.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading django_extensions-3.1.0-py3-none-any.whl (222 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.0/222.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading django_filter-2.4.0-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m712.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading django_model_utils-4.1.1-py3-none-any.whl (32 kB)\n",
      "Downloading django_rq-2.5.1-py2.py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.3/48.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading django_storages-1.12.3-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading django_user_agents-0.4.0-py3-none-any.whl (8.6 kB)\n",
      "Downloading djangorestframework-3.13.1-py3-none-any.whl (958 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.3/958.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading label_studio_converter-0.0.57-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading psycopg2_binary-2.9.6-cp310-cp310-macosx_10_9_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_json_logger-2.0.4-py3-none-any.whl (7.8 kB)\n",
      "Downloading rq-1.10.1-py2.py3-none-any.whl (70 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nltk-3.6.7-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading azure_storage_blob-12.19.0-py3-none-any.whl (394 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.2/394.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading bleach-5.0.1-py3-none-any.whl (160 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.9/160.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading boto3-1.34.53-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.34.53-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Downloading Django-3.2.24-py3-none-any.whl (7.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_storage-2.14.0-py2.py3-none-any.whl (121 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading humansignal_drf_yasg-1.21.9-py3-none-any.whl (4.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading lxml-5.1.0-cp310-cp310-macosx_10_9_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading pydantic-1.10.14-cp310-cp310-macosx_10_9_x86_64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.4/499.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading redis-3.5.3-py2.py3-none-any.whl (72 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.1/72.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentry_sdk-1.40.6-py2.py3-none-any.whl (258 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.5/258.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ujson-5.9.0-cp310-cp310-macosx_10_9_x86_64.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
      "Downloading wheel-0.40.0-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading azure_core-1.30.1-py3-none-any.whl (193 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.4/193.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cryptography-42.0.5-cp39-abi3-macosx_10_12_universal2.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading expiringdict-1.2.2-py3-none-any.whl (8.5 kB)\n",
      "Downloading google_api_core-2.17.1-py3-none-any.whl (137 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.0/137.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
      "Downloading google_crc32c-1.5.0-cp310-cp310-macosx_10_9_x86_64.whl (30 kB)\n",
      "Downloading google_resumable_media-2.7.0-py2.py3-none-any.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ijson-3.2.3-cp310-cp310-macosx_10_9_x86_64.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.7/54.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading inflection-0.5.1-py2.py3-none-any.whl (9.5 kB)\n",
      "Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading label_studio_tools-0.0.3-py3-none-any.whl (14 kB)\n",
      "Downloading pyrsistent-0.20.0-cp310-cp310-macosx_10_9_universal2.whl (83 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.4/83.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached s3transfer-0.10.0-py3-none-any.whl (82 kB)\n",
      "Downloading semver-2.13.0-py2.py3-none-any.whl (12 kB)\n",
      "Downloading sqlparse-0.4.4-py3-none-any.whl (41 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading user_agents-2.2.0-py3-none-any.whl (9.6 kB)\n",
      "Downloading cffi-1.16.0-cp310-cp310-macosx_10_9_x86_64.whl (182 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.5/182.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ua_parser-0.18.0-py2.py3-none-any.whl (38 kB)\n",
      "Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: attr, drf-flex-fields, drf-generators, htmlmin, launchdarkly-server-sdk, ordered-set, rules, django-ranged-fileresponse\n",
      "  Building wheel for attr (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for attr: filename=attr-0.3.1-py3-none-any.whl size=2445 sha256=98167830f66f5b1e09c1b71b3710c78b5e16143684e808e2489faa5419d2d24f\n",
      "  Stored in directory: /Users/mzihayat/Library/Caches/pip/wheels/77/f7/fa/f3c975647897f6c458743646f9e987ab5bad62924d30284726\n",
      "  Building wheel for drf-flex-fields (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for drf-flex-fields: filename=drf_flex_fields-0.9.5-py3-none-any.whl size=14426 sha256=cfce9874964a902dc31bac9bd58d32ff33123e59204b368d81b1a60ad8178520\n",
      "  Stored in directory: /Users/mzihayat/Library/Caches/pip/wheels/a7/c7/cd/d1c736f1f97603c2ad223db5689c9b9603c2d53890fe156fc8\n",
      "  Building wheel for drf-generators (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for drf-generators: filename=drf_generators-0.3.0-py2.py3-none-any.whl size=9771 sha256=5e186ed683f88a2ab8a5cc4771bfd1be08f791ce9efc170f1a5096e7c47dc77c\n",
      "  Stored in directory: /Users/mzihayat/Library/Caches/pip/wheels/bd/b0/47/0389db14737660b01d4b8fd891921ef143296b8cce62fcbef5\n",
      "  Building wheel for htmlmin (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27081 sha256=d9def79be2695fd54f4f0acb8d1eaeabdb454830918c8ff7050150f954b43e5c\n",
      "  Stored in directory: /Users/mzihayat/Library/Caches/pip/wheels/dd/91/29/a79cecb328d01739e64017b6fb9a1ab9d8cb1853098ec5966d\n",
      "  Building wheel for launchdarkly-server-sdk (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for launchdarkly-server-sdk: filename=launchdarkly_server_sdk-7.5.0-py3-none-any.whl size=140852 sha256=b8be706bd7f2f32bd57e316f828544acd33a8a6a699a1802b464b71b3fb84e17\n",
      "  Stored in directory: /Users/mzihayat/Library/Caches/pip/wheels/9d/39/10/6b6dfbec81e8dc60ab22ea7b9df4fd674c3fd44885fa37d64c\n",
      "  Building wheel for ordered-set (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ordered-set: filename=ordered_set-4.0.2-py2.py3-none-any.whl size=8215 sha256=96423e437e295bfb42dbde3160288627fe86176762e0175ba7b13876be06fa8e\n",
      "  Stored in directory: /Users/mzihayat/Library/Caches/pip/wheels/a0/7b/e7/13d20d03563090b0f5a6450dc297cd6d8583358e3755670da6\n",
      "  Building wheel for rules (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rules: filename=rules-2.2-py2.py3-none-any.whl size=25814 sha256=612b5316bfee2a3a3c67e24e6a3cf6ad6e7dbdbb44c2dae4b2ce5339c93de2b8\n",
      "  Stored in directory: /Users/mzihayat/Library/Caches/pip/wheels/08/43/28/3a8f0f0100d724be7edb32d67140297268d83ad2718ce19b46\n",
      "  Building wheel for django-ranged-fileresponse (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for django-ranged-fileresponse: filename=django_ranged_fileresponse-0.1.2-py3-none-any.whl size=3225 sha256=2f689864cdc8ae6e60f89d38a3224d07639f42ec09a51d699a36a6ee5a551520\n",
      "  Stored in directory: /Users/mzihayat/Library/Caches/pip/wheels/0a/39/8d/3e779f86f962b817d1acce58407c5a68385da4f77d73fc1a97\n",
      "Successfully built attr drf-flex-fields drf-generators htmlmin launchdarkly-server-sdk ordered-set rules django-ranged-fileresponse\n",
      "Installing collected packages: xmljson, webencodings, ua-parser, rules, pytz, lockfile, ijson, htmlmin, expiringdict, drf-flex-fields, drf-dynamic-fields, django-ranged-fileresponse, boxing, boto, attr, appdirs, wheel, user-agents, urllib3, uritemplate, ujson, sqlparse, semver, redis, python-json-logger, pyrsistent, pyRFC3339, pydantic, pycparser, psycopg2-binary, ordered-set, nltk, lxml, jmespath, isodate, inflection, google-crc32c, django-extensions, django-environ, defusedxml, colorama, bleach, sentry-sdk, rq, launchdarkly-server-sdk, label-studio-tools, jsonschema, google-resumable-media, Django, cffi, botocore, s3transfer, label-studio-converter, google-api-core, drf-generators, djangorestframework, django-user-agents, django-storages, django-rq, django-model-utils, django-filter, django-debug-toolbar, django-csp, django-cors-headers, django-annoying, cryptography, azure-core, humansignal-drf-yasg, google-cloud-core, boto3, azure-storage-blob, google-cloud-storage, label-studio\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2024.1\n",
      "    Uninstalling pytz-2024.1:\n",
      "      Successfully uninstalled pytz-2024.1\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.1\n",
      "    Uninstalling urllib3-2.2.1:\n",
      "      Successfully uninstalled urllib3-2.2.1\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.6.1\n",
      "    Uninstalling pydantic-2.6.1:\n",
      "      Successfully uninstalled pydantic-2.6.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "types-requests 2.31.0.20240218 requires urllib3>=2, but you have urllib3 1.26.18 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Django-3.2.24 appdirs-1.4.4 attr-0.3.1 azure-core-1.30.1 azure-storage-blob-12.19.0 bleach-5.0.1 boto-2.49.0 boto3-1.34.53 botocore-1.34.53 boxing-0.1.4 cffi-1.16.0 colorama-0.4.6 cryptography-42.0.5 defusedxml-0.7.1 django-annoying-0.10.6 django-cors-headers-3.6.0 django-csp-3.7 django-debug-toolbar-3.2.1 django-environ-0.10.0 django-extensions-3.1.0 django-filter-2.4.0 django-model-utils-4.1.1 django-ranged-fileresponse-0.1.2 django-rq-2.5.1 django-storages-1.12.3 django-user-agents-0.4.0 djangorestframework-3.13.1 drf-dynamic-fields-0.3.0 drf-flex-fields-0.9.5 drf-generators-0.3.0 expiringdict-1.2.2 google-api-core-2.17.1 google-cloud-core-2.4.1 google-cloud-storage-2.14.0 google-crc32c-1.5.0 google-resumable-media-2.7.0 htmlmin-0.1.12 humansignal-drf-yasg-1.21.9 ijson-3.2.3 inflection-0.5.1 isodate-0.6.1 jmespath-1.0.1 jsonschema-3.2.0 label-studio-1.11.0 label-studio-converter-0.0.57 label-studio-tools-0.0.3 launchdarkly-server-sdk-7.5.0 lockfile-0.12.2 lxml-5.1.0 nltk-3.6.7 ordered-set-4.0.2 psycopg2-binary-2.9.6 pyRFC3339-1.1 pycparser-2.21 pydantic-1.10.14 pyrsistent-0.20.0 python-json-logger-2.0.4 pytz-2022.7.1 redis-3.5.3 rq-1.10.1 rules-2.2 s3transfer-0.10.0 semver-2.13.0 sentry-sdk-1.40.6 sqlparse-0.4.4 ua-parser-0.18.0 ujson-5.9.0 uritemplate-4.1.1 urllib3-1.26.18 user-agents-2.2.0 webencodings-0.5.1 wheel-0.40.0 xmljson-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install label-studio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Database and media directory: /Users/mzihayat/Library/Application Support/label-studio\n",
      "=> Static URL is set to: /static/\n",
      "=> Database and media directory: /Users/mzihayat/Library/Application Support/label-studio\n",
      "=> Static URL is set to: /static/\n",
      "Read environment variables from: /Users/mzihayat/Library/Application Support/label-studio/.env\n",
      "get 'SECRET_KEY' casted as '<class 'str'>' with default ''\n",
      "[Tracing] Create new propagation context: {'trace_id': '88bc9d1b2d4641eea2eeb987976c674d', 'span_id': '91b9ebd3dc59ee7d', 'parent_span_id': None, 'dynamic_sampling_context': None}\n",
      "Starting new HTTPS connection (1): pypi.org:443\n",
      "https://pypi.org:443 \"GET /pypi/label-studio/json HTTP/1.1\" 200 31429\n",
      "Performing system checks...\n",
      "\n",
      "System check identified no issues (1 silenced).\n",
      "March 01, 2024 - 16:57:08\n",
      "Django version 3.2.24, using settings 'label_studio.core.settings.label_studio'\n",
      "Starting development server at http://0.0.0.0:8080/\n",
      "Quit the server with CONTROL-C.\n",
      "[2024-03-01 16:57:11,321] [django.server::log_message::161] [INFO] \"GET / HTTP/1.1\" 302 0\n",
      "[2024-03-01 16:57:11,321] [django.server::log_message::161] [INFO] \"GET / HTTP/1.1\" 302 0\n",
      "[2024-03-01 16:57:11,355] [django.server::log_message::161] [INFO] \"GET /projects/ HTTP/1.1\" 200 35416\n",
      "[2024-03-01 16:57:11,355] [django.server::log_message::161] [INFO] \"GET /projects/ HTTP/1.1\" 200 35416\n",
      "[2024-03-01 16:57:11,440] [django.server::log_message::161] [INFO] \"GET /static/css/main.05101f5b0b98.css HTTP/1.1\" 200 15255\n",
      "[2024-03-01 16:57:11,440] [django.server::log_message::161] [INFO] \"GET /static/css/main.05101f5b0b98.css HTTP/1.1\" 200 15255\n",
      "[2024-03-01 16:57:11,446] [django.server::log_message::161] [INFO] \"GET /static/fonts/roboto/roboto.css HTTP/1.1\" 200 3431\n",
      "[2024-03-01 16:57:11,446] [django.server::log_message::161] [INFO] \"GET /static/fonts/roboto/roboto.css HTTP/1.1\" 200 3431\n",
      "[2024-03-01 16:57:11,461] [django.server::log_message::161] [INFO] \"GET /static/css/uikit.e49a7a43adbd.css HTTP/1.1\" 200 3892\n",
      "[2024-03-01 16:57:11,461] [django.server::log_message::161] [INFO] \"GET /static/css/uikit.e49a7a43adbd.css HTTP/1.1\" 200 3892\n",
      "[2024-03-01 16:57:11,480] [django.server::log_message::161] [INFO] \"GET /static/css/Toast.min.0479912dd9c5.css HTTP/1.1\" 200 1213\n",
      "[2024-03-01 16:57:11,480] [django.server::log_message::161] [INFO] \"GET /static/css/Toast.min.0479912dd9c5.css HTTP/1.1\" 200 1213\n",
      "[2024-03-01 16:57:11,490] [django.server::log_message::161] [INFO] \"GET /react-app/main.css?v=de9a65 HTTP/1.1\" 200 73963\n",
      "[2024-03-01 16:57:11,490] [django.server::log_message::161] [INFO] \"GET /react-app/main.css?v=de9a65 HTTP/1.1\" 200 73963\n",
      "[2024-03-01 16:57:11,507] [django.server::log_message::161] [INFO] \"GET /static/js/helpers.9a01b074ff58.js HTTP/1.1\" 200 13336\n",
      "[2024-03-01 16:57:11,507] [django.server::log_message::161] [INFO] \"GET /static/js/helpers.9a01b074ff58.js HTTP/1.1\" 200 13336\n",
      "[2024-03-01 16:57:11,507] [django.server::log_message::161] [INFO] \"GET /static/js/Toast.min.9135be1633df.js HTTP/1.1\" 200 2371\n",
      "[2024-03-01 16:57:11,507] [django.server::log_message::161] [INFO] \"GET /static/js/Toast.min.9135be1633df.js HTTP/1.1\" 200 2371\n",
      "[2024-03-01 16:57:11,514] [django.server::log_message::161] [INFO] \"GET /static/js/jquery.min.e6c2415c0ace.js HTTP/1.1\" 200 87462\n",
      "[2024-03-01 16:57:11,514] [django.server::log_message::161] [INFO] \"GET /static/js/jquery.min.e6c2415c0ace.js HTTP/1.1\" 200 87462\n",
      "[2024-03-01 16:57:11,548] [django.server::log_message::161] [INFO] \"GET /react-app/main.js?v=de9a65 HTTP/1.1\" 200 1181765\n",
      "[2024-03-01 16:57:11,548] [django.server::log_message::161] [INFO] \"GET /react-app/main.js?v=de9a65 HTTP/1.1\" 200 1181765\n",
      "[2024-03-01 16:57:11,729] [django.server::log_message::161] [INFO] \"GET /api/version HTTP/1.1\" 200 558\n",
      "[2024-03-01 16:57:11,729] [django.server::log_message::161] [INFO] \"GET /api/version HTTP/1.1\" 200 558\n",
      "[2024-03-01 16:57:11,744] [django.server::log_message::161] [INFO] \"GET /static/icons/logo-black.svg HTTP/1.1\" 200 10236\n",
      "[2024-03-01 16:57:11,744] [django.server::log_message::161] [INFO] \"GET /static/icons/logo-black.svg HTTP/1.1\" 200 10236\n",
      "[2024-03-01 16:57:11,748] [django.server::log_message::161] [INFO] \"GET /api/projects?page=1&page_size=30&include=id%2Ctitle%2Ccreated_by%2Ccreated_at%2Ccolor%2Cis_published%2Cassignment_settings HTTP/1.1\" 200 267\n",
      "[2024-03-01 16:57:11,748] [django.server::log_message::161] [INFO] \"GET /api/projects?page=1&page_size=30&include=id%2Ctitle%2Ccreated_by%2Ccreated_at%2Ccolor%2Cis_published%2Cassignment_settings HTTP/1.1\" 200 267\n",
      "[2024-03-01 16:57:11,750] [django.server::log_message::161] [INFO] \"GET /static/fonts/roboto/roboto-v20-latin_cyrillic-500.woff2 HTTP/1.1\" 200 22880\n",
      "[2024-03-01 16:57:11,750] [django.server::log_message::161] [INFO] \"GET /static/fonts/roboto/roboto-v20-latin_cyrillic-500.woff2 HTTP/1.1\" 200 22880\n",
      "[2024-03-01 16:57:11,754] [django.server::log_message::161] [INFO] \"GET /static/images/favicon.58c0a5114450.ico HTTP/1.1\" 200 21822\n",
      "[2024-03-01 16:57:11,754] [django.server::log_message::161] [INFO] \"GET /static/images/favicon.58c0a5114450.ico HTTP/1.1\" 200 21822\n",
      "[2024-03-01 16:57:11,873] [django.server::log_message::161] [INFO] \"GET /projects/ HTTP/1.1\" 200 35416\n",
      "[2024-03-01 16:57:11,873] [django.server::log_message::161] [INFO] \"GET /projects/ HTTP/1.1\" 200 35416\n",
      "[2024-03-01 16:57:11,882] [django.server::log_message::161] [INFO] \"GET /static/fonts/roboto/roboto-v20-latin_cyrillic-regular.woff2 HTTP/1.1\" 200 22428\n",
      "[2024-03-01 16:57:11,882] [django.server::log_message::161] [INFO] \"GET /static/fonts/roboto/roboto-v20-latin_cyrillic-regular.woff2 HTTP/1.1\" 200 22428\n",
      "[2024-03-01 16:57:11,882] [django.server::log_message::161] [INFO] \"GET /api/projects?ids=1&include=id%2Cdescription%2Cnum_tasks_with_annotations%2Ctask_number%2Cskipped_annotations_number%2Ctotal_annotations_number%2Ctotal_predictions_number%2Cground_truth_number%2Cfinished_task_number&page_size=30 HTTP/1.1\" 200 262\n",
      "[2024-03-01 16:57:11,882] [django.server::log_message::161] [INFO] \"GET /api/projects?ids=1&include=id%2Cdescription%2Cnum_tasks_with_annotations%2Ctask_number%2Cskipped_annotations_number%2Ctotal_annotations_number%2Ctotal_predictions_number%2Cground_truth_number%2Cfinished_task_number&page_size=30 HTTP/1.1\" 200 262\n",
      "[2024-03-01 16:57:13,437] [django.server::log_message::161] [INFO] \"GET /sw.js HTTP/1.1\" 200 6086\n",
      "[2024-03-01 16:57:13,437] [django.server::log_message::161] [INFO] \"GET /sw.js HTTP/1.1\" 200 6086\n",
      "^C\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!label-studio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Create a New Project**\n",
    "\n",
    "- Create Project: Click on \"Create Project\" and input a project name, such as \"Review Bootstrapped Labels.\"\n",
    "- Define Labeling Configuration: Choose the \"Sentiment Analysis Text Classification\" template for Sentiment Analysis tasks.\n",
    "- Configuration Flexibility: These templates are customizable, allowing for easy adjustment of properties as needed.\n",
    "- Default Labeling Configuration: Below is the default labeling configuration for reference.\n",
    "  \n",
    "<img src=\"./images/lbl_studio_1.png\" width=\"800\" align=\"center\"/>\n",
    "\n",
    "<img src=\"./images/lbl_studio_2.png\" width=\"800\" align=\"center\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Import Pre-labeled Data**\n",
    "\n",
    "<img src=\"./images/lbl_studio_3.png\" width=\"800\" align=\"center\"/>\n",
    "\n",
    "<img src=\"./images/lbl_studio_4.png\" width=\"800\" align=\"center\"/>\n",
    "\n",
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>\n",
    "\n",
    "**Step 4: Review and Update Labels**\n",
    "\n",
    "\n",
    "<img src=\"./images/lbl_studio_5.png\" width=\"800\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beyond Sentiment Analysis: Label Any NLP Task**\n",
    "\n",
    "- **Summarization**\n",
    "```\n",
    "Respond in the json format with a summary for the following text: {‘summary’: summary}\n",
    "\n",
    "Text: I love going to the park on a sunny day. The customer service was terrible; they were rude and unhelpful. I am neither happy nor sad about the new policy changes. The cake was delicious and the presentation was fantastic. I had a really bad experience with the product; it broke after two days.\n",
    "\n",
    "Summary:\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Named Entity Recognition (NER)**\n",
    "  \n",
    "  ```\n",
    "  You are an expert NER labeler. Only return JSON. Do not return explanations. Return the CoNLL format for the following sentence in JSON format.\n",
    "  \n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Human Evaluation: There is no replacement for human assessment in certain contexts.\n",
    "- GPT Models as Starting Point: Utilizing GPT models to provide initial insights can offer significant advantages.\n",
    "- Balancing Human and AI Contributions: Combining human evaluation with AI-generated insights can enhance efficiency and accuracy in various tasks.\n",
    "- Leveraging GPT Models: Incorporating GPT models provides a valuable starting point, which can streamline processes and improve productivity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prioritize responsible manual annotation, preparing around **20 examples** and randomly **selecting 2-8 for prompts** to enhance data diversity.\n",
    "- Ensure examples are representative, correctly formatted, and detail specifics like query length and tone.\n",
    "- Precision in examples and instructions improves synthetic data quality for Retriever training.\n",
    "- Low-quality few-shot examples can detrimentally affect the trained model's quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Utilizing an affordable model like ChatGPT is often adequate for non-English languages and unusual domains.\n",
    "- A typical prompt with instructions and 4-5 examples might use about 700 tokens, plus 25 tokens for generation, under Retriever's 128-token constraint per passage.\n",
    "- The cost of generating a synthetic dataset for 50,000 documents, considering GPT-3.5 Turbo API pricing, is approximately $55.\n",
    "  - Calculation: 50,000 * (700 * 0.001 * $0.0015 + 25 * 0.001 * $0.002)\n",
    "- Generating multiple (2-4) query examples per document is feasible and can enhance local model fine-tuning.\n",
    "- Further training, despite additional costs, often yields significant benefits, particularly for specialized domains such as Czech law."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dai et al. (2022) found that around 50,000 manually labeled data are needed for a model to match synthetic data quality.\n",
    "- Gathering 10,000 manual examples before launch takes time and costs over a thousand dollars.\n",
    "- Synthetic data and local Retriever Model training are more cost-effective.\n",
    "- With the new technique, double-digit metric growth can be achieved in a few days.\n",
    "  \n",
    "<img src=\"./images/synthetic_rag_3.webp\" width=\"800\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Synthetic Data for RAG Setup**\n",
    "\n",
    "- The Retrieval model is pivotal in the RAG (Retriever-And-Generator) framework, as it identifies relevant documents and forwards them to the Large Language Model (LLM) for subsequent processing.\n",
    "- The effectiveness of the Retrieval model directly impacts the quality of the product or feature outcome.\n",
    "- Ideally, the Retrieval model should exhibit satisfactory performance without requiring extensive fine-tuning.\n",
    "- The performance of the Retrieval model may diminish when operating in diverse languages or specialized domains.\n",
    "- Strategies such as domain adaptation or multilingual training may be employed to enhance the Retrieval model's performance in various contexts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Scenario:**\n",
    "- Consider the task of developing a chatbot to answer questions regarding Czech laws and legal practices, or designing a tax assistant customized for the Indian market.\n",
    "- In such specialized domains and languages, the Retrieval model may struggle to identify the most pertinent documents, leading to suboptimal performance and impacting the overall quality of the system.\n",
    "- The Retrieval model's limitations may result in missing crucial information and hindering the chatbot or tax assistant's ability to provide accurate and comprehensive responses.\n",
    "- Addressing these challenges requires tailored approaches such as domain-specific prompting, language adaptation, or incorporating specialized knowledge bases to enhance the Retrieval model's effectiveness in retrieving relevant information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## **Solution:**\n",
    "-  Leveraging existing Large Language Models (LLMs) to synthesize data for training new generations of LLMs, Retrievers, and other models.\n",
    "   - This approach involves distilling LLMs into standard-sized encoders through prompt-based query generation.\n",
    "   - The distillation process requires significant computational resources.\n",
    "- Despite its computational demands, this method significantly reduces inference costs and has the potential to greatly enhance model performance, especially in scenarios involving low-resource languages or specialized domains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use?\n",
    "\n",
    "- Users typically need to supply a brief description and manually label a few examples.\n",
    "- Different retrieval tasks exhibit diverse search intents, resulting in varying interpretations of \"relevance\" for a given (Query, Document) pair.\n",
    "- Relevance can differ significantly based on the specific search intent of the task.\n",
    "  - For example, in an argument retrieval task, relevance might entail identifying supporting arguments, whereas in other scenarios, counter-arguments might be sought.\n",
    "\n",
    "**Prompt:**\n",
    "Task: Identify a counter-argument for the given argument.\n",
    "\n",
    "Argument #1: {insert passage X1 here}\n",
    "\n",
    "A concise counter-argument query related to the argument #1: {insert manually prepared query Y1 here}\n",
    "\n",
    "Argument #2: {insert passage X2 here}\n",
    "A concise counter-argument query related to the argument #2: {insert manually prepared query Y2 here}\n",
    "\n",
    "**Examples:**\n",
    "\n",
    "Argument N: Even if a fine is made proportional to income, you will not get the equality of impact you desire. This is because the impact is not proportional simply to income, but must take into account a number of other factors. For example, someone supporting a family will face a greater impact than someone who is not, because they have a smaller disposable income. Further, a fine based on income ignores overall wealth (i.e. how much money someone actually has: someone might have a lot of assets but not have a high income). The proposition does not cater for these inequalities, which may well have a much greater skewing effect, and therefore the argument is being applied inconsistently.\n",
    "\n",
    "A concise counter-argument query related to the argument #N:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**output:**\n",
    "\n",
    "```\n",
    "punishment house would make fines relative income\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/synthetic_rag_2.webp\" width=\"800\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Suppose Information Retrieval isn't your primary task, such as when working on a legal document classification problem without the option to utilize external APIs.\n",
    "  - In such cases, training a local model becomes necessary to maintain data privacy and comply with restrictions on data sharing.\n",
    "  - However, gathering sufficient data locally can present a significant hurdle, potentially leading to delays in product development.\n",
    "  - Limited access to data may hinder model training and subsequent performance, necessitating innovative strategies to overcome this obstacle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Consider the task of generating children's stories, as explored in the research by Eldan et al. (2023).\n",
    "- Each story typically comprises 2-3 paragraphs, following a simple plot and theme, with the dataset covering vocabulary and factual knowledge suitable for children.\n",
    "- Language serves not only as a system of rules and symbols but also as a medium for conveying and interpreting meaning.\n",
    "- A key challenge in using large language models for generating training data is ensuring **dataset diversity**. \n",
    "  - Even with high generation temperatures, models may produce repetitive datasets lacking the necessary variety, particularly concerning children's language.\n",
    "- Additionally, natural language generation faces challenges related to **coherence** and **relevance**, which are crucial for producing meaningful and engaging children's stories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To address the diversity challenge, the authors curated a vocabulary comprising approximately 1500 basic words, reminiscent of a typical child's vocabulary, categorized into nouns, verbs, and adjectives.\n",
    "- During each generation process, one verb, one noun, and one adjective were randomly chosen from the curated vocabulary.\n",
    "- The model then proceeded to generate a story incorporating these randomly selected words, thereby ensuring diversity in the generated datasets.\n",
    "- By integrating random words from the curated vocabulary, the model diversified the stories it produced, enhancing the overall diversity of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Write a short story (3-5 paragraphs) which only uses very simple words that a 3 year old child would likely understand. The story should use the verb ”{random.choice(verbs_list)}”, the noun ”{random.choice(nouns_list)}” and the adjective ”{random.choice(adjectives_list)}”. The story should have the following features: {random.choice(features_list)}, {random.choice(features_list)}. Remember to only use simple words!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The technique significantly expanded the dataset's diversity by ensuring that stories encompassed a child's entire vocabulary and various combinations of concepts.\n",
    "- Additionally, the authors incorporated potential story features such as dialogue, plot twists, bad endings, or moral lessons.\n",
    "- A random subset of these features was selected for each story generation process.\n",
    "- The model was prompted to include the chosen story features, thereby enriching the narratives with diverse elements and enhancing the overall quality and variety of the generated stories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Write a short story (3-5 paragraphs) which only uses very simple words that a 3 year old child would likely understand. The story should use the verb ”decorate”, the noun ”thunder” and the adjective ”ancient”. The story should have the following features: the story should contain at least one dialogue, the story has a bad ending. Remember to only use simple words!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output:**\n",
    "\n",
    "```\n",
    "Once upon a time, in an ancient house, there lived a girl named Lily. She loved to decorate her room with pretty things. One day, she found a big box in the attic. She opened it and saw many shiny decorations. Lily was very happy and decided to use them in her room. As Lily was decorating her room, the sky outside became dark. There was a loud thunder sound, and Lily got scared. She ran to her mom and said, ”Mommy, the thunder is so loud!” Her mom hugged her and said, ”Don’t worry, it will pass soon.” But the thunder did not stop. It got louder and louder, and the ancient house started to shake. Suddenly, the roof fell down on the pretty decorations. Lily was sad because her room was not pretty anymore. The end.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative (Hierarchical) Synthetic Data Generation\n",
    "\n",
    "- The format can be further enriched by incorporating additional entities, some of which are generated beforehand by the LLM itself.\n",
    "  - For instance, one could initiate the process by requesting the generation of a story summary and specifying a particular sentence that must be included in the story.\n",
    "  - The LLM generates this intermediate data, which is then utilized in subsequent requests.\n",
    "  - In the final request, the previously generated intermediate data is incorporated, allowing for the creation of more complex and intricate story narratives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Summary: {a short summary generated by LLM, using the approach above}\n",
    "Features: {copy the features from the initial prompt}\n",
    "Sentence: {a sentence generated by LLM, which should be present in the story}\n",
    "Words: {copy the words from the initial prompt}\n",
    "Story:\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Example:**\n",
    "```\n",
    "Summary: Lily and Timmy build a sandcastle together and learn to compromise, but it gets knocked over by a gust of wind. They find beauty in the broken sandcastle and play happily with a butterfly.\n",
    "Features: Dialogue, Foreshadowing, Twist\n",
    "Sentence: One day, she went to the park and saw a beautiful butterfly.\n",
    "Words: disagree, network, beautiful\n",
    "Story:\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output:**\n",
    "\n",
    "```\n",
    "Once upon a time, there was a little girl named Lily. She loved to play with her toys and her friends. One day, she went to the park and saw a beautiful butterfly. She tried to catch it, but it flew away. Lily’s friend, Timmy, came to play with her. They decided to build a sandcastle, but they disagreed on how to build it. Lily wanted to make it tall, while Timmy wanted to make it wide. They argued for a while, but finally agreed to make it both tall and wide. As they were building the sandcastle, they noticed a group of ants working together. They realized that the ants were building a network of tunnels. Suddenly, a gust of wind came and knocked over their sandcastle. They were sad, but then they saw the butterfly again. It landed on the remains of their sandcastle and they realized that it was still beautiful, even in its broken state. They smiled and played together happily.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Generating Code**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Language Models like ChatGPT demonstrate high effectiveness in generating code.\n",
    "-  Similar to other chat models from OpenAI, a System Message is employed to define response behavior and format for the prompt examples.\n",
    "- Below is the System Message utilized for the prompt examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "You are a helpful code assistant that can teach a junior developer how to code. Your language of choice is Python. Don't explain the code, just generate the code block itself.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The code generation capabilities of LLMs can also be employed to generate code solely from comments.\n",
    "- Instructions are provided within a comment block to guide the code generation process.\n",
    "- By leveraging comments as input, LLMs can interpret the instructions and generate corresponding code snippets.\n",
    "- This approach offers versatility in generating code from various types of input, such as comments or descriptions of desired functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\"\"\"\n",
    "1. Create a list of movies\n",
    "2. Create a list of ratings for these movies\n",
    "3. Combine them to make a json object of 10 movies with their ratings.\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"The Shawshank Redemption\": 9.3,\n",
      "    \"The Godfather\": 9.2,\n",
      "    \"The Dark Knight\": 9.0,\n",
      "    \"Schindler's List\": 8.9,\n",
      "    \"Pulp Fiction\": 8.9,\n",
      "    \"The Lord of the Rings: The Return of the King\": 8.9,\n",
      "    \"Forrest Gump\": 8.8,\n",
      "    \"Star Wars: Episode V - The Empire Strikes Back\": 8.7,\n",
      "    \"Inception\": 8.7,\n",
      "    \"The Silence of the Lambs\": 8.6\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "movies = [\"The Shawshank Redemption\", \"The Godfather\", \"The Dark Knight\", \"Schindler's List\", \"Pulp Fiction\", \"The Lord of the Rings: The Return of the King\", \"Forrest Gump\", \"Star Wars: Episode V - The Empire Strikes Back\", \"Inception\", \"The Silence of the Lambs\"]\n",
    " \n",
    "ratings = [9.3, 9.2, 9.0, 8.9, 8.9, 8.9, 8.8, 8.7, 8.7, 8.6]\n",
    " \n",
    "movie_ratings = {}\n",
    " \n",
    "for i in range(len(movies)):\n",
    "    movie_ratings[movies[i]] = ratings[i]\n",
    " \n",
    "json_object = json.dumps(movie_ratings, indent=4)\n",
    " \n",
    "print(json_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Complete Functions or Next Line**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# function to multiply two numbers and add 75 to it\n",
    " \n",
    "def multiply(\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output:**\n",
    "\n",
    "```\n",
    "a, b):\n",
    "    result = a * b\n",
    "    result += 75\n",
    "    return result\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Explain Code**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When learning a programming language, prompting the model to explain specific code segments can be highly beneficial.\n",
    "- Queries generated previously can be repurposed to request explanations for code snippets.\n",
    "- It's essential to consider the System Message used, as the model's behavior may vary based on its instructions.\n",
    "  - For instance, if the System Message restricts the model to acting as a Python code assistant, it might refuse certain requests that deviate from this instruction.\n",
    "- The model may still provide explanations for code snippets, demonstrating its adaptability and utility in aiding programming education."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "SELECT students.StudentId, students.StudentName\n",
    "FROM students\n",
    "INNER JOIN departments\n",
    "ON students.DepartmentId = departments.DepartmentId\n",
    "WHERE departments.DepartmentName = 'Computer Science';\n",
    "\n",
    "Explain the above SQL statement.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output:**\n",
    "\n",
    "```\n",
    "Sorry, as a code assistant in Python, I cannot generate SQL code. However, I can explain the purpose of the SQL statement provided. \n",
    "\n",
    "This SQL statement selects the `StudentId` and `StudentName` columns from the `students` table, where the `DepartmentName` column in the `departments` table is equal to 'Computer Science'. To achieve this, the statement performs an inner join on the `DepartmentId` column between the `students` and `departments` tables. \n",
    "\n",
    "In simpler terms, it is selecting the names and IDs of students who are enrolled in the Computer Science department.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Graduate Job Classification Case Study**\n",
    "\n",
    "- Clavié et al., 2023 present a case study on prompt engineering applied to a text classification task within a production system.\n",
    "- **Task Description:** \n",
    "  - Classifying whether a job is suitable as an entry-level position for recent graduates or not.\n",
    "- The study evaluates various prompt engineering techniques using GPT-3.5 (gpt-3.5-turbo), comparing its performance against other models, including DeBERTa-V3.\n",
    "  - Few-shot CoT prompting underperforms compared to Zero-shot prompting when expert knowledge is not required.\n",
    "  - The prompt significantly influences the model's reasoning, with post-prompt engineering models achieving substantially higher F1 scores.\n",
    "  - Attempts to enforce template adherence reduce performance across all cases.\n",
    "  - Small modifications have a disproportionate impact on performance.\n",
    "  - Clear instructions and repetition of key points are crucial for enhancing performance.\n",
    "  - Even simple modifications, such as assigning a human name to the model, lead to measurable improvements in F1 score.\n",
    "- The observed template adherence issue diminishes in early testing with GPT-4, which is subsequent to the period covered in the paper.\n",
    "\n",
    "\n",
    "<img src=\"./images/study_1.png\" width=\"800\" align=\"center\"/>\n",
    "\n",
    "\n",
    "<img src=\"./images/study_2.png\" width=\"800\" align=\"center\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Prompt Function**\n",
    "\n",
    "- Drawing a parallel between GPT's dialogue interface and a programming language's shell\n",
    "  - The prompt can be likened to forming a function.\n",
    "- The encapsulated prompt acts as a **function** with a unique name. \n",
    "  - When invoked with input text, it produces results based on predefined internal rules.\n",
    "- Creating a reusable prompt with a name simplifies engagement with GPT, akin to having a handy tool to delegate specific tasks.\n",
    "  - Inputting text triggers the function, generating the desired output.\n",
    "- Encapsulating prompts into functions enables the creation of a series of functions to establish a workflow.\n",
    "  - Each function represents a distinct step or task, and when sequenced appropriately, they automate complex processes or enhance problem-solving efficiency.\n",
    "\n",
    "\n",
    "- **Before** we can use a function, we need to **let GPT know about it**. \n",
    "\n",
    "\n",
    "```\n",
    "Hello, ChatGPT! I hope you are doing well. I am reaching out to you for assistance with a specific function. I understand that you have the capability to process information and perform various tasks based on the instructions provided. In order to help you understand my request more easily, I will be using a template to describe the function, input, and instructions on what to do with the input. Please find the details below:\n",
    "\n",
    "function_name: [Function Name]\n",
    "input: [Input]\n",
    "rule: [Instructions on how to process the input]\n",
    "\n",
    "I kindly request you to provide the output for this function, based on the details I have provided. Your assistance is greatly appreciated. Thank you!\n",
    "I will replace the text inside the brackets with the relevant information for the function I want you to perform. This detailed introduction should help you understand my request more efficiently and provide the desired output. The format is function_name(input) If you understand, just answer one word with ok.\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Examples: English Study Assistant**\n",
    "\n",
    "```\n",
    "function_name: [trans_word]\n",
    "input: [\"text\"]\n",
    "rule: [I want you to act as an English translator, spelling corrector and improver. I will provide you with input forms including \"text\" in any language and you will detect the language, translate it and answer in the corrected of my text, in English.]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "function_name: [fix_english]\n",
    "input: [\"text\"]\n",
    "rule: [Please serve as an English master, spelling corrector, and language enhancer. I will provide you with input forms including \"text\", I want you to improve the text's vocabulary and sentences with more natural and elegent. Keep the meaning same.]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "trans_word('婆罗摩火山处于享有“千岛之国”美称的印度尼西亚. 多岛之国印尼有4500座之多的火山, 世界著名的十大活火山有三座在这里.')\n",
    "fix_english('Finally, you can run the function independently or chain them together.')\n",
    "fix_english(expand_word(trans_word('婆罗摩火山处于享有“千岛之国”美称的印度尼西亚. 多岛之国印尼有4500座之多的火山, 世界著名的十大活火山有三座在这里.')))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If you don't want ChatGPT to output excessive information, you can simply add a sentence after defining the function's rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Multiple params function**\n",
    "\n",
    "```\n",
    "function_name: [pg]\n",
    "input: [\"length\", \"capitalized\", \"lowercase\", \"numbers\", \"special\"]\n",
    "rule: [I want you to act as a password generator for individuals in need of a secure password. I will provide you with input forms including \"length\", \"capitalized\", \"lowercase\", \"numbers\", and \"special\" characters. Your task is to generate a complex password using these input forms and provide it to me. Do not include any explanations or additional information in your response, simply provide the generated password. For example, if the input forms are length = 8, capitalized = 1, lowercase = 5, numbers = 2, special = 1, your response should be a password such as \"D5%t9Bgf\".]\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
